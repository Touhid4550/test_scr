2023-11-13 18:46:05 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://eurolux.de/category/warmespeicher> (referer: https://eurolux.de/)
2023-11-13 18:46:05 [scrapy.core.scraper] ERROR: Spider error processing <GET https://eurolux.de/category/warmespeicher> (referer: https://eurolux.de/)
Traceback (most recent call last):
  File "/Users/ms/scrapy-1/.venv/lib/python3.9/site-packages/scrapy/utils/defer.py", line 295, in aiter_errback
    yield await it.__anext__()
  File "/Users/ms/scrapy-1/.venv/lib/python3.9/site-packages/scrapy/utils/python.py", line 374, in __anext__
    return await self.data.__anext__()
  File "/Users/ms/scrapy-1/.venv/lib/python3.9/site-packages/scrapy/utils/python.py", line 355, in _async_chain
    async for o in as_async_generator(it):
  File "/Users/ms/scrapy-1/.venv/lib/python3.9/site-packages/scrapy/utils/asyncgen.py", line 14, in as_async_generator
    async for r in it:
  File "/Users/ms/scrapy-1/.venv/lib/python3.9/site-packages/scrapy/utils/python.py", line 374, in __anext__
    return await self.data.__anext__()
  File "/Users/ms/scrapy-1/.venv/lib/python3.9/site-packages/scrapy/utils/python.py", line 355, in _async_chain
    async for o in as_async_generator(it):
  File "/Users/ms/scrapy-1/.venv/lib/python3.9/site-packages/scrapy/utils/asyncgen.py", line 14, in as_async_generator
    async for r in it:
  File "/Users/ms/scrapy-1/.venv/lib/python3.9/site-packages/scrapy/core/spidermw.py", line 118, in process_async
    async for r in iterable:
  File "/Users/ms/scrapy-1/.venv/lib/python3.9/site-packages/scrapy/spidermiddlewares/offsite.py", line 31, in process_spider_output_async
    async for r in result or ():
  File "/Users/ms/scrapy-1/.venv/lib/python3.9/site-packages/scrapy/core/spidermw.py", line 118, in process_async
    async for r in iterable:
  File "/Users/ms/scrapy-1/.venv/lib/python3.9/site-packages/scrapy/spidermiddlewares/referer.py", line 355, in process_spider_output_async
    async for r in result or ():
  File "/Users/ms/scrapy-1/.venv/lib/python3.9/site-packages/scrapy/core/spidermw.py", line 118, in process_async
    async for r in iterable:
  File "/Users/ms/scrapy-1/.venv/lib/python3.9/site-packages/scrapy/spidermiddlewares/urllength.py", line 30, in process_spider_output_async
    async for r in result or ():
  File "/Users/ms/scrapy-1/.venv/lib/python3.9/site-packages/scrapy/core/spidermw.py", line 118, in process_async
    async for r in iterable:
  File "/Users/ms/scrapy-1/.venv/lib/python3.9/site-packages/scrapy/spidermiddlewares/depth.py", line 35, in process_spider_output_async
    async for r in result or ():
  File "/Users/ms/scrapy-1/.venv/lib/python3.9/site-packages/scrapy/core/spidermw.py", line 118, in process_async
    async for r in iterable:
  File "/Users/ms/scrapy-1/.venv/lib/python3.9/site-packages/scrapy/spiders/crawl.py", line 124, in _parse_response
    for request_or_item in iterate_spider_output(cb_res):
  File "/Users/ms/scrapy-1/scrapy1/scrapy1/spiders/eurolux_spider.py", line 44, in parse_page
    description = bleach_html(response.css('.text-md-h6').get())
  File "/Users/ms/scrapy-1/scrapy1/scrapy1/spiders/eurolux_spider.py", line 15, in bleach_html
    cleaned_html = bleach.clean(html_string, tags=allowed_tags, strip=True)
  File "/Users/ms/scrapy-1/.venv/lib/python3.9/site-packages/bleach/__init__.py", line 82, in clean
    return cleaner.clean(text)
  File "/Users/ms/scrapy-1/.venv/lib/python3.9/site-packages/bleach/sanitizer.py", line 186, in clean
    raise TypeError(message)
TypeError: argument cannot be of 'NoneType' type, must be of text type
2023-11-13 18:46:05 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://eurolux.de/category/immervolltank> (referer: https://eurolux.de/)
2023-11-13 18:46:06 [scrapy.core.scraper] ERROR: Spider error processing <GET https://eurolux.de/category/immervolltank> (referer: https://eurolux.de/)
Traceback (most recent call last):
  File "/Users/ms/scrapy-1/.venv/lib/python3.9/site-packages/scrapy/utils/defer.py", line 295, in aiter_errback
    yield await it.__anext__()
  File "/Users/ms/scrapy-1/.venv/lib/python3.9/site-packages/scrapy/utils/python.py", line 374, in __anext__
    return await self.data.__anext__()
  File "/Users/ms/scrapy-1/.venv/lib/python3.9/site-packages/scrapy/utils/python.py", line 355, in _async_chain
    async for o in as_async_generator(it):
  File "/Users/ms/scrapy-1/.venv/lib/python3.9/site-packages/scrapy/utils/asyncgen.py", line 14, in as_async_generator
    async for r in it:
  File "/Users/ms/scrapy-1/.venv/lib/python3.9/site-packages/scrapy/utils/python.py", line 374, in __anext__
    return await self.data.__anext__()
  File "/Users/ms/scrapy-1/.venv/lib/python3.9/site-packages/scrapy/utils/python.py", line 355, in _async_chain
    async for o in as_async_generator(it):
  File "/Users/ms/scrapy-1/.venv/lib/python3.9/site-packages/scrapy/utils/asyncgen.py", line 14, in as_async_generator
    async for r in it:
  File "/Users/ms/scrapy-1/.venv/lib/python3.9/site-packages/scrapy/core/spidermw.py", line 118, in process_async
    async for r in iterable:
  File "/Users/ms/scrapy-1/.venv/lib/python3.9/site-packages/scrapy/spidermiddlewares/offsite.py", line 31, in process_spider_output_async
    async for r in result or ():
  File "/Users/ms/scrapy-1/.venv/lib/python3.9/site-packages/scrapy/core/spidermw.py", line 118, in process_async
    async for r in iterable:
  File "/Users/ms/scrapy-1/.venv/lib/python3.9/site-packages/scrapy/spidermiddlewares/referer.py", line 355, in process_spider_output_async
    async for r in result or ():
  File "/Users/ms/scrapy-1/.venv/lib/python3.9/site-packages/scrapy/core/spidermw.py", line 118, in process_async
    async for r in iterable:
  File "/Users/ms/scrapy-1/.venv/lib/python3.9/site-packages/scrapy/spidermiddlewares/urllength.py", line 30, in process_spider_output_async
    async for r in result or ():
  File "/Users/ms/scrapy-1/.venv/lib/python3.9/site-packages/scrapy/core/spidermw.py", line 118, in process_async
    async for r in iterable:
  File "/Users/ms/scrapy-1/.venv/lib/python3.9/site-packages/scrapy/spidermiddlewares/depth.py", line 35, in process_spider_output_async
    async for r in result or ():
  File "/Users/ms/scrapy-1/.venv/lib/python3.9/site-packages/scrapy/core/spidermw.py", line 118, in process_async
    async for r in iterable:
  File "/Users/ms/scrapy-1/.venv/lib/python3.9/site-packages/scrapy/spiders/crawl.py", line 124, in _parse_response
    for request_or_item in iterate_spider_output(cb_res):
  File "/Users/ms/scrapy-1/scrapy1/scrapy1/spiders/eurolux_spider.py", line 44, in parse_page
    description = bleach_html(response.css('.text-md-h6').get())
  File "/Users/ms/scrapy-1/scrapy1/scrapy1/spiders/eurolux_spider.py", line 15, in bleach_html
    cleaned_html = bleach.clean(html_string, tags=allowed_tags, strip=True)
  File "/Users/ms/scrapy-1/.venv/lib/python3.9/site-packages/bleach/__init__.py", line 82, in clean
    return cleaner.clean(text)
  File "/Users/ms/scrapy-1/.venv/lib/python3.9/site-packages/bleach/sanitizer.py", line 186, in clean
    raise TypeError(message)
TypeError: argument cannot be of 'NoneType' type, must be of text type
2023-11-13 18:46:06 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://eurolux.de/category/gfk-tank-kunststofftank> (referer: https://eurolux.de/)
2023-11-13 18:46:06 [scrapy.core.scraper] ERROR: Spider error processing <GET https://eurolux.de/category/gfk-tank-kunststofftank> (referer: https://eurolux.de/)
Traceback (most recent call last):
  File "/Users/ms/scrapy-1/.venv/lib/python3.9/site-packages/scrapy/utils/defer.py", line 295, in aiter_errback
    yield await it.__anext__()
  File "/Users/ms/scrapy-1/.venv/lib/python3.9/site-packages/scrapy/utils/python.py", line 374, in __anext__
    return await self.data.__anext__()
  File "/Users/ms/scrapy-1/.venv/lib/python3.9/site-packages/scrapy/utils/python.py", line 355, in _async_chain
    async for o in as_async_generator(it):
  File "/Users/ms/scrapy-1/.venv/lib/python3.9/site-packages/scrapy/utils/asyncgen.py", line 14, in as_async_generator
    async for r in it:
  File "/Users/ms/scrapy-1/.venv/lib/python3.9/site-packages/scrapy/utils/python.py", line 374, in __anext__
    return await self.data.__anext__()
  File "/Users/ms/scrapy-1/.venv/lib/python3.9/site-packages/scrapy/utils/python.py", line 355, in _async_chain
    async for o in as_async_generator(it):
  File "/Users/ms/scrapy-1/.venv/lib/python3.9/site-packages/scrapy/utils/asyncgen.py", line 14, in as_async_generator
    async for r in it:
  File "/Users/ms/scrapy-1/.venv/lib/python3.9/site-packages/scrapy/core/spidermw.py", line 118, in process_async
    async for r in iterable:
  File "/Users/ms/scrapy-1/.venv/lib/python3.9/site-packages/scrapy/spidermiddlewares/offsite.py", line 31, in process_spider_output_async
    async for r in result or ():
  File "/Users/ms/scrapy-1/.venv/lib/python3.9/site-packages/scrapy/core/spidermw.py", line 118, in process_async
    async for r in iterable:
  File "/Users/ms/scrapy-1/.venv/lib/python3.9/site-packages/scrapy/spidermiddlewares/referer.py", line 355, in process_spider_output_async
    async for r in result or ():
  File "/Users/ms/scrapy-1/.venv/lib/python3.9/site-packages/scrapy/core/spidermw.py", line 118, in process_async
    async for r in iterable:
  File "/Users/ms/scrapy-1/.venv/lib/python3.9/site-packages/scrapy/spidermiddlewares/urllength.py", line 30, in process_spider_output_async
    async for r in result or ():
  File "/Users/ms/scrapy-1/.venv/lib/python3.9/site-packages/scrapy/core/spidermw.py", line 118, in process_async
    async for r in iterable:
  File "/Users/ms/scrapy-1/.venv/lib/python3.9/site-packages/scrapy/spidermiddlewares/depth.py", line 35, in process_spider_output_async
    async for r in result or ():
  File "/Users/ms/scrapy-1/.venv/lib/python3.9/site-packages/scrapy/core/spidermw.py", line 118, in process_async
    async for r in iterable:
  File "/Users/ms/scrapy-1/.venv/lib/python3.9/site-packages/scrapy/spiders/crawl.py", line 124, in _parse_response
    for request_or_item in iterate_spider_output(cb_res):
  File "/Users/ms/scrapy-1/scrapy1/scrapy1/spiders/eurolux_spider.py", line 44, in parse_page
    description = bleach_html(response.css('.text-md-h6').get())
  File "/Users/ms/scrapy-1/scrapy1/scrapy1/spiders/eurolux_spider.py", line 15, in bleach_html
    cleaned_html = bleach.clean(html_string, tags=allowed_tags, strip=True)
  File "/Users/ms/scrapy-1/.venv/lib/python3.9/site-packages/bleach/__init__.py", line 82, in clean
    return cleaner.clean(text)
  File "/Users/ms/scrapy-1/.venv/lib/python3.9/site-packages/bleach/sanitizer.py", line 186, in clean
    raise TypeError(message)
TypeError: argument cannot be of 'NoneType' type, must be of text type
2023-11-13 18:46:07 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://eurolux.de/category/cip-tank-de> (referer: https://eurolux.de/)
2023-11-13 18:46:07 [scrapy.core.scraper] ERROR: Spider error processing <GET https://eurolux.de/category/cip-tank-de> (referer: https://eurolux.de/)
Traceback (most recent call last):
  File "/Users/ms/scrapy-1/.venv/lib/python3.9/site-packages/scrapy/utils/defer.py", line 295, in aiter_errback
    yield await it.__anext__()
  File "/Users/ms/scrapy-1/.venv/lib/python3.9/site-packages/scrapy/utils/python.py", line 374, in __anext__
    return await self.data.__anext__()
  File "/Users/ms/scrapy-1/.venv/lib/python3.9/site-packages/scrapy/utils/python.py", line 355, in _async_chain
    async for o in as_async_generator(it):
  File "/Users/ms/scrapy-1/.venv/lib/python3.9/site-packages/scrapy/utils/asyncgen.py", line 14, in as_async_generator
    async for r in it:
  File "/Users/ms/scrapy-1/.venv/lib/python3.9/site-packages/scrapy/utils/python.py", line 374, in __anext__
    return await self.data.__anext__()
  File "/Users/ms/scrapy-1/.venv/lib/python3.9/site-packages/scrapy/utils/python.py", line 355, in _async_chain
    async for o in as_async_generator(it):
  File "/Users/ms/scrapy-1/.venv/lib/python3.9/site-packages/scrapy/utils/asyncgen.py", line 14, in as_async_generator
    async for r in it:
  File "/Users/ms/scrapy-1/.venv/lib/python3.9/site-packages/scrapy/core/spidermw.py", line 118, in process_async
    async for r in iterable:
  File "/Users/ms/scrapy-1/.venv/lib/python3.9/site-packages/scrapy/spidermiddlewares/offsite.py", line 31, in process_spider_output_async
    async for r in result or ():
  File "/Users/ms/scrapy-1/.venv/lib/python3.9/site-packages/scrapy/core/spidermw.py", line 118, in process_async
    async for r in iterable:
  File "/Users/ms/scrapy-1/.venv/lib/python3.9/site-packages/scrapy/spidermiddlewares/referer.py", line 355, in process_spider_output_async
    async for r in result or ():
  File "/Users/ms/scrapy-1/.venv/lib/python3.9/site-packages/scrapy/core/spidermw.py", line 118, in process_async
    async for r in iterable:
  File "/Users/ms/scrapy-1/.venv/lib/python3.9/site-packages/scrapy/spidermiddlewares/urllength.py", line 30, in process_spider_output_async
    async for r in result or ():
  File "/Users/ms/scrapy-1/.venv/lib/python3.9/site-packages/scrapy/core/spidermw.py", line 118, in process_async
    async for r in iterable:
  File "/Users/ms/scrapy-1/.venv/lib/python3.9/site-packages/scrapy/spidermiddlewares/depth.py", line 35, in process_spider_output_async
    async for r in result or ():
  File "/Users/ms/scrapy-1/.venv/lib/python3.9/site-packages/scrapy/core/spidermw.py", line 118, in process_async
    async for r in iterable:
  File "/Users/ms/scrapy-1/.venv/lib/python3.9/site-packages/scrapy/spiders/crawl.py", line 124, in _parse_response
    for request_or_item in iterate_spider_output(cb_res):
  File "/Users/ms/scrapy-1/scrapy1/scrapy1/spiders/eurolux_spider.py", line 44, in parse_page
    description = bleach_html(response.css('.text-md-h6').get())
  File "/Users/ms/scrapy-1/scrapy1/scrapy1/spiders/eurolux_spider.py", line 15, in bleach_html
    cleaned_html = bleach.clean(html_string, tags=allowed_tags, strip=True)
  File "/Users/ms/scrapy-1/.venv/lib/python3.9/site-packages/bleach/__init__.py", line 82, in clean
    return cleaner.clean(text)
  File "/Users/ms/scrapy-1/.venv/lib/python3.9/site-packages/bleach/sanitizer.py", line 186, in clean
    raise TypeError(message)
TypeError: argument cannot be of 'NoneType' type, must be of text type
2023-11-13 18:46:09 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://eurolux.de/category/transporttank-container> (referer: https://eurolux.de/)
2023-11-13 18:46:09 [scrapy.core.scraper] ERROR: Spider error processing <GET https://eurolux.de/category/transporttank-container> (referer: https://eurolux.de/)
Traceback (most recent call last):
  File "/Users/ms/scrapy-1/.venv/lib/python3.9/site-packages/scrapy/utils/defer.py", line 295, in aiter_errback
    yield await it.__anext__()
  File "/Users/ms/scrapy-1/.venv/lib/python3.9/site-packages/scrapy/utils/python.py", line 374, in __anext__
    return await self.data.__anext__()
  File "/Users/ms/scrapy-1/.venv/lib/python3.9/site-packages/scrapy/utils/python.py", line 355, in _async_chain
    async for o in as_async_generator(it):
  File "/Users/ms/scrapy-1/.venv/lib/python3.9/site-packages/scrapy/utils/asyncgen.py", line 14, in as_async_generator
    async for r in it:
  File "/Users/ms/scrapy-1/.venv/lib/python3.9/site-packages/scrapy/utils/python.py", line 374, in __anext__
    return await self.data.__anext__()
  File "/Users/ms/scrapy-1/.venv/lib/python3.9/site-packages/scrapy/utils/python.py", line 355, in _async_chain
    async for o in as_async_generator(it):
  File "/Users/ms/scrapy-1/.venv/lib/python3.9/site-packages/scrapy/utils/asyncgen.py", line 14, in as_async_generator
    async for r in it:
  File "/Users/ms/scrapy-1/.venv/lib/python3.9/site-packages/scrapy/core/spidermw.py", line 118, in process_async
    async for r in iterable:
  File "/Users/ms/scrapy-1/.venv/lib/python3.9/site-packages/scrapy/spidermiddlewares/offsite.py", line 31, in process_spider_output_async
    async for r in result or ():
  File "/Users/ms/scrapy-1/.venv/lib/python3.9/site-packages/scrapy/core/spidermw.py", line 118, in process_async
    async for r in iterable:
  File "/Users/ms/scrapy-1/.venv/lib/python3.9/site-packages/scrapy/spidermiddlewares/referer.py", line 355, in process_spider_output_async
    async for r in result or ():
  File "/Users/ms/scrapy-1/.venv/lib/python3.9/site-packages/scrapy/core/spidermw.py", line 118, in process_async
    async for r in iterable:
  File "/Users/ms/scrapy-1/.venv/lib/python3.9/site-packages/scrapy/spidermiddlewares/urllength.py", line 30, in process_spider_output_async
    async for r in result or ():
  File "/Users/ms/scrapy-1/.venv/lib/python3.9/site-packages/scrapy/core/spidermw.py", line 118, in process_async
    async for r in iterable:
  File "/Users/ms/scrapy-1/.venv/lib/python3.9/site-packages/scrapy/spidermiddlewares/depth.py", line 35, in process_spider_output_async
    async for r in result or ():
  File "/Users/ms/scrapy-1/.venv/lib/python3.9/site-packages/scrapy/core/spidermw.py", line 118, in process_async
    async for r in iterable:
  File "/Users/ms/scrapy-1/.venv/lib/python3.9/site-packages/scrapy/spiders/crawl.py", line 124, in _parse_response
    for request_or_item in iterate_spider_output(cb_res):
  File "/Users/ms/scrapy-1/scrapy1/scrapy1/spiders/eurolux_spider.py", line 44, in parse_page
    description = bleach_html(response.css('.text-md-h6').get())
  File "/Users/ms/scrapy-1/scrapy1/scrapy1/spiders/eurolux_spider.py", line 15, in bleach_html
    cleaned_html = bleach.clean(html_string, tags=allowed_tags, strip=True)
  File "/Users/ms/scrapy-1/.venv/lib/python3.9/site-packages/bleach/__init__.py", line 82, in clean
    return cleaner.clean(text)
  File "/Users/ms/scrapy-1/.venv/lib/python3.9/site-packages/bleach/sanitizer.py", line 186, in clean
    raise TypeError(message)
TypeError: argument cannot be of 'NoneType' type, must be of text type
2023-11-13 18:46:09 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://eurolux.de/category/ruhrwerke> (referer: https://eurolux.de/)
2023-11-13 18:46:09 [scrapy.core.scraper] ERROR: Spider error processing <GET https://eurolux.de/category/ruhrwerke> (referer: https://eurolux.de/)
Traceback (most recent call last):
  File "/Users/ms/scrapy-1/.venv/lib/python3.9/site-packages/scrapy/utils/defer.py", line 295, in aiter_errback
    yield await it.__anext__()
  File "/Users/ms/scrapy-1/.venv/lib/python3.9/site-packages/scrapy/utils/python.py", line 374, in __anext__
    return await self.data.__anext__()
  File "/Users/ms/scrapy-1/.venv/lib/python3.9/site-packages/scrapy/utils/python.py", line 355, in _async_chain
    async for o in as_async_generator(it):
  File "/Users/ms/scrapy-1/.venv/lib/python3.9/site-packages/scrapy/utils/asyncgen.py", line 14, in as_async_generator
    async for r in it:
  File "/Users/ms/scrapy-1/.venv/lib/python3.9/site-packages/scrapy/utils/python.py", line 374, in __anext__
    return await self.data.__anext__()
  File "/Users/ms/scrapy-1/.venv/lib/python3.9/site-packages/scrapy/utils/python.py", line 355, in _async_chain
    async for o in as_async_generator(it):
  File "/Users/ms/scrapy-1/.venv/lib/python3.9/site-packages/scrapy/utils/asyncgen.py", line 14, in as_async_generator
    async for r in it:
  File "/Users/ms/scrapy-1/.venv/lib/python3.9/site-packages/scrapy/core/spidermw.py", line 118, in process_async
    async for r in iterable:
  File "/Users/ms/scrapy-1/.venv/lib/python3.9/site-packages/scrapy/spidermiddlewares/offsite.py", line 31, in process_spider_output_async
    async for r in result or ():
  File "/Users/ms/scrapy-1/.venv/lib/python3.9/site-packages/scrapy/core/spidermw.py", line 118, in process_async
    async for r in iterable:
  File "/Users/ms/scrapy-1/.venv/lib/python3.9/site-packages/scrapy/spidermiddlewares/referer.py", line 355, in process_spider_output_async
    async for r in result or ():
  File "/Users/ms/scrapy-1/.venv/lib/python3.9/site-packages/scrapy/core/spidermw.py", line 118, in process_async
    async for r in iterable:
  File "/Users/ms/scrapy-1/.venv/lib/python3.9/site-packages/scrapy/spidermiddlewares/urllength.py", line 30, in process_spider_output_async
    async for r in result or ():
  File "/Users/ms/scrapy-1/.venv/lib/python3.9/site-packages/scrapy/core/spidermw.py", line 118, in process_async
    async for r in iterable:
  File "/Users/ms/scrapy-1/.venv/lib/python3.9/site-packages/scrapy/spidermiddlewares/depth.py", line 35, in process_spider_output_async
    async for r in result or ():
  File "/Users/ms/scrapy-1/.venv/lib/python3.9/site-packages/scrapy/core/spidermw.py", line 118, in process_async
    async for r in iterable:
  File "/Users/ms/scrapy-1/.venv/lib/python3.9/site-packages/scrapy/spiders/crawl.py", line 124, in _parse_response
    for request_or_item in iterate_spider_output(cb_res):
  File "/Users/ms/scrapy-1/scrapy1/scrapy1/spiders/eurolux_spider.py", line 44, in parse_page
    description = bleach_html(response.css('.text-md-h6').get())
  File "/Users/ms/scrapy-1/scrapy1/scrapy1/spiders/eurolux_spider.py", line 15, in bleach_html
    cleaned_html = bleach.clean(html_string, tags=allowed_tags, strip=True)
  File "/Users/ms/scrapy-1/.venv/lib/python3.9/site-packages/bleach/__init__.py", line 82, in clean
    return cleaner.clean(text)
  File "/Users/ms/scrapy-1/.venv/lib/python3.9/site-packages/bleach/sanitizer.py", line 186, in clean
    raise TypeError(message)
TypeError: argument cannot be of 'NoneType' type, must be of text type
2023-11-13 18:46:09 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://eurolux.de/category/komplette-abfuellanlage> (referer: https://eurolux.de/)
2023-11-13 18:46:09 [scrapy.core.scraper] ERROR: Spider error processing <GET https://eurolux.de/category/komplette-abfuellanlage> (referer: https://eurolux.de/)
Traceback (most recent call last):
  File "/Users/ms/scrapy-1/.venv/lib/python3.9/site-packages/scrapy/utils/defer.py", line 295, in aiter_errback
    yield await it.__anext__()
  File "/Users/ms/scrapy-1/.venv/lib/python3.9/site-packages/scrapy/utils/python.py", line 374, in __anext__
    return await self.data.__anext__()
  File "/Users/ms/scrapy-1/.venv/lib/python3.9/site-packages/scrapy/utils/python.py", line 355, in _async_chain
    async for o in as_async_generator(it):
  File "/Users/ms/scrapy-1/.venv/lib/python3.9/site-packages/scrapy/utils/asyncgen.py", line 14, in as_async_generator
    async for r in it:
  File "/Users/ms/scrapy-1/.venv/lib/python3.9/site-packages/scrapy/utils/python.py", line 374, in __anext__
    return await self.data.__anext__()
  File "/Users/ms/scrapy-1/.venv/lib/python3.9/site-packages/scrapy/utils/python.py", line 355, in _async_chain
    async for o in as_async_generator(it):
  File "/Users/ms/scrapy-1/.venv/lib/python3.9/site-packages/scrapy/utils/asyncgen.py", line 14, in as_async_generator
    async for r in it:
  File "/Users/ms/scrapy-1/.venv/lib/python3.9/site-packages/scrapy/core/spidermw.py", line 118, in process_async
    async for r in iterable:
  File "/Users/ms/scrapy-1/.venv/lib/python3.9/site-packages/scrapy/spidermiddlewares/offsite.py", line 31, in process_spider_output_async
    async for r in result or ():
  File "/Users/ms/scrapy-1/.venv/lib/python3.9/site-packages/scrapy/core/spidermw.py", line 118, in process_async
    async for r in iterable:
  File "/Users/ms/scrapy-1/.venv/lib/python3.9/site-packages/scrapy/spidermiddlewares/referer.py", line 355, in process_spider_output_async
    async for r in result or ():
  File "/Users/ms/scrapy-1/.venv/lib/python3.9/site-packages/scrapy/core/spidermw.py", line 118, in process_async
    async for r in iterable:
  File "/Users/ms/scrapy-1/.venv/lib/python3.9/site-packages/scrapy/spidermiddlewares/urllength.py", line 30, in process_spider_output_async
    async for r in result or ():
  File "/Users/ms/scrapy-1/.venv/lib/python3.9/site-packages/scrapy/core/spidermw.py", line 118, in process_async
    async for r in iterable:
  File "/Users/ms/scrapy-1/.venv/lib/python3.9/site-packages/scrapy/spidermiddlewares/depth.py", line 35, in process_spider_output_async
    async for r in result or ():
  File "/Users/ms/scrapy-1/.venv/lib/python3.9/site-packages/scrapy/core/spidermw.py", line 118, in process_async
    async for r in iterable:
  File "/Users/ms/scrapy-1/.venv/lib/python3.9/site-packages/scrapy/spiders/crawl.py", line 124, in _parse_response
    for request_or_item in iterate_spider_output(cb_res):
  File "/Users/ms/scrapy-1/scrapy1/scrapy1/spiders/eurolux_spider.py", line 44, in parse_page
    description = bleach_html(response.css('.text-md-h6').get())
  File "/Users/ms/scrapy-1/scrapy1/scrapy1/spiders/eurolux_spider.py", line 15, in bleach_html
    cleaned_html = bleach.clean(html_string, tags=allowed_tags, strip=True)
  File "/Users/ms/scrapy-1/.venv/lib/python3.9/site-packages/bleach/__init__.py", line 82, in clean
    return cleaner.clean(text)
  File "/Users/ms/scrapy-1/.venv/lib/python3.9/site-packages/bleach/sanitizer.py", line 186, in clean
    raise TypeError(message)
TypeError: argument cannot be of 'NoneType' type, must be of text type
2023-11-13 18:46:09 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://eurolux.de/category/zubehor> (referer: https://eurolux.de/)
2023-11-13 18:46:09 [scrapy.core.scraper] ERROR: Spider error processing <GET https://eurolux.de/category/zubehor> (referer: https://eurolux.de/)
Traceback (most recent call last):
  File "/Users/ms/scrapy-1/.venv/lib/python3.9/site-packages/scrapy/utils/defer.py", line 295, in aiter_errback
    yield await it.__anext__()
  File "/Users/ms/scrapy-1/.venv/lib/python3.9/site-packages/scrapy/utils/python.py", line 374, in __anext__
    return await self.data.__anext__()
  File "/Users/ms/scrapy-1/.venv/lib/python3.9/site-packages/scrapy/utils/python.py", line 355, in _async_chain
    async for o in as_async_generator(it):
  File "/Users/ms/scrapy-1/.venv/lib/python3.9/site-packages/scrapy/utils/asyncgen.py", line 14, in as_async_generator
    async for r in it:
  File "/Users/ms/scrapy-1/.venv/lib/python3.9/site-packages/scrapy/utils/python.py", line 374, in __anext__
    return await self.data.__anext__()
  File "/Users/ms/scrapy-1/.venv/lib/python3.9/site-packages/scrapy/utils/python.py", line 355, in _async_chain
    async for o in as_async_generator(it):
  File "/Users/ms/scrapy-1/.venv/lib/python3.9/site-packages/scrapy/utils/asyncgen.py", line 14, in as_async_generator
    async for r in it:
  File "/Users/ms/scrapy-1/.venv/lib/python3.9/site-packages/scrapy/core/spidermw.py", line 118, in process_async
    async for r in iterable:
  File "/Users/ms/scrapy-1/.venv/lib/python3.9/site-packages/scrapy/spidermiddlewares/offsite.py", line 31, in process_spider_output_async
    async for r in result or ():
  File "/Users/ms/scrapy-1/.venv/lib/python3.9/site-packages/scrapy/core/spidermw.py", line 118, in process_async
    async for r in iterable:
  File "/Users/ms/scrapy-1/.venv/lib/python3.9/site-packages/scrapy/spidermiddlewares/referer.py", line 355, in process_spider_output_async
    async for r in result or ():
  File "/Users/ms/scrapy-1/.venv/lib/python3.9/site-packages/scrapy/core/spidermw.py", line 118, in process_async
    async for r in iterable:
  File "/Users/ms/scrapy-1/.venv/lib/python3.9/site-packages/scrapy/spidermiddlewares/urllength.py", line 30, in process_spider_output_async
    async for r in result or ():
  File "/Users/ms/scrapy-1/.venv/lib/python3.9/site-packages/scrapy/core/spidermw.py", line 118, in process_async
    async for r in iterable:
  File "/Users/ms/scrapy-1/.venv/lib/python3.9/site-packages/scrapy/spidermiddlewares/depth.py", line 35, in process_spider_output_async
    async for r in result or ():
  File "/Users/ms/scrapy-1/.venv/lib/python3.9/site-packages/scrapy/core/spidermw.py", line 118, in process_async
    async for r in iterable:
  File "/Users/ms/scrapy-1/.venv/lib/python3.9/site-packages/scrapy/spiders/crawl.py", line 124, in _parse_response
    for request_or_item in iterate_spider_output(cb_res):
  File "/Users/ms/scrapy-1/scrapy1/scrapy1/spiders/eurolux_spider.py", line 44, in parse_page
    description = bleach_html(response.css('.text-md-h6').get())
  File "/Users/ms/scrapy-1/scrapy1/scrapy1/spiders/eurolux_spider.py", line 15, in bleach_html
    cleaned_html = bleach.clean(html_string, tags=allowed_tags, strip=True)
  File "/Users/ms/scrapy-1/.venv/lib/python3.9/site-packages/bleach/__init__.py", line 82, in clean
    return cleaner.clean(text)
  File "/Users/ms/scrapy-1/.venv/lib/python3.9/site-packages/bleach/sanitizer.py", line 186, in clean
    raise TypeError(message)
TypeError: argument cannot be of 'NoneType' type, must be of text type
2023-11-13 18:46:09 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://eurolux.de/category/getraenke-und-technik> (referer: https://eurolux.de/)
2023-11-13 18:46:10 [scrapy.core.scraper] ERROR: Spider error processing <GET https://eurolux.de/category/getraenke-und-technik> (referer: https://eurolux.de/)
Traceback (most recent call last):
  File "/Users/ms/scrapy-1/.venv/lib/python3.9/site-packages/scrapy/utils/defer.py", line 295, in aiter_errback
    yield await it.__anext__()
  File "/Users/ms/scrapy-1/.venv/lib/python3.9/site-packages/scrapy/utils/python.py", line 374, in __anext__
    return await self.data.__anext__()
  File "/Users/ms/scrapy-1/.venv/lib/python3.9/site-packages/scrapy/utils/python.py", line 355, in _async_chain
    async for o in as_async_generator(it):
  File "/Users/ms/scrapy-1/.venv/lib/python3.9/site-packages/scrapy/utils/asyncgen.py", line 14, in as_async_generator
    async for r in it:
  File "/Users/ms/scrapy-1/.venv/lib/python3.9/site-packages/scrapy/utils/python.py", line 374, in __anext__
    return await self.data.__anext__()
  File "/Users/ms/scrapy-1/.venv/lib/python3.9/site-packages/scrapy/utils/python.py", line 355, in _async_chain
    async for o in as_async_generator(it):
  File "/Users/ms/scrapy-1/.venv/lib/python3.9/site-packages/scrapy/utils/asyncgen.py", line 14, in as_async_generator
    async for r in it:
  File "/Users/ms/scrapy-1/.venv/lib/python3.9/site-packages/scrapy/core/spidermw.py", line 118, in process_async
    async for r in iterable:
  File "/Users/ms/scrapy-1/.venv/lib/python3.9/site-packages/scrapy/spidermiddlewares/offsite.py", line 31, in process_spider_output_async
    async for r in result or ():
  File "/Users/ms/scrapy-1/.venv/lib/python3.9/site-packages/scrapy/core/spidermw.py", line 118, in process_async
    async for r in iterable:
  File "/Users/ms/scrapy-1/.venv/lib/python3.9/site-packages/scrapy/spidermiddlewares/referer.py", line 355, in process_spider_output_async
    async for r in result or ():
  File "/Users/ms/scrapy-1/.venv/lib/python3.9/site-packages/scrapy/core/spidermw.py", line 118, in process_async
    async for r in iterable:
  File "/Users/ms/scrapy-1/.venv/lib/python3.9/site-packages/scrapy/spidermiddlewares/urllength.py", line 30, in process_spider_output_async
    async for r in result or ():
  File "/Users/ms/scrapy-1/.venv/lib/python3.9/site-packages/scrapy/core/spidermw.py", line 118, in process_async
    async for r in iterable:
  File "/Users/ms/scrapy-1/.venv/lib/python3.9/site-packages/scrapy/spidermiddlewares/depth.py", line 35, in process_spider_output_async
    async for r in result or ():
  File "/Users/ms/scrapy-1/.venv/lib/python3.9/site-packages/scrapy/core/spidermw.py", line 118, in process_async
    async for r in iterable:
  File "/Users/ms/scrapy-1/.venv/lib/python3.9/site-packages/scrapy/spiders/crawl.py", line 124, in _parse_response
    for request_or_item in iterate_spider_output(cb_res):
  File "/Users/ms/scrapy-1/scrapy1/scrapy1/spiders/eurolux_spider.py", line 44, in parse_page
    description = bleach_html(response.css('.text-md-h6').get())
  File "/Users/ms/scrapy-1/scrapy1/scrapy1/spiders/eurolux_spider.py", line 15, in bleach_html
    cleaned_html = bleach.clean(html_string, tags=allowed_tags, strip=True)
  File "/Users/ms/scrapy-1/.venv/lib/python3.9/site-packages/bleach/__init__.py", line 82, in clean
    return cleaner.clean(text)
  File "/Users/ms/scrapy-1/.venv/lib/python3.9/site-packages/bleach/sanitizer.py", line 186, in clean
    raise TypeError(message)
TypeError: argument cannot be of 'NoneType' type, must be of text type
2023-11-13 18:46:10 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://eurolux.de/category/dichtungen> (referer: https://eurolux.de/)
2023-11-13 18:46:10 [scrapy.core.scraper] ERROR: Spider error processing <GET https://eurolux.de/category/dichtungen> (referer: https://eurolux.de/)
Traceback (most recent call last):
  File "/Users/ms/scrapy-1/.venv/lib/python3.9/site-packages/scrapy/utils/defer.py", line 295, in aiter_errback
    yield await it.__anext__()
  File "/Users/ms/scrapy-1/.venv/lib/python3.9/site-packages/scrapy/utils/python.py", line 374, in __anext__
    return await self.data.__anext__()
  File "/Users/ms/scrapy-1/.venv/lib/python3.9/site-packages/scrapy/utils/python.py", line 355, in _async_chain
    async for o in as_async_generator(it):
  File "/Users/ms/scrapy-1/.venv/lib/python3.9/site-packages/scrapy/utils/asyncgen.py", line 14, in as_async_generator
    async for r in it:
  File "/Users/ms/scrapy-1/.venv/lib/python3.9/site-packages/scrapy/utils/python.py", line 374, in __anext__
    return await self.data.__anext__()
  File "/Users/ms/scrapy-1/.venv/lib/python3.9/site-packages/scrapy/utils/python.py", line 355, in _async_chain
    async for o in as_async_generator(it):
  File "/Users/ms/scrapy-1/.venv/lib/python3.9/site-packages/scrapy/utils/asyncgen.py", line 14, in as_async_generator
    async for r in it:
  File "/Users/ms/scrapy-1/.venv/lib/python3.9/site-packages/scrapy/core/spidermw.py", line 118, in process_async
    async for r in iterable:
  File "/Users/ms/scrapy-1/.venv/lib/python3.9/site-packages/scrapy/spidermiddlewares/offsite.py", line 31, in process_spider_output_async
    async for r in result or ():
  File "/Users/ms/scrapy-1/.venv/lib/python3.9/site-packages/scrapy/core/spidermw.py", line 118, in process_async
    async for r in iterable:
  File "/Users/ms/scrapy-1/.venv/lib/python3.9/site-packages/scrapy/spidermiddlewares/referer.py", line 355, in process_spider_output_async
    async for r in result or ():
  File "/Users/ms/scrapy-1/.venv/lib/python3.9/site-packages/scrapy/core/spidermw.py", line 118, in process_async
    async for r in iterable:
  File "/Users/ms/scrapy-1/.venv/lib/python3.9/site-packages/scrapy/spidermiddlewares/urllength.py", line 30, in process_spider_output_async
    async for r in result or ():
  File "/Users/ms/scrapy-1/.venv/lib/python3.9/site-packages/scrapy/core/spidermw.py", line 118, in process_async
    async for r in iterable:
  File "/Users/ms/scrapy-1/.venv/lib/python3.9/site-packages/scrapy/spidermiddlewares/depth.py", line 35, in process_spider_output_async
    async for r in result or ():
  File "/Users/ms/scrapy-1/.venv/lib/python3.9/site-packages/scrapy/core/spidermw.py", line 118, in process_async
    async for r in iterable:
  File "/Users/ms/scrapy-1/.venv/lib/python3.9/site-packages/scrapy/spiders/crawl.py", line 124, in _parse_response
    for request_or_item in iterate_spider_output(cb_res):
  File "/Users/ms/scrapy-1/scrapy1/scrapy1/spiders/eurolux_spider.py", line 44, in parse_page
    description = bleach_html(response.css('.text-md-h6').get())
  File "/Users/ms/scrapy-1/scrapy1/scrapy1/spiders/eurolux_spider.py", line 15, in bleach_html
    cleaned_html = bleach.clean(html_string, tags=allowed_tags, strip=True)
  File "/Users/ms/scrapy-1/.venv/lib/python3.9/site-packages/bleach/__init__.py", line 82, in clean
    return cleaner.clean(text)
  File "/Users/ms/scrapy-1/.venv/lib/python3.9/site-packages/bleach/sanitizer.py", line 186, in clean
    raise TypeError(message)
TypeError: argument cannot be of 'NoneType' type, must be of text type
2023-11-13 18:46:10 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://eurolux.de/category/sonstiges> (referer: https://eurolux.de/)
2023-11-13 18:46:10 [scrapy.core.scraper] ERROR: Spider error processing <GET https://eurolux.de/category/sonstiges> (referer: https://eurolux.de/)
Traceback (most recent call last):
  File "/Users/ms/scrapy-1/.venv/lib/python3.9/site-packages/scrapy/utils/defer.py", line 295, in aiter_errback
    yield await it.__anext__()
  File "/Users/ms/scrapy-1/.venv/lib/python3.9/site-packages/scrapy/utils/python.py", line 374, in __anext__
    return await self.data.__anext__()
  File "/Users/ms/scrapy-1/.venv/lib/python3.9/site-packages/scrapy/utils/python.py", line 355, in _async_chain
    async for o in as_async_generator(it):
  File "/Users/ms/scrapy-1/.venv/lib/python3.9/site-packages/scrapy/utils/asyncgen.py", line 14, in as_async_generator
    async for r in it:
  File "/Users/ms/scrapy-1/.venv/lib/python3.9/site-packages/scrapy/utils/python.py", line 374, in __anext__
    return await self.data.__anext__()
  File "/Users/ms/scrapy-1/.venv/lib/python3.9/site-packages/scrapy/utils/python.py", line 355, in _async_chain
    async for o in as_async_generator(it):
  File "/Users/ms/scrapy-1/.venv/lib/python3.9/site-packages/scrapy/utils/asyncgen.py", line 14, in as_async_generator
    async for r in it:
  File "/Users/ms/scrapy-1/.venv/lib/python3.9/site-packages/scrapy/core/spidermw.py", line 118, in process_async
    async for r in iterable:
  File "/Users/ms/scrapy-1/.venv/lib/python3.9/site-packages/scrapy/spidermiddlewares/offsite.py", line 31, in process_spider_output_async
    async for r in result or ():
  File "/Users/ms/scrapy-1/.venv/lib/python3.9/site-packages/scrapy/core/spidermw.py", line 118, in process_async
    async for r in iterable:
  File "/Users/ms/scrapy-1/.venv/lib/python3.9/site-packages/scrapy/spidermiddlewares/referer.py", line 355, in process_spider_output_async
    async for r in result or ():
  File "/Users/ms/scrapy-1/.venv/lib/python3.9/site-packages/scrapy/core/spidermw.py", line 118, in process_async
    async for r in iterable:
  File "/Users/ms/scrapy-1/.venv/lib/python3.9/site-packages/scrapy/spidermiddlewares/urllength.py", line 30, in process_spider_output_async
    async for r in result or ():
  File "/Users/ms/scrapy-1/.venv/lib/python3.9/site-packages/scrapy/core/spidermw.py", line 118, in process_async
    async for r in iterable:
  File "/Users/ms/scrapy-1/.venv/lib/python3.9/site-packages/scrapy/spidermiddlewares/depth.py", line 35, in process_spider_output_async
    async for r in result or ():
  File "/Users/ms/scrapy-1/.venv/lib/python3.9/site-packages/scrapy/core/spidermw.py", line 118, in process_async
    async for r in iterable:
  File "/Users/ms/scrapy-1/.venv/lib/python3.9/site-packages/scrapy/spiders/crawl.py", line 124, in _parse_response
    for request_or_item in iterate_spider_output(cb_res):
  File "/Users/ms/scrapy-1/scrapy1/scrapy1/spiders/eurolux_spider.py", line 44, in parse_page
    description = bleach_html(response.css('.text-md-h6').get())
  File "/Users/ms/scrapy-1/scrapy1/scrapy1/spiders/eurolux_spider.py", line 15, in bleach_html
    cleaned_html = bleach.clean(html_string, tags=allowed_tags, strip=True)
  File "/Users/ms/scrapy-1/.venv/lib/python3.9/site-packages/bleach/__init__.py", line 82, in clean
    return cleaner.clean(text)
  File "/Users/ms/scrapy-1/.venv/lib/python3.9/site-packages/bleach/sanitizer.py", line 186, in clean
    raise TypeError(message)
TypeError: argument cannot be of 'NoneType' type, must be of text type
2023-11-13 18:46:10 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://eurolux.de/category/ersatzteile> (referer: https://eurolux.de/)
2023-11-13 18:46:11 [scrapy.core.scraper] ERROR: Spider error processing <GET https://eurolux.de/category/ersatzteile> (referer: https://eurolux.de/)
Traceback (most recent call last):
  File "/Users/ms/scrapy-1/.venv/lib/python3.9/site-packages/scrapy/utils/defer.py", line 295, in aiter_errback
    yield await it.__anext__()
  File "/Users/ms/scrapy-1/.venv/lib/python3.9/site-packages/scrapy/utils/python.py", line 374, in __anext__
    return await self.data.__anext__()
  File "/Users/ms/scrapy-1/.venv/lib/python3.9/site-packages/scrapy/utils/python.py", line 355, in _async_chain
    async for o in as_async_generator(it):
  File "/Users/ms/scrapy-1/.venv/lib/python3.9/site-packages/scrapy/utils/asyncgen.py", line 14, in as_async_generator
    async for r in it:
  File "/Users/ms/scrapy-1/.venv/lib/python3.9/site-packages/scrapy/utils/python.py", line 374, in __anext__
    return await self.data.__anext__()
  File "/Users/ms/scrapy-1/.venv/lib/python3.9/site-packages/scrapy/utils/python.py", line 355, in _async_chain
    async for o in as_async_generator(it):
  File "/Users/ms/scrapy-1/.venv/lib/python3.9/site-packages/scrapy/utils/asyncgen.py", line 14, in as_async_generator
    async for r in it:
  File "/Users/ms/scrapy-1/.venv/lib/python3.9/site-packages/scrapy/core/spidermw.py", line 118, in process_async
    async for r in iterable:
  File "/Users/ms/scrapy-1/.venv/lib/python3.9/site-packages/scrapy/spidermiddlewares/offsite.py", line 31, in process_spider_output_async
    async for r in result or ():
  File "/Users/ms/scrapy-1/.venv/lib/python3.9/site-packages/scrapy/core/spidermw.py", line 118, in process_async
    async for r in iterable:
  File "/Users/ms/scrapy-1/.venv/lib/python3.9/site-packages/scrapy/spidermiddlewares/referer.py", line 355, in process_spider_output_async
    async for r in result or ():
  File "/Users/ms/scrapy-1/.venv/lib/python3.9/site-packages/scrapy/core/spidermw.py", line 118, in process_async
    async for r in iterable:
  File "/Users/ms/scrapy-1/.venv/lib/python3.9/site-packages/scrapy/spidermiddlewares/urllength.py", line 30, in process_spider_output_async
    async for r in result or ():
  File "/Users/ms/scrapy-1/.venv/lib/python3.9/site-packages/scrapy/core/spidermw.py", line 118, in process_async
    async for r in iterable:
  File "/Users/ms/scrapy-1/.venv/lib/python3.9/site-packages/scrapy/spidermiddlewares/depth.py", line 35, in process_spider_output_async
    async for r in result or ():
  File "/Users/ms/scrapy-1/.venv/lib/python3.9/site-packages/scrapy/core/spidermw.py", line 118, in process_async
    async for r in iterable:
  File "/Users/ms/scrapy-1/.venv/lib/python3.9/site-packages/scrapy/spiders/crawl.py", line 124, in _parse_response
    for request_or_item in iterate_spider_output(cb_res):
  File "/Users/ms/scrapy-1/scrapy1/scrapy1/spiders/eurolux_spider.py", line 44, in parse_page
    description = bleach_html(response.css('.text-md-h6').get())
  File "/Users/ms/scrapy-1/scrapy1/scrapy1/spiders/eurolux_spider.py", line 15, in bleach_html
    cleaned_html = bleach.clean(html_string, tags=allowed_tags, strip=True)
  File "/Users/ms/scrapy-1/.venv/lib/python3.9/site-packages/bleach/__init__.py", line 82, in clean
    return cleaner.clean(text)
  File "/Users/ms/scrapy-1/.venv/lib/python3.9/site-packages/bleach/sanitizer.py", line 186, in clean
    raise TypeError(message)
TypeError: argument cannot be of 'NoneType' type, must be of text type
2023-11-13 18:46:12 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://eurolux.de/category/foerderbaender> (referer: https://eurolux.de/)
2023-11-13 18:46:13 [scrapy.core.scraper] ERROR: Spider error processing <GET https://eurolux.de/category/foerderbaender> (referer: https://eurolux.de/)
Traceback (most recent call last):
  File "/Users/ms/scrapy-1/.venv/lib/python3.9/site-packages/scrapy/utils/defer.py", line 295, in aiter_errback
    yield await it.__anext__()
  File "/Users/ms/scrapy-1/.venv/lib/python3.9/site-packages/scrapy/utils/python.py", line 374, in __anext__
    return await self.data.__anext__()
  File "/Users/ms/scrapy-1/.venv/lib/python3.9/site-packages/scrapy/utils/python.py", line 355, in _async_chain
    async for o in as_async_generator(it):
  File "/Users/ms/scrapy-1/.venv/lib/python3.9/site-packages/scrapy/utils/asyncgen.py", line 14, in as_async_generator
    async for r in it:
  File "/Users/ms/scrapy-1/.venv/lib/python3.9/site-packages/scrapy/utils/python.py", line 374, in __anext__
    return await self.data.__anext__()
  File "/Users/ms/scrapy-1/.venv/lib/python3.9/site-packages/scrapy/utils/python.py", line 355, in _async_chain
    async for o in as_async_generator(it):
  File "/Users/ms/scrapy-1/.venv/lib/python3.9/site-packages/scrapy/utils/asyncgen.py", line 14, in as_async_generator
    async for r in it:
  File "/Users/ms/scrapy-1/.venv/lib/python3.9/site-packages/scrapy/core/spidermw.py", line 118, in process_async
    async for r in iterable:
  File "/Users/ms/scrapy-1/.venv/lib/python3.9/site-packages/scrapy/spidermiddlewares/offsite.py", line 31, in process_spider_output_async
    async for r in result or ():
  File "/Users/ms/scrapy-1/.venv/lib/python3.9/site-packages/scrapy/core/spidermw.py", line 118, in process_async
    async for r in iterable:
  File "/Users/ms/scrapy-1/.venv/lib/python3.9/site-packages/scrapy/spidermiddlewares/referer.py", line 355, in process_spider_output_async
    async for r in result or ():
  File "/Users/ms/scrapy-1/.venv/lib/python3.9/site-packages/scrapy/core/spidermw.py", line 118, in process_async
    async for r in iterable:
  File "/Users/ms/scrapy-1/.venv/lib/python3.9/site-packages/scrapy/spidermiddlewares/urllength.py", line 30, in process_spider_output_async
    async for r in result or ():
  File "/Users/ms/scrapy-1/.venv/lib/python3.9/site-packages/scrapy/core/spidermw.py", line 118, in process_async
    async for r in iterable:
  File "/Users/ms/scrapy-1/.venv/lib/python3.9/site-packages/scrapy/spidermiddlewares/depth.py", line 35, in process_spider_output_async
    async for r in result or ():
  File "/Users/ms/scrapy-1/.venv/lib/python3.9/site-packages/scrapy/core/spidermw.py", line 118, in process_async
    async for r in iterable:
  File "/Users/ms/scrapy-1/.venv/lib/python3.9/site-packages/scrapy/spiders/crawl.py", line 124, in _parse_response
    for request_or_item in iterate_spider_output(cb_res):
  File "/Users/ms/scrapy-1/scrapy1/scrapy1/spiders/eurolux_spider.py", line 44, in parse_page
    description = bleach_html(response.css('.text-md-h6').get())
  File "/Users/ms/scrapy-1/scrapy1/scrapy1/spiders/eurolux_spider.py", line 15, in bleach_html
    cleaned_html = bleach.clean(html_string, tags=allowed_tags, strip=True)
  File "/Users/ms/scrapy-1/.venv/lib/python3.9/site-packages/bleach/__init__.py", line 82, in clean
    return cleaner.clean(text)
  File "/Users/ms/scrapy-1/.venv/lib/python3.9/site-packages/bleach/sanitizer.py", line 186, in clean
    raise TypeError(message)
TypeError: argument cannot be of 'NoneType' type, must be of text type
2023-11-13 18:46:15 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://eurolux.de/category/kolben-pumpen> (referer: https://eurolux.de/)
2023-11-13 18:46:15 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://eurolux.de/category/excenter-schnecken-pumpen> (referer: https://eurolux.de/)
2023-11-13 18:46:15 [scrapy.core.scraper] ERROR: Spider error processing <GET https://eurolux.de/category/kolben-pumpen> (referer: https://eurolux.de/)
Traceback (most recent call last):
  File "/Users/ms/scrapy-1/.venv/lib/python3.9/site-packages/scrapy/utils/defer.py", line 295, in aiter_errback
    yield await it.__anext__()
  File "/Users/ms/scrapy-1/.venv/lib/python3.9/site-packages/scrapy/utils/python.py", line 374, in __anext__
    return await self.data.__anext__()
  File "/Users/ms/scrapy-1/.venv/lib/python3.9/site-packages/scrapy/utils/python.py", line 355, in _async_chain
    async for o in as_async_generator(it):
  File "/Users/ms/scrapy-1/.venv/lib/python3.9/site-packages/scrapy/utils/asyncgen.py", line 14, in as_async_generator
    async for r in it:
  File "/Users/ms/scrapy-1/.venv/lib/python3.9/site-packages/scrapy/utils/python.py", line 374, in __anext__
    return await self.data.__anext__()
  File "/Users/ms/scrapy-1/.venv/lib/python3.9/site-packages/scrapy/utils/python.py", line 355, in _async_chain
    async for o in as_async_generator(it):
  File "/Users/ms/scrapy-1/.venv/lib/python3.9/site-packages/scrapy/utils/asyncgen.py", line 14, in as_async_generator
    async for r in it:
  File "/Users/ms/scrapy-1/.venv/lib/python3.9/site-packages/scrapy/core/spidermw.py", line 118, in process_async
    async for r in iterable:
  File "/Users/ms/scrapy-1/.venv/lib/python3.9/site-packages/scrapy/spidermiddlewares/offsite.py", line 31, in process_spider_output_async
    async for r in result or ():
  File "/Users/ms/scrapy-1/.venv/lib/python3.9/site-packages/scrapy/core/spidermw.py", line 118, in process_async
    async for r in iterable:
  File "/Users/ms/scrapy-1/.venv/lib/python3.9/site-packages/scrapy/spidermiddlewares/referer.py", line 355, in process_spider_output_async
    async for r in result or ():
  File "/Users/ms/scrapy-1/.venv/lib/python3.9/site-packages/scrapy/core/spidermw.py", line 118, in process_async
    async for r in iterable:
  File "/Users/ms/scrapy-1/.venv/lib/python3.9/site-packages/scrapy/spidermiddlewares/urllength.py", line 30, in process_spider_output_async
    async for r in result or ():
  File "/Users/ms/scrapy-1/.venv/lib/python3.9/site-packages/scrapy/core/spidermw.py", line 118, in process_async
    async for r in iterable:
  File "/Users/ms/scrapy-1/.venv/lib/python3.9/site-packages/scrapy/spidermiddlewares/depth.py", line 35, in process_spider_output_async
    async for r in result or ():
  File "/Users/ms/scrapy-1/.venv/lib/python3.9/site-packages/scrapy/core/spidermw.py", line 118, in process_async
    async for r in iterable:
  File "/Users/ms/scrapy-1/.venv/lib/python3.9/site-packages/scrapy/spiders/crawl.py", line 124, in _parse_response
    for request_or_item in iterate_spider_output(cb_res):
  File "/Users/ms/scrapy-1/scrapy1/scrapy1/spiders/eurolux_spider.py", line 44, in parse_page
    description = bleach_html(response.css('.text-md-h6').get())
  File "/Users/ms/scrapy-1/scrapy1/scrapy1/spiders/eurolux_spider.py", line 15, in bleach_html
    cleaned_html = bleach.clean(html_string, tags=allowed_tags, strip=True)
  File "/Users/ms/scrapy-1/.venv/lib/python3.9/site-packages/bleach/__init__.py", line 82, in clean
    return cleaner.clean(text)
  File "/Users/ms/scrapy-1/.venv/lib/python3.9/site-packages/bleach/sanitizer.py", line 186, in clean
    raise TypeError(message)
TypeError: argument cannot be of 'NoneType' type, must be of text type
2023-11-13 18:46:15 [scrapy.core.scraper] ERROR: Spider error processing <GET https://eurolux.de/category/excenter-schnecken-pumpen> (referer: https://eurolux.de/)
Traceback (most recent call last):
  File "/Users/ms/scrapy-1/.venv/lib/python3.9/site-packages/scrapy/utils/defer.py", line 295, in aiter_errback
    yield await it.__anext__()
  File "/Users/ms/scrapy-1/.venv/lib/python3.9/site-packages/scrapy/utils/python.py", line 374, in __anext__
    return await self.data.__anext__()
  File "/Users/ms/scrapy-1/.venv/lib/python3.9/site-packages/scrapy/utils/python.py", line 355, in _async_chain
    async for o in as_async_generator(it):
  File "/Users/ms/scrapy-1/.venv/lib/python3.9/site-packages/scrapy/utils/asyncgen.py", line 14, in as_async_generator
    async for r in it:
  File "/Users/ms/scrapy-1/.venv/lib/python3.9/site-packages/scrapy/utils/python.py", line 374, in __anext__
    return await self.data.__anext__()
  File "/Users/ms/scrapy-1/.venv/lib/python3.9/site-packages/scrapy/utils/python.py", line 355, in _async_chain
    async for o in as_async_generator(it):
  File "/Users/ms/scrapy-1/.venv/lib/python3.9/site-packages/scrapy/utils/asyncgen.py", line 14, in as_async_generator
    async for r in it:
  File "/Users/ms/scrapy-1/.venv/lib/python3.9/site-packages/scrapy/core/spidermw.py", line 118, in process_async
    async for r in iterable:
  File "/Users/ms/scrapy-1/.venv/lib/python3.9/site-packages/scrapy/spidermiddlewares/offsite.py", line 31, in process_spider_output_async
    async for r in result or ():
  File "/Users/ms/scrapy-1/.venv/lib/python3.9/site-packages/scrapy/core/spidermw.py", line 118, in process_async
    async for r in iterable:
  File "/Users/ms/scrapy-1/.venv/lib/python3.9/site-packages/scrapy/spidermiddlewares/referer.py", line 355, in process_spider_output_async
    async for r in result or ():
  File "/Users/ms/scrapy-1/.venv/lib/python3.9/site-packages/scrapy/core/spidermw.py", line 118, in process_async
    async for r in iterable:
  File "/Users/ms/scrapy-1/.venv/lib/python3.9/site-packages/scrapy/spidermiddlewares/urllength.py", line 30, in process_spider_output_async
    async for r in result or ():
  File "/Users/ms/scrapy-1/.venv/lib/python3.9/site-packages/scrapy/core/spidermw.py", line 118, in process_async
    async for r in iterable:
  File "/Users/ms/scrapy-1/.venv/lib/python3.9/site-packages/scrapy/spidermiddlewares/depth.py", line 35, in process_spider_output_async
    async for r in result or ():
  File "/Users/ms/scrapy-1/.venv/lib/python3.9/site-packages/scrapy/core/spidermw.py", line 118, in process_async
    async for r in iterable:
  File "/Users/ms/scrapy-1/.venv/lib/python3.9/site-packages/scrapy/spiders/crawl.py", line 124, in _parse_response
    for request_or_item in iterate_spider_output(cb_res):
  File "/Users/ms/scrapy-1/scrapy1/scrapy1/spiders/eurolux_spider.py", line 44, in parse_page
    description = bleach_html(response.css('.text-md-h6').get())
  File "/Users/ms/scrapy-1/scrapy1/scrapy1/spiders/eurolux_spider.py", line 15, in bleach_html
    cleaned_html = bleach.clean(html_string, tags=allowed_tags, strip=True)
  File "/Users/ms/scrapy-1/.venv/lib/python3.9/site-packages/bleach/__init__.py", line 82, in clean
    return cleaner.clean(text)
  File "/Users/ms/scrapy-1/.venv/lib/python3.9/site-packages/bleach/sanitizer.py", line 186, in clean
    raise TypeError(message)
TypeError: argument cannot be of 'NoneType' type, must be of text type
2023-11-13 18:46:15 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://eurolux.de/category/pumpen-sonstiges> (referer: https://eurolux.de/)
2023-11-13 18:46:15 [scrapy.core.scraper] ERROR: Spider error processing <GET https://eurolux.de/category/pumpen-sonstiges> (referer: https://eurolux.de/)
Traceback (most recent call last):
  File "/Users/ms/scrapy-1/.venv/lib/python3.9/site-packages/scrapy/utils/defer.py", line 295, in aiter_errback
    yield await it.__anext__()
  File "/Users/ms/scrapy-1/.venv/lib/python3.9/site-packages/scrapy/utils/python.py", line 374, in __anext__
    return await self.data.__anext__()
  File "/Users/ms/scrapy-1/.venv/lib/python3.9/site-packages/scrapy/utils/python.py", line 355, in _async_chain
    async for o in as_async_generator(it):
  File "/Users/ms/scrapy-1/.venv/lib/python3.9/site-packages/scrapy/utils/asyncgen.py", line 14, in as_async_generator
    async for r in it:
  File "/Users/ms/scrapy-1/.venv/lib/python3.9/site-packages/scrapy/utils/python.py", line 374, in __anext__
    return await self.data.__anext__()
  File "/Users/ms/scrapy-1/.venv/lib/python3.9/site-packages/scrapy/utils/python.py", line 355, in _async_chain
    async for o in as_async_generator(it):
  File "/Users/ms/scrapy-1/.venv/lib/python3.9/site-packages/scrapy/utils/asyncgen.py", line 14, in as_async_generator
    async for r in it:
  File "/Users/ms/scrapy-1/.venv/lib/python3.9/site-packages/scrapy/core/spidermw.py", line 118, in process_async
    async for r in iterable:
  File "/Users/ms/scrapy-1/.venv/lib/python3.9/site-packages/scrapy/spidermiddlewares/offsite.py", line 31, in process_spider_output_async
    async for r in result or ():
  File "/Users/ms/scrapy-1/.venv/lib/python3.9/site-packages/scrapy/core/spidermw.py", line 118, in process_async
    async for r in iterable:
  File "/Users/ms/scrapy-1/.venv/lib/python3.9/site-packages/scrapy/spidermiddlewares/referer.py", line 355, in process_spider_output_async
    async for r in result or ():
  File "/Users/ms/scrapy-1/.venv/lib/python3.9/site-packages/scrapy/core/spidermw.py", line 118, in process_async
    async for r in iterable:
  File "/Users/ms/scrapy-1/.venv/lib/python3.9/site-packages/scrapy/spidermiddlewares/urllength.py", line 30, in process_spider_output_async
    async for r in result or ():
  File "/Users/ms/scrapy-1/.venv/lib/python3.9/site-packages/scrapy/core/spidermw.py", line 118, in process_async
    async for r in iterable:
  File "/Users/ms/scrapy-1/.venv/lib/python3.9/site-packages/scrapy/spidermiddlewares/depth.py", line 35, in process_spider_output_async
    async for r in result or ():
  File "/Users/ms/scrapy-1/.venv/lib/python3.9/site-packages/scrapy/core/spidermw.py", line 118, in process_async
    async for r in iterable:
  File "/Users/ms/scrapy-1/.venv/lib/python3.9/site-packages/scrapy/spiders/crawl.py", line 124, in _parse_response
    for request_or_item in iterate_spider_output(cb_res):
  File "/Users/ms/scrapy-1/scrapy1/scrapy1/spiders/eurolux_spider.py", line 44, in parse_page
    description = bleach_html(response.css('.text-md-h6').get())
  File "/Users/ms/scrapy-1/scrapy1/scrapy1/spiders/eurolux_spider.py", line 15, in bleach_html
    cleaned_html = bleach.clean(html_string, tags=allowed_tags, strip=True)
  File "/Users/ms/scrapy-1/.venv/lib/python3.9/site-packages/bleach/__init__.py", line 82, in clean
    return cleaner.clean(text)
  File "/Users/ms/scrapy-1/.venv/lib/python3.9/site-packages/bleach/sanitizer.py", line 186, in clean
    raise TypeError(message)
TypeError: argument cannot be of 'NoneType' type, must be of text type
2023-11-13 18:46:16 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://eurolux.de/category/filter-sonstiges> (referer: https://eurolux.de/)
2023-11-13 18:46:16 [scrapy.core.scraper] ERROR: Spider error processing <GET https://eurolux.de/category/filter-sonstiges> (referer: https://eurolux.de/)
Traceback (most recent call last):
  File "/Users/ms/scrapy-1/.venv/lib/python3.9/site-packages/scrapy/utils/defer.py", line 295, in aiter_errback
    yield await it.__anext__()
  File "/Users/ms/scrapy-1/.venv/lib/python3.9/site-packages/scrapy/utils/python.py", line 374, in __anext__
    return await self.data.__anext__()
  File "/Users/ms/scrapy-1/.venv/lib/python3.9/site-packages/scrapy/utils/python.py", line 355, in _async_chain
    async for o in as_async_generator(it):
  File "/Users/ms/scrapy-1/.venv/lib/python3.9/site-packages/scrapy/utils/asyncgen.py", line 14, in as_async_generator
    async for r in it:
  File "/Users/ms/scrapy-1/.venv/lib/python3.9/site-packages/scrapy/utils/python.py", line 374, in __anext__
    return await self.data.__anext__()
  File "/Users/ms/scrapy-1/.venv/lib/python3.9/site-packages/scrapy/utils/python.py", line 355, in _async_chain
    async for o in as_async_generator(it):
  File "/Users/ms/scrapy-1/.venv/lib/python3.9/site-packages/scrapy/utils/asyncgen.py", line 14, in as_async_generator
    async for r in it:
  File "/Users/ms/scrapy-1/.venv/lib/python3.9/site-packages/scrapy/core/spidermw.py", line 118, in process_async
    async for r in iterable:
  File "/Users/ms/scrapy-1/.venv/lib/python3.9/site-packages/scrapy/spidermiddlewares/offsite.py", line 31, in process_spider_output_async
    async for r in result or ():
  File "/Users/ms/scrapy-1/.venv/lib/python3.9/site-packages/scrapy/core/spidermw.py", line 118, in process_async
    async for r in iterable:
  File "/Users/ms/scrapy-1/.venv/lib/python3.9/site-packages/scrapy/spidermiddlewares/referer.py", line 355, in process_spider_output_async
    async for r in result or ():
  File "/Users/ms/scrapy-1/.venv/lib/python3.9/site-packages/scrapy/core/spidermw.py", line 118, in process_async
    async for r in iterable:
  File "/Users/ms/scrapy-1/.venv/lib/python3.9/site-packages/scrapy/spidermiddlewares/urllength.py", line 30, in process_spider_output_async
    async for r in result or ():
  File "/Users/ms/scrapy-1/.venv/lib/python3.9/site-packages/scrapy/core/spidermw.py", line 118, in process_async
    async for r in iterable:
  File "/Users/ms/scrapy-1/.venv/lib/python3.9/site-packages/scrapy/spidermiddlewares/depth.py", line 35, in process_spider_output_async
    async for r in result or ():
  File "/Users/ms/scrapy-1/.venv/lib/python3.9/site-packages/scrapy/core/spidermw.py", line 118, in process_async
    async for r in iterable:
  File "/Users/ms/scrapy-1/.venv/lib/python3.9/site-packages/scrapy/spiders/crawl.py", line 124, in _parse_response
    for request_or_item in iterate_spider_output(cb_res):
  File "/Users/ms/scrapy-1/scrapy1/scrapy1/spiders/eurolux_spider.py", line 44, in parse_page
    description = bleach_html(response.css('.text-md-h6').get())
  File "/Users/ms/scrapy-1/scrapy1/scrapy1/spiders/eurolux_spider.py", line 15, in bleach_html
    cleaned_html = bleach.clean(html_string, tags=allowed_tags, strip=True)
  File "/Users/ms/scrapy-1/.venv/lib/python3.9/site-packages/bleach/__init__.py", line 82, in clean
    return cleaner.clean(text)
  File "/Users/ms/scrapy-1/.venv/lib/python3.9/site-packages/bleach/sanitizer.py", line 186, in clean
    raise TypeError(message)
TypeError: argument cannot be of 'NoneType' type, must be of text type
2023-11-13 18:46:16 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://eurolux.de/category/kreisel-pumpen> (referer: https://eurolux.de/)
2023-11-13 18:46:16 [scrapy.core.scraper] ERROR: Spider error processing <GET https://eurolux.de/category/kreisel-pumpen> (referer: https://eurolux.de/)
Traceback (most recent call last):
  File "/Users/ms/scrapy-1/.venv/lib/python3.9/site-packages/scrapy/utils/defer.py", line 295, in aiter_errback
    yield await it.__anext__()
  File "/Users/ms/scrapy-1/.venv/lib/python3.9/site-packages/scrapy/utils/python.py", line 374, in __anext__
    return await self.data.__anext__()
  File "/Users/ms/scrapy-1/.venv/lib/python3.9/site-packages/scrapy/utils/python.py", line 355, in _async_chain
    async for o in as_async_generator(it):
  File "/Users/ms/scrapy-1/.venv/lib/python3.9/site-packages/scrapy/utils/asyncgen.py", line 14, in as_async_generator
    async for r in it:
  File "/Users/ms/scrapy-1/.venv/lib/python3.9/site-packages/scrapy/utils/python.py", line 374, in __anext__
    return await self.data.__anext__()
  File "/Users/ms/scrapy-1/.venv/lib/python3.9/site-packages/scrapy/utils/python.py", line 355, in _async_chain
    async for o in as_async_generator(it):
  File "/Users/ms/scrapy-1/.venv/lib/python3.9/site-packages/scrapy/utils/asyncgen.py", line 14, in as_async_generator
    async for r in it:
  File "/Users/ms/scrapy-1/.venv/lib/python3.9/site-packages/scrapy/core/spidermw.py", line 118, in process_async
    async for r in iterable:
  File "/Users/ms/scrapy-1/.venv/lib/python3.9/site-packages/scrapy/spidermiddlewares/offsite.py", line 31, in process_spider_output_async
    async for r in result or ():
  File "/Users/ms/scrapy-1/.venv/lib/python3.9/site-packages/scrapy/core/spidermw.py", line 118, in process_async
    async for r in iterable:
  File "/Users/ms/scrapy-1/.venv/lib/python3.9/site-packages/scrapy/spidermiddlewares/referer.py", line 355, in process_spider_output_async
    async for r in result or ():
  File "/Users/ms/scrapy-1/.venv/lib/python3.9/site-packages/scrapy/core/spidermw.py", line 118, in process_async
    async for r in iterable:
  File "/Users/ms/scrapy-1/.venv/lib/python3.9/site-packages/scrapy/spidermiddlewares/urllength.py", line 30, in process_spider_output_async
    async for r in result or ():
  File "/Users/ms/scrapy-1/.venv/lib/python3.9/site-packages/scrapy/core/spidermw.py", line 118, in process_async
    async for r in iterable:
  File "/Users/ms/scrapy-1/.venv/lib/python3.9/site-packages/scrapy/spidermiddlewares/depth.py", line 35, in process_spider_output_async
    async for r in result or ():
  File "/Users/ms/scrapy-1/.venv/lib/python3.9/site-packages/scrapy/core/spidermw.py", line 118, in process_async
    async for r in iterable:
  File "/Users/ms/scrapy-1/.venv/lib/python3.9/site-packages/scrapy/spiders/crawl.py", line 124, in _parse_response
    for request_or_item in iterate_spider_output(cb_res):
  File "/Users/ms/scrapy-1/scrapy1/scrapy1/spiders/eurolux_spider.py", line 44, in parse_page
    description = bleach_html(response.css('.text-md-h6').get())
  File "/Users/ms/scrapy-1/scrapy1/scrapy1/spiders/eurolux_spider.py", line 15, in bleach_html
    cleaned_html = bleach.clean(html_string, tags=allowed_tags, strip=True)
  File "/Users/ms/scrapy-1/.venv/lib/python3.9/site-packages/bleach/__init__.py", line 82, in clean
    return cleaner.clean(text)
  File "/Users/ms/scrapy-1/.venv/lib/python3.9/site-packages/bleach/sanitizer.py", line 186, in clean
    raise TypeError(message)
TypeError: argument cannot be of 'NoneType' type, must be of text type
2023-11-13 18:46:17 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://eurolux.de/category/pumpen> (referer: https://eurolux.de/)
2023-11-13 18:46:17 [scrapy.core.scraper] ERROR: Spider error processing <GET https://eurolux.de/category/pumpen> (referer: https://eurolux.de/)
Traceback (most recent call last):
  File "/Users/ms/scrapy-1/.venv/lib/python3.9/site-packages/scrapy/utils/defer.py", line 295, in aiter_errback
    yield await it.__anext__()
  File "/Users/ms/scrapy-1/.venv/lib/python3.9/site-packages/scrapy/utils/python.py", line 374, in __anext__
    return await self.data.__anext__()
  File "/Users/ms/scrapy-1/.venv/lib/python3.9/site-packages/scrapy/utils/python.py", line 355, in _async_chain
    async for o in as_async_generator(it):
  File "/Users/ms/scrapy-1/.venv/lib/python3.9/site-packages/scrapy/utils/asyncgen.py", line 14, in as_async_generator
    async for r in it:
  File "/Users/ms/scrapy-1/.venv/lib/python3.9/site-packages/scrapy/utils/python.py", line 374, in __anext__
    return await self.data.__anext__()
  File "/Users/ms/scrapy-1/.venv/lib/python3.9/site-packages/scrapy/utils/python.py", line 355, in _async_chain
    async for o in as_async_generator(it):
  File "/Users/ms/scrapy-1/.venv/lib/python3.9/site-packages/scrapy/utils/asyncgen.py", line 14, in as_async_generator
    async for r in it:
  File "/Users/ms/scrapy-1/.venv/lib/python3.9/site-packages/scrapy/core/spidermw.py", line 118, in process_async
    async for r in iterable:
  File "/Users/ms/scrapy-1/.venv/lib/python3.9/site-packages/scrapy/spidermiddlewares/offsite.py", line 31, in process_spider_output_async
    async for r in result or ():
  File "/Users/ms/scrapy-1/.venv/lib/python3.9/site-packages/scrapy/core/spidermw.py", line 118, in process_async
    async for r in iterable:
  File "/Users/ms/scrapy-1/.venv/lib/python3.9/site-packages/scrapy/spidermiddlewares/referer.py", line 355, in process_spider_output_async
    async for r in result or ():
  File "/Users/ms/scrapy-1/.venv/lib/python3.9/site-packages/scrapy/core/spidermw.py", line 118, in process_async
    async for r in iterable:
  File "/Users/ms/scrapy-1/.venv/lib/python3.9/site-packages/scrapy/spidermiddlewares/urllength.py", line 30, in process_spider_output_async
    async for r in result or ():
  File "/Users/ms/scrapy-1/.venv/lib/python3.9/site-packages/scrapy/core/spidermw.py", line 118, in process_async
    async for r in iterable:
  File "/Users/ms/scrapy-1/.venv/lib/python3.9/site-packages/scrapy/spidermiddlewares/depth.py", line 35, in process_spider_output_async
    async for r in result or ():
  File "/Users/ms/scrapy-1/.venv/lib/python3.9/site-packages/scrapy/core/spidermw.py", line 118, in process_async
    async for r in iterable:
  File "/Users/ms/scrapy-1/.venv/lib/python3.9/site-packages/scrapy/spiders/crawl.py", line 124, in _parse_response
    for request_or_item in iterate_spider_output(cb_res):
  File "/Users/ms/scrapy-1/scrapy1/scrapy1/spiders/eurolux_spider.py", line 44, in parse_page
    description = bleach_html(response.css('.text-md-h6').get())
  File "/Users/ms/scrapy-1/scrapy1/scrapy1/spiders/eurolux_spider.py", line 15, in bleach_html
    cleaned_html = bleach.clean(html_string, tags=allowed_tags, strip=True)
  File "/Users/ms/scrapy-1/.venv/lib/python3.9/site-packages/bleach/__init__.py", line 82, in clean
    return cleaner.clean(text)
  File "/Users/ms/scrapy-1/.venv/lib/python3.9/site-packages/bleach/sanitizer.py", line 186, in clean
    raise TypeError(message)
TypeError: argument cannot be of 'NoneType' type, must be of text type
2023-11-13 18:46:17 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://eurolux.de/category/kerzenfilter> (referer: https://eurolux.de/)
2023-11-13 18:46:17 [scrapy.core.scraper] ERROR: Spider error processing <GET https://eurolux.de/category/kerzenfilter> (referer: https://eurolux.de/)
Traceback (most recent call last):
  File "/Users/ms/scrapy-1/.venv/lib/python3.9/site-packages/scrapy/utils/defer.py", line 295, in aiter_errback
    yield await it.__anext__()
  File "/Users/ms/scrapy-1/.venv/lib/python3.9/site-packages/scrapy/utils/python.py", line 374, in __anext__
    return await self.data.__anext__()
  File "/Users/ms/scrapy-1/.venv/lib/python3.9/site-packages/scrapy/utils/python.py", line 355, in _async_chain
    async for o in as_async_generator(it):
  File "/Users/ms/scrapy-1/.venv/lib/python3.9/site-packages/scrapy/utils/asyncgen.py", line 14, in as_async_generator
    async for r in it:
  File "/Users/ms/scrapy-1/.venv/lib/python3.9/site-packages/scrapy/utils/python.py", line 374, in __anext__
    return await self.data.__anext__()
  File "/Users/ms/scrapy-1/.venv/lib/python3.9/site-packages/scrapy/utils/python.py", line 355, in _async_chain
    async for o in as_async_generator(it):
  File "/Users/ms/scrapy-1/.venv/lib/python3.9/site-packages/scrapy/utils/asyncgen.py", line 14, in as_async_generator
    async for r in it:
  File "/Users/ms/scrapy-1/.venv/lib/python3.9/site-packages/scrapy/core/spidermw.py", line 118, in process_async
    async for r in iterable:
  File "/Users/ms/scrapy-1/.venv/lib/python3.9/site-packages/scrapy/spidermiddlewares/offsite.py", line 31, in process_spider_output_async
    async for r in result or ():
  File "/Users/ms/scrapy-1/.venv/lib/python3.9/site-packages/scrapy/core/spidermw.py", line 118, in process_async
    async for r in iterable:
  File "/Users/ms/scrapy-1/.venv/lib/python3.9/site-packages/scrapy/spidermiddlewares/referer.py", line 355, in process_spider_output_async
    async for r in result or ():
  File "/Users/ms/scrapy-1/.venv/lib/python3.9/site-packages/scrapy/core/spidermw.py", line 118, in process_async
    async for r in iterable:
  File "/Users/ms/scrapy-1/.venv/lib/python3.9/site-packages/scrapy/spidermiddlewares/urllength.py", line 30, in process_spider_output_async
    async for r in result or ():
  File "/Users/ms/scrapy-1/.venv/lib/python3.9/site-packages/scrapy/core/spidermw.py", line 118, in process_async
    async for r in iterable:
  File "/Users/ms/scrapy-1/.venv/lib/python3.9/site-packages/scrapy/spidermiddlewares/depth.py", line 35, in process_spider_output_async
    async for r in result or ():
  File "/Users/ms/scrapy-1/.venv/lib/python3.9/site-packages/scrapy/core/spidermw.py", line 118, in process_async
    async for r in iterable:
  File "/Users/ms/scrapy-1/.venv/lib/python3.9/site-packages/scrapy/spiders/crawl.py", line 124, in _parse_response
    for request_or_item in iterate_spider_output(cb_res):
  File "/Users/ms/scrapy-1/scrapy1/scrapy1/spiders/eurolux_spider.py", line 44, in parse_page
    description = bleach_html(response.css('.text-md-h6').get())
  File "/Users/ms/scrapy-1/scrapy1/scrapy1/spiders/eurolux_spider.py", line 15, in bleach_html
    cleaned_html = bleach.clean(html_string, tags=allowed_tags, strip=True)
  File "/Users/ms/scrapy-1/.venv/lib/python3.9/site-packages/bleach/__init__.py", line 82, in clean
    return cleaner.clean(text)
  File "/Users/ms/scrapy-1/.venv/lib/python3.9/site-packages/bleach/sanitizer.py", line 186, in clean
    raise TypeError(message)
TypeError: argument cannot be of 'NoneType' type, must be of text type
2023-11-13 18:46:18 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://eurolux.de/category/querstromfilter> (referer: https://eurolux.de/)
2023-11-13 18:46:18 [scrapy.core.scraper] ERROR: Spider error processing <GET https://eurolux.de/category/querstromfilter> (referer: https://eurolux.de/)
Traceback (most recent call last):
  File "/Users/ms/scrapy-1/.venv/lib/python3.9/site-packages/scrapy/utils/defer.py", line 295, in aiter_errback
    yield await it.__anext__()
  File "/Users/ms/scrapy-1/.venv/lib/python3.9/site-packages/scrapy/utils/python.py", line 374, in __anext__
    return await self.data.__anext__()
  File "/Users/ms/scrapy-1/.venv/lib/python3.9/site-packages/scrapy/utils/python.py", line 355, in _async_chain
    async for o in as_async_generator(it):
  File "/Users/ms/scrapy-1/.venv/lib/python3.9/site-packages/scrapy/utils/asyncgen.py", line 14, in as_async_generator
    async for r in it:
  File "/Users/ms/scrapy-1/.venv/lib/python3.9/site-packages/scrapy/utils/python.py", line 374, in __anext__
    return await self.data.__anext__()
  File "/Users/ms/scrapy-1/.venv/lib/python3.9/site-packages/scrapy/utils/python.py", line 355, in _async_chain
    async for o in as_async_generator(it):
  File "/Users/ms/scrapy-1/.venv/lib/python3.9/site-packages/scrapy/utils/asyncgen.py", line 14, in as_async_generator
    async for r in it:
  File "/Users/ms/scrapy-1/.venv/lib/python3.9/site-packages/scrapy/core/spidermw.py", line 118, in process_async
    async for r in iterable:
  File "/Users/ms/scrapy-1/.venv/lib/python3.9/site-packages/scrapy/spidermiddlewares/offsite.py", line 31, in process_spider_output_async
    async for r in result or ():
  File "/Users/ms/scrapy-1/.venv/lib/python3.9/site-packages/scrapy/core/spidermw.py", line 118, in process_async
    async for r in iterable:
  File "/Users/ms/scrapy-1/.venv/lib/python3.9/site-packages/scrapy/spidermiddlewares/referer.py", line 355, in process_spider_output_async
    async for r in result or ():
  File "/Users/ms/scrapy-1/.venv/lib/python3.9/site-packages/scrapy/core/spidermw.py", line 118, in process_async
    async for r in iterable:
  File "/Users/ms/scrapy-1/.venv/lib/python3.9/site-packages/scrapy/spidermiddlewares/urllength.py", line 30, in process_spider_output_async
    async for r in result or ():
  File "/Users/ms/scrapy-1/.venv/lib/python3.9/site-packages/scrapy/core/spidermw.py", line 118, in process_async
    async for r in iterable:
  File "/Users/ms/scrapy-1/.venv/lib/python3.9/site-packages/scrapy/spidermiddlewares/depth.py", line 35, in process_spider_output_async
    async for r in result or ():
  File "/Users/ms/scrapy-1/.venv/lib/python3.9/site-packages/scrapy/core/spidermw.py", line 118, in process_async
    async for r in iterable:
  File "/Users/ms/scrapy-1/.venv/lib/python3.9/site-packages/scrapy/spiders/crawl.py", line 124, in _parse_response
    for request_or_item in iterate_spider_output(cb_res):
  File "/Users/ms/scrapy-1/scrapy1/scrapy1/spiders/eurolux_spider.py", line 44, in parse_page
    description = bleach_html(response.css('.text-md-h6').get())
  File "/Users/ms/scrapy-1/scrapy1/scrapy1/spiders/eurolux_spider.py", line 15, in bleach_html
    cleaned_html = bleach.clean(html_string, tags=allowed_tags, strip=True)
  File "/Users/ms/scrapy-1/.venv/lib/python3.9/site-packages/bleach/__init__.py", line 82, in clean
    return cleaner.clean(text)
  File "/Users/ms/scrapy-1/.venv/lib/python3.9/site-packages/bleach/sanitizer.py", line 186, in clean
    raise TypeError(message)
TypeError: argument cannot be of 'NoneType' type, must be of text type
2023-11-13 18:46:18 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://eurolux.de/category/vakuumdrehfilter> (referer: https://eurolux.de/)
2023-11-13 18:46:18 [scrapy.core.scraper] ERROR: Spider error processing <GET https://eurolux.de/category/vakuumdrehfilter> (referer: https://eurolux.de/)
Traceback (most recent call last):
  File "/Users/ms/scrapy-1/.venv/lib/python3.9/site-packages/scrapy/utils/defer.py", line 295, in aiter_errback
    yield await it.__anext__()
  File "/Users/ms/scrapy-1/.venv/lib/python3.9/site-packages/scrapy/utils/python.py", line 374, in __anext__
    return await self.data.__anext__()
  File "/Users/ms/scrapy-1/.venv/lib/python3.9/site-packages/scrapy/utils/python.py", line 355, in _async_chain
    async for o in as_async_generator(it):
  File "/Users/ms/scrapy-1/.venv/lib/python3.9/site-packages/scrapy/utils/asyncgen.py", line 14, in as_async_generator
    async for r in it:
  File "/Users/ms/scrapy-1/.venv/lib/python3.9/site-packages/scrapy/utils/python.py", line 374, in __anext__
    return await self.data.__anext__()
  File "/Users/ms/scrapy-1/.venv/lib/python3.9/site-packages/scrapy/utils/python.py", line 355, in _async_chain
    async for o in as_async_generator(it):
  File "/Users/ms/scrapy-1/.venv/lib/python3.9/site-packages/scrapy/utils/asyncgen.py", line 14, in as_async_generator
    async for r in it:
  File "/Users/ms/scrapy-1/.venv/lib/python3.9/site-packages/scrapy/core/spidermw.py", line 118, in process_async
    async for r in iterable:
  File "/Users/ms/scrapy-1/.venv/lib/python3.9/site-packages/scrapy/spidermiddlewares/offsite.py", line 31, in process_spider_output_async
    async for r in result or ():
  File "/Users/ms/scrapy-1/.venv/lib/python3.9/site-packages/scrapy/core/spidermw.py", line 118, in process_async
    async for r in iterable:
  File "/Users/ms/scrapy-1/.venv/lib/python3.9/site-packages/scrapy/spidermiddlewares/referer.py", line 355, in process_spider_output_async
    async for r in result or ():
  File "/Users/ms/scrapy-1/.venv/lib/python3.9/site-packages/scrapy/core/spidermw.py", line 118, in process_async
    async for r in iterable:
  File "/Users/ms/scrapy-1/.venv/lib/python3.9/site-packages/scrapy/spidermiddlewares/urllength.py", line 30, in process_spider_output_async
    async for r in result or ():
  File "/Users/ms/scrapy-1/.venv/lib/python3.9/site-packages/scrapy/core/spidermw.py", line 118, in process_async
    async for r in iterable:
  File "/Users/ms/scrapy-1/.venv/lib/python3.9/site-packages/scrapy/spidermiddlewares/depth.py", line 35, in process_spider_output_async
    async for r in result or ():
  File "/Users/ms/scrapy-1/.venv/lib/python3.9/site-packages/scrapy/core/spidermw.py", line 118, in process_async
    async for r in iterable:
  File "/Users/ms/scrapy-1/.venv/lib/python3.9/site-packages/scrapy/spiders/crawl.py", line 124, in _parse_response
    for request_or_item in iterate_spider_output(cb_res):
  File "/Users/ms/scrapy-1/scrapy1/scrapy1/spiders/eurolux_spider.py", line 44, in parse_page
    description = bleach_html(response.css('.text-md-h6').get())
  File "/Users/ms/scrapy-1/scrapy1/scrapy1/spiders/eurolux_spider.py", line 15, in bleach_html
    cleaned_html = bleach.clean(html_string, tags=allowed_tags, strip=True)
  File "/Users/ms/scrapy-1/.venv/lib/python3.9/site-packages/bleach/__init__.py", line 82, in clean
    return cleaner.clean(text)
  File "/Users/ms/scrapy-1/.venv/lib/python3.9/site-packages/bleach/sanitizer.py", line 186, in clean
    raise TypeError(message)
TypeError: argument cannot be of 'NoneType' type, must be of text type
2023-11-13 18:46:19 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://eurolux.de/category/filter> (referer: https://eurolux.de/)
2023-11-13 18:46:19 [scrapy.core.scraper] ERROR: Spider error processing <GET https://eurolux.de/category/filter> (referer: https://eurolux.de/)
Traceback (most recent call last):
  File "/Users/ms/scrapy-1/.venv/lib/python3.9/site-packages/scrapy/utils/defer.py", line 295, in aiter_errback
    yield await it.__anext__()
  File "/Users/ms/scrapy-1/.venv/lib/python3.9/site-packages/scrapy/utils/python.py", line 374, in __anext__
    return await self.data.__anext__()
  File "/Users/ms/scrapy-1/.venv/lib/python3.9/site-packages/scrapy/utils/python.py", line 355, in _async_chain
    async for o in as_async_generator(it):
  File "/Users/ms/scrapy-1/.venv/lib/python3.9/site-packages/scrapy/utils/asyncgen.py", line 14, in as_async_generator
    async for r in it:
  File "/Users/ms/scrapy-1/.venv/lib/python3.9/site-packages/scrapy/utils/python.py", line 374, in __anext__
    return await self.data.__anext__()
  File "/Users/ms/scrapy-1/.venv/lib/python3.9/site-packages/scrapy/utils/python.py", line 355, in _async_chain
    async for o in as_async_generator(it):
  File "/Users/ms/scrapy-1/.venv/lib/python3.9/site-packages/scrapy/utils/asyncgen.py", line 14, in as_async_generator
    async for r in it:
  File "/Users/ms/scrapy-1/.venv/lib/python3.9/site-packages/scrapy/core/spidermw.py", line 118, in process_async
    async for r in iterable:
  File "/Users/ms/scrapy-1/.venv/lib/python3.9/site-packages/scrapy/spidermiddlewares/offsite.py", line 31, in process_spider_output_async
    async for r in result or ():
  File "/Users/ms/scrapy-1/.venv/lib/python3.9/site-packages/scrapy/core/spidermw.py", line 118, in process_async
    async for r in iterable:
  File "/Users/ms/scrapy-1/.venv/lib/python3.9/site-packages/scrapy/spidermiddlewares/referer.py", line 355, in process_spider_output_async
    async for r in result or ():
  File "/Users/ms/scrapy-1/.venv/lib/python3.9/site-packages/scrapy/core/spidermw.py", line 118, in process_async
    async for r in iterable:
  File "/Users/ms/scrapy-1/.venv/lib/python3.9/site-packages/scrapy/spidermiddlewares/urllength.py", line 30, in process_spider_output_async
    async for r in result or ():
  File "/Users/ms/scrapy-1/.venv/lib/python3.9/site-packages/scrapy/core/spidermw.py", line 118, in process_async
    async for r in iterable:
  File "/Users/ms/scrapy-1/.venv/lib/python3.9/site-packages/scrapy/spidermiddlewares/depth.py", line 35, in process_spider_output_async
    async for r in result or ():
  File "/Users/ms/scrapy-1/.venv/lib/python3.9/site-packages/scrapy/core/spidermw.py", line 118, in process_async
    async for r in iterable:
  File "/Users/ms/scrapy-1/.venv/lib/python3.9/site-packages/scrapy/spiders/crawl.py", line 124, in _parse_response
    for request_or_item in iterate_spider_output(cb_res):
  File "/Users/ms/scrapy-1/scrapy1/scrapy1/spiders/eurolux_spider.py", line 44, in parse_page
    description = bleach_html(response.css('.text-md-h6').get())
  File "/Users/ms/scrapy-1/scrapy1/scrapy1/spiders/eurolux_spider.py", line 15, in bleach_html
    cleaned_html = bleach.clean(html_string, tags=allowed_tags, strip=True)
  File "/Users/ms/scrapy-1/.venv/lib/python3.9/site-packages/bleach/__init__.py", line 82, in clean
    return cleaner.clean(text)
  File "/Users/ms/scrapy-1/.venv/lib/python3.9/site-packages/bleach/sanitizer.py", line 186, in clean
    raise TypeError(message)
TypeError: argument cannot be of 'NoneType' type, must be of text type
2023-11-13 18:46:20 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://eurolux.de/category/molkerei-diverse> (referer: https://eurolux.de/)
2023-11-13 18:46:20 [scrapy.core.scraper] ERROR: Spider error processing <GET https://eurolux.de/category/molkerei-diverse> (referer: https://eurolux.de/)
Traceback (most recent call last):
  File "/Users/ms/scrapy-1/.venv/lib/python3.9/site-packages/scrapy/utils/defer.py", line 295, in aiter_errback
    yield await it.__anext__()
  File "/Users/ms/scrapy-1/.venv/lib/python3.9/site-packages/scrapy/utils/python.py", line 374, in __anext__
    return await self.data.__anext__()
  File "/Users/ms/scrapy-1/.venv/lib/python3.9/site-packages/scrapy/utils/python.py", line 355, in _async_chain
    async for o in as_async_generator(it):
  File "/Users/ms/scrapy-1/.venv/lib/python3.9/site-packages/scrapy/utils/asyncgen.py", line 14, in as_async_generator
    async for r in it:
  File "/Users/ms/scrapy-1/.venv/lib/python3.9/site-packages/scrapy/utils/python.py", line 374, in __anext__
    return await self.data.__anext__()
  File "/Users/ms/scrapy-1/.venv/lib/python3.9/site-packages/scrapy/utils/python.py", line 355, in _async_chain
    async for o in as_async_generator(it):
  File "/Users/ms/scrapy-1/.venv/lib/python3.9/site-packages/scrapy/utils/asyncgen.py", line 14, in as_async_generator
    async for r in it:
  File "/Users/ms/scrapy-1/.venv/lib/python3.9/site-packages/scrapy/core/spidermw.py", line 118, in process_async
    async for r in iterable:
  File "/Users/ms/scrapy-1/.venv/lib/python3.9/site-packages/scrapy/spidermiddlewares/offsite.py", line 31, in process_spider_output_async
    async for r in result or ():
  File "/Users/ms/scrapy-1/.venv/lib/python3.9/site-packages/scrapy/core/spidermw.py", line 118, in process_async
    async for r in iterable:
  File "/Users/ms/scrapy-1/.venv/lib/python3.9/site-packages/scrapy/spidermiddlewares/referer.py", line 355, in process_spider_output_async
    async for r in result or ():
  File "/Users/ms/scrapy-1/.venv/lib/python3.9/site-packages/scrapy/core/spidermw.py", line 118, in process_async
    async for r in iterable:
  File "/Users/ms/scrapy-1/.venv/lib/python3.9/site-packages/scrapy/spidermiddlewares/urllength.py", line 30, in process_spider_output_async
    async for r in result or ():
  File "/Users/ms/scrapy-1/.venv/lib/python3.9/site-packages/scrapy/core/spidermw.py", line 118, in process_async
    async for r in iterable:
  File "/Users/ms/scrapy-1/.venv/lib/python3.9/site-packages/scrapy/spidermiddlewares/depth.py", line 35, in process_spider_output_async
    async for r in result or ():
  File "/Users/ms/scrapy-1/.venv/lib/python3.9/site-packages/scrapy/core/spidermw.py", line 118, in process_async
    async for r in iterable:
  File "/Users/ms/scrapy-1/.venv/lib/python3.9/site-packages/scrapy/spiders/crawl.py", line 124, in _parse_response
    for request_or_item in iterate_spider_output(cb_res):
  File "/Users/ms/scrapy-1/scrapy1/scrapy1/spiders/eurolux_spider.py", line 44, in parse_page
    description = bleach_html(response.css('.text-md-h6').get())
  File "/Users/ms/scrapy-1/scrapy1/scrapy1/spiders/eurolux_spider.py", line 15, in bleach_html
    cleaned_html = bleach.clean(html_string, tags=allowed_tags, strip=True)
  File "/Users/ms/scrapy-1/.venv/lib/python3.9/site-packages/bleach/__init__.py", line 82, in clean
    return cleaner.clean(text)
  File "/Users/ms/scrapy-1/.venv/lib/python3.9/site-packages/bleach/sanitizer.py", line 186, in clean
    raise TypeError(message)
TypeError: argument cannot be of 'NoneType' type, must be of text type
2023-11-13 18:46:21 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://eurolux.de/category/plattenfilter> (referer: https://eurolux.de/)
2023-11-13 18:46:21 [scrapy.core.scraper] ERROR: Spider error processing <GET https://eurolux.de/category/plattenfilter> (referer: https://eurolux.de/)
Traceback (most recent call last):
  File "/Users/ms/scrapy-1/.venv/lib/python3.9/site-packages/scrapy/utils/defer.py", line 295, in aiter_errback
    yield await it.__anext__()
  File "/Users/ms/scrapy-1/.venv/lib/python3.9/site-packages/scrapy/utils/python.py", line 374, in __anext__
    return await self.data.__anext__()
  File "/Users/ms/scrapy-1/.venv/lib/python3.9/site-packages/scrapy/utils/python.py", line 355, in _async_chain
    async for o in as_async_generator(it):
  File "/Users/ms/scrapy-1/.venv/lib/python3.9/site-packages/scrapy/utils/asyncgen.py", line 14, in as_async_generator
    async for r in it:
  File "/Users/ms/scrapy-1/.venv/lib/python3.9/site-packages/scrapy/utils/python.py", line 374, in __anext__
    return await self.data.__anext__()
  File "/Users/ms/scrapy-1/.venv/lib/python3.9/site-packages/scrapy/utils/python.py", line 355, in _async_chain
    async for o in as_async_generator(it):
  File "/Users/ms/scrapy-1/.venv/lib/python3.9/site-packages/scrapy/utils/asyncgen.py", line 14, in as_async_generator
    async for r in it:
  File "/Users/ms/scrapy-1/.venv/lib/python3.9/site-packages/scrapy/core/spidermw.py", line 118, in process_async
    async for r in iterable:
  File "/Users/ms/scrapy-1/.venv/lib/python3.9/site-packages/scrapy/spidermiddlewares/offsite.py", line 31, in process_spider_output_async
    async for r in result or ():
  File "/Users/ms/scrapy-1/.venv/lib/python3.9/site-packages/scrapy/core/spidermw.py", line 118, in process_async
    async for r in iterable:
  File "/Users/ms/scrapy-1/.venv/lib/python3.9/site-packages/scrapy/spidermiddlewares/referer.py", line 355, in process_spider_output_async
    async for r in result or ():
  File "/Users/ms/scrapy-1/.venv/lib/python3.9/site-packages/scrapy/core/spidermw.py", line 118, in process_async
    async for r in iterable:
  File "/Users/ms/scrapy-1/.venv/lib/python3.9/site-packages/scrapy/spidermiddlewares/urllength.py", line 30, in process_spider_output_async
    async for r in result or ():
  File "/Users/ms/scrapy-1/.venv/lib/python3.9/site-packages/scrapy/core/spidermw.py", line 118, in process_async
    async for r in iterable:
  File "/Users/ms/scrapy-1/.venv/lib/python3.9/site-packages/scrapy/spidermiddlewares/depth.py", line 35, in process_spider_output_async
    async for r in result or ():
  File "/Users/ms/scrapy-1/.venv/lib/python3.9/site-packages/scrapy/core/spidermw.py", line 118, in process_async
    async for r in iterable:
  File "/Users/ms/scrapy-1/.venv/lib/python3.9/site-packages/scrapy/spiders/crawl.py", line 124, in _parse_response
    for request_or_item in iterate_spider_output(cb_res):
  File "/Users/ms/scrapy-1/scrapy1/scrapy1/spiders/eurolux_spider.py", line 44, in parse_page
    description = bleach_html(response.css('.text-md-h6').get())
  File "/Users/ms/scrapy-1/scrapy1/scrapy1/spiders/eurolux_spider.py", line 15, in bleach_html
    cleaned_html = bleach.clean(html_string, tags=allowed_tags, strip=True)
  File "/Users/ms/scrapy-1/.venv/lib/python3.9/site-packages/bleach/__init__.py", line 82, in clean
    return cleaner.clean(text)
  File "/Users/ms/scrapy-1/.venv/lib/python3.9/site-packages/bleach/sanitizer.py", line 186, in clean
    raise TypeError(message)
TypeError: argument cannot be of 'NoneType' type, must be of text type
2023-11-13 18:46:21 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://eurolux.de/category/kieselgur-filter> (referer: https://eurolux.de/)
2023-11-13 18:46:21 [scrapy.core.scraper] ERROR: Spider error processing <GET https://eurolux.de/category/kieselgur-filter> (referer: https://eurolux.de/)
Traceback (most recent call last):
  File "/Users/ms/scrapy-1/.venv/lib/python3.9/site-packages/scrapy/utils/defer.py", line 295, in aiter_errback
    yield await it.__anext__()
  File "/Users/ms/scrapy-1/.venv/lib/python3.9/site-packages/scrapy/utils/python.py", line 374, in __anext__
    return await self.data.__anext__()
  File "/Users/ms/scrapy-1/.venv/lib/python3.9/site-packages/scrapy/utils/python.py", line 355, in _async_chain
    async for o in as_async_generator(it):
  File "/Users/ms/scrapy-1/.venv/lib/python3.9/site-packages/scrapy/utils/asyncgen.py", line 14, in as_async_generator
    async for r in it:
  File "/Users/ms/scrapy-1/.venv/lib/python3.9/site-packages/scrapy/utils/python.py", line 374, in __anext__
    return await self.data.__anext__()
  File "/Users/ms/scrapy-1/.venv/lib/python3.9/site-packages/scrapy/utils/python.py", line 355, in _async_chain
    async for o in as_async_generator(it):
  File "/Users/ms/scrapy-1/.venv/lib/python3.9/site-packages/scrapy/utils/asyncgen.py", line 14, in as_async_generator
    async for r in it:
  File "/Users/ms/scrapy-1/.venv/lib/python3.9/site-packages/scrapy/core/spidermw.py", line 118, in process_async
    async for r in iterable:
  File "/Users/ms/scrapy-1/.venv/lib/python3.9/site-packages/scrapy/spidermiddlewares/offsite.py", line 31, in process_spider_output_async
    async for r in result or ():
  File "/Users/ms/scrapy-1/.venv/lib/python3.9/site-packages/scrapy/core/spidermw.py", line 118, in process_async
    async for r in iterable:
  File "/Users/ms/scrapy-1/.venv/lib/python3.9/site-packages/scrapy/spidermiddlewares/referer.py", line 355, in process_spider_output_async
    async for r in result or ():
  File "/Users/ms/scrapy-1/.venv/lib/python3.9/site-packages/scrapy/core/spidermw.py", line 118, in process_async
    async for r in iterable:
  File "/Users/ms/scrapy-1/.venv/lib/python3.9/site-packages/scrapy/spidermiddlewares/urllength.py", line 30, in process_spider_output_async
    async for r in result or ():
  File "/Users/ms/scrapy-1/.venv/lib/python3.9/site-packages/scrapy/core/spidermw.py", line 118, in process_async
    async for r in iterable:
  File "/Users/ms/scrapy-1/.venv/lib/python3.9/site-packages/scrapy/spidermiddlewares/depth.py", line 35, in process_spider_output_async
    async for r in result or ():
  File "/Users/ms/scrapy-1/.venv/lib/python3.9/site-packages/scrapy/core/spidermw.py", line 118, in process_async
    async for r in iterable:
  File "/Users/ms/scrapy-1/.venv/lib/python3.9/site-packages/scrapy/spiders/crawl.py", line 124, in _parse_response
    for request_or_item in iterate_spider_output(cb_res):
  File "/Users/ms/scrapy-1/scrapy1/scrapy1/spiders/eurolux_spider.py", line 44, in parse_page
    description = bleach_html(response.css('.text-md-h6').get())
  File "/Users/ms/scrapy-1/scrapy1/scrapy1/spiders/eurolux_spider.py", line 15, in bleach_html
    cleaned_html = bleach.clean(html_string, tags=allowed_tags, strip=True)
  File "/Users/ms/scrapy-1/.venv/lib/python3.9/site-packages/bleach/__init__.py", line 82, in clean
    return cleaner.clean(text)
  File "/Users/ms/scrapy-1/.venv/lib/python3.9/site-packages/bleach/sanitizer.py", line 186, in clean
    raise TypeError(message)
TypeError: argument cannot be of 'NoneType' type, must be of text type
2023-11-13 18:46:21 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://eurolux.de/category/separatoren> (referer: https://eurolux.de/)
2023-11-13 18:46:21 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://eurolux.de/category/pressen> (referer: https://eurolux.de/)
2023-11-13 18:46:22 [scrapy.core.scraper] ERROR: Spider error processing <GET https://eurolux.de/category/separatoren> (referer: https://eurolux.de/)
Traceback (most recent call last):
  File "/Users/ms/scrapy-1/.venv/lib/python3.9/site-packages/scrapy/utils/defer.py", line 295, in aiter_errback
    yield await it.__anext__()
  File "/Users/ms/scrapy-1/.venv/lib/python3.9/site-packages/scrapy/utils/python.py", line 374, in __anext__
    return await self.data.__anext__()
  File "/Users/ms/scrapy-1/.venv/lib/python3.9/site-packages/scrapy/utils/python.py", line 355, in _async_chain
    async for o in as_async_generator(it):
  File "/Users/ms/scrapy-1/.venv/lib/python3.9/site-packages/scrapy/utils/asyncgen.py", line 14, in as_async_generator
    async for r in it:
  File "/Users/ms/scrapy-1/.venv/lib/python3.9/site-packages/scrapy/utils/python.py", line 374, in __anext__
    return await self.data.__anext__()
  File "/Users/ms/scrapy-1/.venv/lib/python3.9/site-packages/scrapy/utils/python.py", line 355, in _async_chain
    async for o in as_async_generator(it):
  File "/Users/ms/scrapy-1/.venv/lib/python3.9/site-packages/scrapy/utils/asyncgen.py", line 14, in as_async_generator
    async for r in it:
  File "/Users/ms/scrapy-1/.venv/lib/python3.9/site-packages/scrapy/core/spidermw.py", line 118, in process_async
    async for r in iterable:
  File "/Users/ms/scrapy-1/.venv/lib/python3.9/site-packages/scrapy/spidermiddlewares/offsite.py", line 31, in process_spider_output_async
    async for r in result or ():
  File "/Users/ms/scrapy-1/.venv/lib/python3.9/site-packages/scrapy/core/spidermw.py", line 118, in process_async
    async for r in iterable:
  File "/Users/ms/scrapy-1/.venv/lib/python3.9/site-packages/scrapy/spidermiddlewares/referer.py", line 355, in process_spider_output_async
    async for r in result or ():
  File "/Users/ms/scrapy-1/.venv/lib/python3.9/site-packages/scrapy/core/spidermw.py", line 118, in process_async
    async for r in iterable:
  File "/Users/ms/scrapy-1/.venv/lib/python3.9/site-packages/scrapy/spidermiddlewares/urllength.py", line 30, in process_spider_output_async
    async for r in result or ():
  File "/Users/ms/scrapy-1/.venv/lib/python3.9/site-packages/scrapy/core/spidermw.py", line 118, in process_async
    async for r in iterable:
  File "/Users/ms/scrapy-1/.venv/lib/python3.9/site-packages/scrapy/spidermiddlewares/depth.py", line 35, in process_spider_output_async
    async for r in result or ():
  File "/Users/ms/scrapy-1/.venv/lib/python3.9/site-packages/scrapy/core/spidermw.py", line 118, in process_async
    async for r in iterable:
  File "/Users/ms/scrapy-1/.venv/lib/python3.9/site-packages/scrapy/spiders/crawl.py", line 124, in _parse_response
    for request_or_item in iterate_spider_output(cb_res):
  File "/Users/ms/scrapy-1/scrapy1/scrapy1/spiders/eurolux_spider.py", line 44, in parse_page
    description = bleach_html(response.css('.text-md-h6').get())
  File "/Users/ms/scrapy-1/scrapy1/scrapy1/spiders/eurolux_spider.py", line 15, in bleach_html
    cleaned_html = bleach.clean(html_string, tags=allowed_tags, strip=True)
  File "/Users/ms/scrapy-1/.venv/lib/python3.9/site-packages/bleach/__init__.py", line 82, in clean
    return cleaner.clean(text)
  File "/Users/ms/scrapy-1/.venv/lib/python3.9/site-packages/bleach/sanitizer.py", line 186, in clean
    raise TypeError(message)
TypeError: argument cannot be of 'NoneType' type, must be of text type
2023-11-13 18:46:22 [scrapy.core.scraper] ERROR: Spider error processing <GET https://eurolux.de/category/pressen> (referer: https://eurolux.de/)
Traceback (most recent call last):
  File "/Users/ms/scrapy-1/.venv/lib/python3.9/site-packages/scrapy/utils/defer.py", line 295, in aiter_errback
    yield await it.__anext__()
  File "/Users/ms/scrapy-1/.venv/lib/python3.9/site-packages/scrapy/utils/python.py", line 374, in __anext__
    return await self.data.__anext__()
  File "/Users/ms/scrapy-1/.venv/lib/python3.9/site-packages/scrapy/utils/python.py", line 355, in _async_chain
    async for o in as_async_generator(it):
  File "/Users/ms/scrapy-1/.venv/lib/python3.9/site-packages/scrapy/utils/asyncgen.py", line 14, in as_async_generator
    async for r in it:
  File "/Users/ms/scrapy-1/.venv/lib/python3.9/site-packages/scrapy/utils/python.py", line 374, in __anext__
    return await self.data.__anext__()
  File "/Users/ms/scrapy-1/.venv/lib/python3.9/site-packages/scrapy/utils/python.py", line 355, in _async_chain
    async for o in as_async_generator(it):
  File "/Users/ms/scrapy-1/.venv/lib/python3.9/site-packages/scrapy/utils/asyncgen.py", line 14, in as_async_generator
    async for r in it:
  File "/Users/ms/scrapy-1/.venv/lib/python3.9/site-packages/scrapy/core/spidermw.py", line 118, in process_async
    async for r in iterable:
  File "/Users/ms/scrapy-1/.venv/lib/python3.9/site-packages/scrapy/spidermiddlewares/offsite.py", line 31, in process_spider_output_async
    async for r in result or ():
  File "/Users/ms/scrapy-1/.venv/lib/python3.9/site-packages/scrapy/core/spidermw.py", line 118, in process_async
    async for r in iterable:
  File "/Users/ms/scrapy-1/.venv/lib/python3.9/site-packages/scrapy/spidermiddlewares/referer.py", line 355, in process_spider_output_async
    async for r in result or ():
  File "/Users/ms/scrapy-1/.venv/lib/python3.9/site-packages/scrapy/core/spidermw.py", line 118, in process_async
    async for r in iterable:
  File "/Users/ms/scrapy-1/.venv/lib/python3.9/site-packages/scrapy/spidermiddlewares/urllength.py", line 30, in process_spider_output_async
    async for r in result or ():
  File "/Users/ms/scrapy-1/.venv/lib/python3.9/site-packages/scrapy/core/spidermw.py", line 118, in process_async
    async for r in iterable:
  File "/Users/ms/scrapy-1/.venv/lib/python3.9/site-packages/scrapy/spidermiddlewares/depth.py", line 35, in process_spider_output_async
    async for r in result or ():
  File "/Users/ms/scrapy-1/.venv/lib/python3.9/site-packages/scrapy/core/spidermw.py", line 118, in process_async
    async for r in iterable:
  File "/Users/ms/scrapy-1/.venv/lib/python3.9/site-packages/scrapy/spiders/crawl.py", line 124, in _parse_response
    for request_or_item in iterate_spider_output(cb_res):
  File "/Users/ms/scrapy-1/scrapy1/scrapy1/spiders/eurolux_spider.py", line 44, in parse_page
    description = bleach_html(response.css('.text-md-h6').get())
  File "/Users/ms/scrapy-1/scrapy1/scrapy1/spiders/eurolux_spider.py", line 15, in bleach_html
    cleaned_html = bleach.clean(html_string, tags=allowed_tags, strip=True)
  File "/Users/ms/scrapy-1/.venv/lib/python3.9/site-packages/bleach/__init__.py", line 82, in clean
    return cleaner.clean(text)
  File "/Users/ms/scrapy-1/.venv/lib/python3.9/site-packages/bleach/sanitizer.py", line 186, in clean
    raise TypeError(message)
TypeError: argument cannot be of 'NoneType' type, must be of text type
2023-11-13 18:46:22 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://eurolux.de/category/molkerei> (referer: https://eurolux.de/)
2023-11-13 18:46:22 [scrapy.core.scraper] ERROR: Spider error processing <GET https://eurolux.de/category/molkerei> (referer: https://eurolux.de/)
Traceback (most recent call last):
  File "/Users/ms/scrapy-1/.venv/lib/python3.9/site-packages/scrapy/utils/defer.py", line 295, in aiter_errback
    yield await it.__anext__()
  File "/Users/ms/scrapy-1/.venv/lib/python3.9/site-packages/scrapy/utils/python.py", line 374, in __anext__
    return await self.data.__anext__()
  File "/Users/ms/scrapy-1/.venv/lib/python3.9/site-packages/scrapy/utils/python.py", line 355, in _async_chain
    async for o in as_async_generator(it):
  File "/Users/ms/scrapy-1/.venv/lib/python3.9/site-packages/scrapy/utils/asyncgen.py", line 14, in as_async_generator
    async for r in it:
  File "/Users/ms/scrapy-1/.venv/lib/python3.9/site-packages/scrapy/utils/python.py", line 374, in __anext__
    return await self.data.__anext__()
  File "/Users/ms/scrapy-1/.venv/lib/python3.9/site-packages/scrapy/utils/python.py", line 355, in _async_chain
    async for o in as_async_generator(it):
  File "/Users/ms/scrapy-1/.venv/lib/python3.9/site-packages/scrapy/utils/asyncgen.py", line 14, in as_async_generator
    async for r in it:
  File "/Users/ms/scrapy-1/.venv/lib/python3.9/site-packages/scrapy/core/spidermw.py", line 118, in process_async
    async for r in iterable:
  File "/Users/ms/scrapy-1/.venv/lib/python3.9/site-packages/scrapy/spidermiddlewares/offsite.py", line 31, in process_spider_output_async
    async for r in result or ():
  File "/Users/ms/scrapy-1/.venv/lib/python3.9/site-packages/scrapy/core/spidermw.py", line 118, in process_async
    async for r in iterable:
  File "/Users/ms/scrapy-1/.venv/lib/python3.9/site-packages/scrapy/spidermiddlewares/referer.py", line 355, in process_spider_output_async
    async for r in result or ():
  File "/Users/ms/scrapy-1/.venv/lib/python3.9/site-packages/scrapy/core/spidermw.py", line 118, in process_async
    async for r in iterable:
  File "/Users/ms/scrapy-1/.venv/lib/python3.9/site-packages/scrapy/spidermiddlewares/urllength.py", line 30, in process_spider_output_async
    async for r in result or ():
  File "/Users/ms/scrapy-1/.venv/lib/python3.9/site-packages/scrapy/core/spidermw.py", line 118, in process_async
    async for r in iterable:
  File "/Users/ms/scrapy-1/.venv/lib/python3.9/site-packages/scrapy/spidermiddlewares/depth.py", line 35, in process_spider_output_async
    async for r in result or ():
  File "/Users/ms/scrapy-1/.venv/lib/python3.9/site-packages/scrapy/core/spidermw.py", line 118, in process_async
    async for r in iterable:
  File "/Users/ms/scrapy-1/.venv/lib/python3.9/site-packages/scrapy/spiders/crawl.py", line 124, in _parse_response
    for request_or_item in iterate_spider_output(cb_res):
  File "/Users/ms/scrapy-1/scrapy1/scrapy1/spiders/eurolux_spider.py", line 44, in parse_page
    description = bleach_html(response.css('.text-md-h6').get())
  File "/Users/ms/scrapy-1/scrapy1/scrapy1/spiders/eurolux_spider.py", line 15, in bleach_html
    cleaned_html = bleach.clean(html_string, tags=allowed_tags, strip=True)
  File "/Users/ms/scrapy-1/.venv/lib/python3.9/site-packages/bleach/__init__.py", line 82, in clean
    return cleaner.clean(text)
  File "/Users/ms/scrapy-1/.venv/lib/python3.9/site-packages/bleach/sanitizer.py", line 186, in clean
    raise TypeError(message)
TypeError: argument cannot be of 'NoneType' type, must be of text type
2023-11-13 18:46:22 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://eurolux.de/category/pueree> (referer: https://eurolux.de/)
2023-11-13 18:46:23 [scrapy.core.scraper] ERROR: Spider error processing <GET https://eurolux.de/category/pueree> (referer: https://eurolux.de/)
Traceback (most recent call last):
  File "/Users/ms/scrapy-1/.venv/lib/python3.9/site-packages/scrapy/utils/defer.py", line 295, in aiter_errback
    yield await it.__anext__()
  File "/Users/ms/scrapy-1/.venv/lib/python3.9/site-packages/scrapy/utils/python.py", line 374, in __anext__
    return await self.data.__anext__()
  File "/Users/ms/scrapy-1/.venv/lib/python3.9/site-packages/scrapy/utils/python.py", line 355, in _async_chain
    async for o in as_async_generator(it):
  File "/Users/ms/scrapy-1/.venv/lib/python3.9/site-packages/scrapy/utils/asyncgen.py", line 14, in as_async_generator
    async for r in it:
  File "/Users/ms/scrapy-1/.venv/lib/python3.9/site-packages/scrapy/utils/python.py", line 374, in __anext__
    return await self.data.__anext__()
  File "/Users/ms/scrapy-1/.venv/lib/python3.9/site-packages/scrapy/utils/python.py", line 355, in _async_chain
    async for o in as_async_generator(it):
  File "/Users/ms/scrapy-1/.venv/lib/python3.9/site-packages/scrapy/utils/asyncgen.py", line 14, in as_async_generator
    async for r in it:
  File "/Users/ms/scrapy-1/.venv/lib/python3.9/site-packages/scrapy/core/spidermw.py", line 118, in process_async
    async for r in iterable:
  File "/Users/ms/scrapy-1/.venv/lib/python3.9/site-packages/scrapy/spidermiddlewares/offsite.py", line 31, in process_spider_output_async
    async for r in result or ():
  File "/Users/ms/scrapy-1/.venv/lib/python3.9/site-packages/scrapy/core/spidermw.py", line 118, in process_async
    async for r in iterable:
  File "/Users/ms/scrapy-1/.venv/lib/python3.9/site-packages/scrapy/spidermiddlewares/referer.py", line 355, in process_spider_output_async
    async for r in result or ():
  File "/Users/ms/scrapy-1/.venv/lib/python3.9/site-packages/scrapy/core/spidermw.py", line 118, in process_async
    async for r in iterable:
  File "/Users/ms/scrapy-1/.venv/lib/python3.9/site-packages/scrapy/spidermiddlewares/urllength.py", line 30, in process_spider_output_async
    async for r in result or ():
  File "/Users/ms/scrapy-1/.venv/lib/python3.9/site-packages/scrapy/core/spidermw.py", line 118, in process_async
    async for r in iterable:
  File "/Users/ms/scrapy-1/.venv/lib/python3.9/site-packages/scrapy/spidermiddlewares/depth.py", line 35, in process_spider_output_async
    async for r in result or ():
  File "/Users/ms/scrapy-1/.venv/lib/python3.9/site-packages/scrapy/core/spidermw.py", line 118, in process_async
    async for r in iterable:
  File "/Users/ms/scrapy-1/.venv/lib/python3.9/site-packages/scrapy/spiders/crawl.py", line 124, in _parse_response
    for request_or_item in iterate_spider_output(cb_res):
  File "/Users/ms/scrapy-1/scrapy1/scrapy1/spiders/eurolux_spider.py", line 44, in parse_page
    description = bleach_html(response.css('.text-md-h6').get())
  File "/Users/ms/scrapy-1/scrapy1/scrapy1/spiders/eurolux_spider.py", line 15, in bleach_html
    cleaned_html = bleach.clean(html_string, tags=allowed_tags, strip=True)
  File "/Users/ms/scrapy-1/.venv/lib/python3.9/site-packages/bleach/__init__.py", line 82, in clean
    return cleaner.clean(text)
  File "/Users/ms/scrapy-1/.venv/lib/python3.9/site-packages/bleach/sanitizer.py", line 186, in clean
    raise TypeError(message)
TypeError: argument cannot be of 'NoneType' type, must be of text type
2023-11-13 18:46:23 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://eurolux.de/category/brennerei> (referer: https://eurolux.de/)
2023-11-13 18:46:23 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://eurolux.de/category/brauerei> (referer: https://eurolux.de/)
2023-11-13 18:46:23 [scrapy.core.scraper] ERROR: Spider error processing <GET https://eurolux.de/category/brennerei> (referer: https://eurolux.de/)
Traceback (most recent call last):
  File "/Users/ms/scrapy-1/.venv/lib/python3.9/site-packages/scrapy/utils/defer.py", line 295, in aiter_errback
    yield await it.__anext__()
  File "/Users/ms/scrapy-1/.venv/lib/python3.9/site-packages/scrapy/utils/python.py", line 374, in __anext__
    return await self.data.__anext__()
  File "/Users/ms/scrapy-1/.venv/lib/python3.9/site-packages/scrapy/utils/python.py", line 355, in _async_chain
    async for o in as_async_generator(it):
  File "/Users/ms/scrapy-1/.venv/lib/python3.9/site-packages/scrapy/utils/asyncgen.py", line 14, in as_async_generator
    async for r in it:
  File "/Users/ms/scrapy-1/.venv/lib/python3.9/site-packages/scrapy/utils/python.py", line 374, in __anext__
    return await self.data.__anext__()
  File "/Users/ms/scrapy-1/.venv/lib/python3.9/site-packages/scrapy/utils/python.py", line 355, in _async_chain
    async for o in as_async_generator(it):
  File "/Users/ms/scrapy-1/.venv/lib/python3.9/site-packages/scrapy/utils/asyncgen.py", line 14, in as_async_generator
    async for r in it:
  File "/Users/ms/scrapy-1/.venv/lib/python3.9/site-packages/scrapy/core/spidermw.py", line 118, in process_async
    async for r in iterable:
  File "/Users/ms/scrapy-1/.venv/lib/python3.9/site-packages/scrapy/spidermiddlewares/offsite.py", line 31, in process_spider_output_async
    async for r in result or ():
  File "/Users/ms/scrapy-1/.venv/lib/python3.9/site-packages/scrapy/core/spidermw.py", line 118, in process_async
    async for r in iterable:
  File "/Users/ms/scrapy-1/.venv/lib/python3.9/site-packages/scrapy/spidermiddlewares/referer.py", line 355, in process_spider_output_async
    async for r in result or ():
  File "/Users/ms/scrapy-1/.venv/lib/python3.9/site-packages/scrapy/core/spidermw.py", line 118, in process_async
    async for r in iterable:
  File "/Users/ms/scrapy-1/.venv/lib/python3.9/site-packages/scrapy/spidermiddlewares/urllength.py", line 30, in process_spider_output_async
    async for r in result or ():
  File "/Users/ms/scrapy-1/.venv/lib/python3.9/site-packages/scrapy/core/spidermw.py", line 118, in process_async
    async for r in iterable:
  File "/Users/ms/scrapy-1/.venv/lib/python3.9/site-packages/scrapy/spidermiddlewares/depth.py", line 35, in process_spider_output_async
    async for r in result or ():
  File "/Users/ms/scrapy-1/.venv/lib/python3.9/site-packages/scrapy/core/spidermw.py", line 118, in process_async
    async for r in iterable:
  File "/Users/ms/scrapy-1/.venv/lib/python3.9/site-packages/scrapy/spiders/crawl.py", line 124, in _parse_response
    for request_or_item in iterate_spider_output(cb_res):
  File "/Users/ms/scrapy-1/scrapy1/scrapy1/spiders/eurolux_spider.py", line 44, in parse_page
    description = bleach_html(response.css('.text-md-h6').get())
  File "/Users/ms/scrapy-1/scrapy1/scrapy1/spiders/eurolux_spider.py", line 15, in bleach_html
    cleaned_html = bleach.clean(html_string, tags=allowed_tags, strip=True)
  File "/Users/ms/scrapy-1/.venv/lib/python3.9/site-packages/bleach/__init__.py", line 82, in clean
    return cleaner.clean(text)
  File "/Users/ms/scrapy-1/.venv/lib/python3.9/site-packages/bleach/sanitizer.py", line 186, in clean
    raise TypeError(message)
TypeError: argument cannot be of 'NoneType' type, must be of text type
2023-11-13 18:46:23 [scrapy.core.scraper] ERROR: Spider error processing <GET https://eurolux.de/category/brauerei> (referer: https://eurolux.de/)
Traceback (most recent call last):
  File "/Users/ms/scrapy-1/.venv/lib/python3.9/site-packages/scrapy/utils/defer.py", line 295, in aiter_errback
    yield await it.__anext__()
  File "/Users/ms/scrapy-1/.venv/lib/python3.9/site-packages/scrapy/utils/python.py", line 374, in __anext__
    return await self.data.__anext__()
  File "/Users/ms/scrapy-1/.venv/lib/python3.9/site-packages/scrapy/utils/python.py", line 355, in _async_chain
    async for o in as_async_generator(it):
  File "/Users/ms/scrapy-1/.venv/lib/python3.9/site-packages/scrapy/utils/asyncgen.py", line 14, in as_async_generator
    async for r in it:
  File "/Users/ms/scrapy-1/.venv/lib/python3.9/site-packages/scrapy/utils/python.py", line 374, in __anext__
    return await self.data.__anext__()
  File "/Users/ms/scrapy-1/.venv/lib/python3.9/site-packages/scrapy/utils/python.py", line 355, in _async_chain
    async for o in as_async_generator(it):
  File "/Users/ms/scrapy-1/.venv/lib/python3.9/site-packages/scrapy/utils/asyncgen.py", line 14, in as_async_generator
    async for r in it:
  File "/Users/ms/scrapy-1/.venv/lib/python3.9/site-packages/scrapy/core/spidermw.py", line 118, in process_async
    async for r in iterable:
  File "/Users/ms/scrapy-1/.venv/lib/python3.9/site-packages/scrapy/spidermiddlewares/offsite.py", line 31, in process_spider_output_async
    async for r in result or ():
  File "/Users/ms/scrapy-1/.venv/lib/python3.9/site-packages/scrapy/core/spidermw.py", line 118, in process_async
    async for r in iterable:
  File "/Users/ms/scrapy-1/.venv/lib/python3.9/site-packages/scrapy/spidermiddlewares/referer.py", line 355, in process_spider_output_async
    async for r in result or ():
  File "/Users/ms/scrapy-1/.venv/lib/python3.9/site-packages/scrapy/core/spidermw.py", line 118, in process_async
    async for r in iterable:
  File "/Users/ms/scrapy-1/.venv/lib/python3.9/site-packages/scrapy/spidermiddlewares/urllength.py", line 30, in process_spider_output_async
    async for r in result or ():
  File "/Users/ms/scrapy-1/.venv/lib/python3.9/site-packages/scrapy/core/spidermw.py", line 118, in process_async
    async for r in iterable:
  File "/Users/ms/scrapy-1/.venv/lib/python3.9/site-packages/scrapy/spidermiddlewares/depth.py", line 35, in process_spider_output_async
    async for r in result or ():
  File "/Users/ms/scrapy-1/.venv/lib/python3.9/site-packages/scrapy/core/spidermw.py", line 118, in process_async
    async for r in iterable:
  File "/Users/ms/scrapy-1/.venv/lib/python3.9/site-packages/scrapy/spiders/crawl.py", line 124, in _parse_response
    for request_or_item in iterate_spider_output(cb_res):
  File "/Users/ms/scrapy-1/scrapy1/scrapy1/spiders/eurolux_spider.py", line 44, in parse_page
    description = bleach_html(response.css('.text-md-h6').get())
  File "/Users/ms/scrapy-1/scrapy1/scrapy1/spiders/eurolux_spider.py", line 15, in bleach_html
    cleaned_html = bleach.clean(html_string, tags=allowed_tags, strip=True)
  File "/Users/ms/scrapy-1/.venv/lib/python3.9/site-packages/bleach/__init__.py", line 82, in clean
    return cleaner.clean(text)
  File "/Users/ms/scrapy-1/.venv/lib/python3.9/site-packages/bleach/sanitizer.py", line 186, in clean
    raise TypeError(message)
TypeError: argument cannot be of 'NoneType' type, must be of text type
2023-11-13 18:46:24 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://eurolux.de/category/konzentrat-pueree-> (referer: https://eurolux.de/)
2023-11-13 18:46:24 [scrapy.core.scraper] ERROR: Spider error processing <GET https://eurolux.de/category/konzentrat-pueree-> (referer: https://eurolux.de/)
Traceback (most recent call last):
  File "/Users/ms/scrapy-1/.venv/lib/python3.9/site-packages/scrapy/utils/defer.py", line 295, in aiter_errback
    yield await it.__anext__()
  File "/Users/ms/scrapy-1/.venv/lib/python3.9/site-packages/scrapy/utils/python.py", line 374, in __anext__
    return await self.data.__anext__()
  File "/Users/ms/scrapy-1/.venv/lib/python3.9/site-packages/scrapy/utils/python.py", line 355, in _async_chain
    async for o in as_async_generator(it):
  File "/Users/ms/scrapy-1/.venv/lib/python3.9/site-packages/scrapy/utils/asyncgen.py", line 14, in as_async_generator
    async for r in it:
  File "/Users/ms/scrapy-1/.venv/lib/python3.9/site-packages/scrapy/utils/python.py", line 374, in __anext__
    return await self.data.__anext__()
  File "/Users/ms/scrapy-1/.venv/lib/python3.9/site-packages/scrapy/utils/python.py", line 355, in _async_chain
    async for o in as_async_generator(it):
  File "/Users/ms/scrapy-1/.venv/lib/python3.9/site-packages/scrapy/utils/asyncgen.py", line 14, in as_async_generator
    async for r in it:
  File "/Users/ms/scrapy-1/.venv/lib/python3.9/site-packages/scrapy/core/spidermw.py", line 118, in process_async
    async for r in iterable:
  File "/Users/ms/scrapy-1/.venv/lib/python3.9/site-packages/scrapy/spidermiddlewares/offsite.py", line 31, in process_spider_output_async
    async for r in result or ():
  File "/Users/ms/scrapy-1/.venv/lib/python3.9/site-packages/scrapy/core/spidermw.py", line 118, in process_async
    async for r in iterable:
  File "/Users/ms/scrapy-1/.venv/lib/python3.9/site-packages/scrapy/spidermiddlewares/referer.py", line 355, in process_spider_output_async
    async for r in result or ():
  File "/Users/ms/scrapy-1/.venv/lib/python3.9/site-packages/scrapy/core/spidermw.py", line 118, in process_async
    async for r in iterable:
  File "/Users/ms/scrapy-1/.venv/lib/python3.9/site-packages/scrapy/spidermiddlewares/urllength.py", line 30, in process_spider_output_async
    async for r in result or ():
  File "/Users/ms/scrapy-1/.venv/lib/python3.9/site-packages/scrapy/core/spidermw.py", line 118, in process_async
    async for r in iterable:
  File "/Users/ms/scrapy-1/.venv/lib/python3.9/site-packages/scrapy/spidermiddlewares/depth.py", line 35, in process_spider_output_async
    async for r in result or ():
  File "/Users/ms/scrapy-1/.venv/lib/python3.9/site-packages/scrapy/core/spidermw.py", line 118, in process_async
    async for r in iterable:
  File "/Users/ms/scrapy-1/.venv/lib/python3.9/site-packages/scrapy/spiders/crawl.py", line 124, in _parse_response
    for request_or_item in iterate_spider_output(cb_res):
  File "/Users/ms/scrapy-1/scrapy1/scrapy1/spiders/eurolux_spider.py", line 44, in parse_page
    description = bleach_html(response.css('.text-md-h6').get())
  File "/Users/ms/scrapy-1/scrapy1/scrapy1/spiders/eurolux_spider.py", line 15, in bleach_html
    cleaned_html = bleach.clean(html_string, tags=allowed_tags, strip=True)
  File "/Users/ms/scrapy-1/.venv/lib/python3.9/site-packages/bleach/__init__.py", line 82, in clean
    return cleaner.clean(text)
  File "/Users/ms/scrapy-1/.venv/lib/python3.9/site-packages/bleach/sanitizer.py", line 186, in clean
    raise TypeError(message)
TypeError: argument cannot be of 'NoneType' type, must be of text type
2023-11-13 18:46:25 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://eurolux.de/category/konzentrat> (referer: https://eurolux.de/)
2023-11-13 18:46:25 [scrapy.core.scraper] ERROR: Spider error processing <GET https://eurolux.de/category/konzentrat> (referer: https://eurolux.de/)
Traceback (most recent call last):
  File "/Users/ms/scrapy-1/.venv/lib/python3.9/site-packages/scrapy/utils/defer.py", line 295, in aiter_errback
    yield await it.__anext__()
  File "/Users/ms/scrapy-1/.venv/lib/python3.9/site-packages/scrapy/utils/python.py", line 374, in __anext__
    return await self.data.__anext__()
  File "/Users/ms/scrapy-1/.venv/lib/python3.9/site-packages/scrapy/utils/python.py", line 355, in _async_chain
    async for o in as_async_generator(it):
  File "/Users/ms/scrapy-1/.venv/lib/python3.9/site-packages/scrapy/utils/asyncgen.py", line 14, in as_async_generator
    async for r in it:
  File "/Users/ms/scrapy-1/.venv/lib/python3.9/site-packages/scrapy/utils/python.py", line 374, in __anext__
    return await self.data.__anext__()
  File "/Users/ms/scrapy-1/.venv/lib/python3.9/site-packages/scrapy/utils/python.py", line 355, in _async_chain
    async for o in as_async_generator(it):
  File "/Users/ms/scrapy-1/.venv/lib/python3.9/site-packages/scrapy/utils/asyncgen.py", line 14, in as_async_generator
    async for r in it:
  File "/Users/ms/scrapy-1/.venv/lib/python3.9/site-packages/scrapy/core/spidermw.py", line 118, in process_async
    async for r in iterable:
  File "/Users/ms/scrapy-1/.venv/lib/python3.9/site-packages/scrapy/spidermiddlewares/offsite.py", line 31, in process_spider_output_async
    async for r in result or ():
  File "/Users/ms/scrapy-1/.venv/lib/python3.9/site-packages/scrapy/core/spidermw.py", line 118, in process_async
    async for r in iterable:
  File "/Users/ms/scrapy-1/.venv/lib/python3.9/site-packages/scrapy/spidermiddlewares/referer.py", line 355, in process_spider_output_async
    async for r in result or ():
  File "/Users/ms/scrapy-1/.venv/lib/python3.9/site-packages/scrapy/core/spidermw.py", line 118, in process_async
    async for r in iterable:
  File "/Users/ms/scrapy-1/.venv/lib/python3.9/site-packages/scrapy/spidermiddlewares/urllength.py", line 30, in process_spider_output_async
    async for r in result or ():
  File "/Users/ms/scrapy-1/.venv/lib/python3.9/site-packages/scrapy/core/spidermw.py", line 118, in process_async
    async for r in iterable:
  File "/Users/ms/scrapy-1/.venv/lib/python3.9/site-packages/scrapy/spidermiddlewares/depth.py", line 35, in process_spider_output_async
    async for r in result or ():
  File "/Users/ms/scrapy-1/.venv/lib/python3.9/site-packages/scrapy/core/spidermw.py", line 118, in process_async
    async for r in iterable:
  File "/Users/ms/scrapy-1/.venv/lib/python3.9/site-packages/scrapy/spiders/crawl.py", line 124, in _parse_response
    for request_or_item in iterate_spider_output(cb_res):
  File "/Users/ms/scrapy-1/scrapy1/scrapy1/spiders/eurolux_spider.py", line 44, in parse_page
    description = bleach_html(response.css('.text-md-h6').get())
  File "/Users/ms/scrapy-1/scrapy1/scrapy1/spiders/eurolux_spider.py", line 15, in bleach_html
    cleaned_html = bleach.clean(html_string, tags=allowed_tags, strip=True)
  File "/Users/ms/scrapy-1/.venv/lib/python3.9/site-packages/bleach/__init__.py", line 82, in clean
    return cleaner.clean(text)
  File "/Users/ms/scrapy-1/.venv/lib/python3.9/site-packages/bleach/sanitizer.py", line 186, in clean
    raise TypeError(message)
TypeError: argument cannot be of 'NoneType' type, must be of text type
2023-11-13 18:46:25 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://eurolux.de/category/fueller-verschliesser> (referer: https://eurolux.de/)
2023-11-13 18:46:25 [scrapy.core.scraper] ERROR: Spider error processing <GET https://eurolux.de/category/fueller-verschliesser> (referer: https://eurolux.de/)
Traceback (most recent call last):
  File "/Users/ms/scrapy-1/.venv/lib/python3.9/site-packages/scrapy/utils/defer.py", line 295, in aiter_errback
    yield await it.__anext__()
  File "/Users/ms/scrapy-1/.venv/lib/python3.9/site-packages/scrapy/utils/python.py", line 374, in __anext__
    return await self.data.__anext__()
  File "/Users/ms/scrapy-1/.venv/lib/python3.9/site-packages/scrapy/utils/python.py", line 355, in _async_chain
    async for o in as_async_generator(it):
  File "/Users/ms/scrapy-1/.venv/lib/python3.9/site-packages/scrapy/utils/asyncgen.py", line 14, in as_async_generator
    async for r in it:
  File "/Users/ms/scrapy-1/.venv/lib/python3.9/site-packages/scrapy/utils/python.py", line 374, in __anext__
    return await self.data.__anext__()
  File "/Users/ms/scrapy-1/.venv/lib/python3.9/site-packages/scrapy/utils/python.py", line 355, in _async_chain
    async for o in as_async_generator(it):
  File "/Users/ms/scrapy-1/.venv/lib/python3.9/site-packages/scrapy/utils/asyncgen.py", line 14, in as_async_generator
    async for r in it:
  File "/Users/ms/scrapy-1/.venv/lib/python3.9/site-packages/scrapy/core/spidermw.py", line 118, in process_async
    async for r in iterable:
  File "/Users/ms/scrapy-1/.venv/lib/python3.9/site-packages/scrapy/spidermiddlewares/offsite.py", line 31, in process_spider_output_async
    async for r in result or ():
  File "/Users/ms/scrapy-1/.venv/lib/python3.9/site-packages/scrapy/core/spidermw.py", line 118, in process_async
    async for r in iterable:
  File "/Users/ms/scrapy-1/.venv/lib/python3.9/site-packages/scrapy/spidermiddlewares/referer.py", line 355, in process_spider_output_async
    async for r in result or ():
  File "/Users/ms/scrapy-1/.venv/lib/python3.9/site-packages/scrapy/core/spidermw.py", line 118, in process_async
    async for r in iterable:
  File "/Users/ms/scrapy-1/.venv/lib/python3.9/site-packages/scrapy/spidermiddlewares/urllength.py", line 30, in process_spider_output_async
    async for r in result or ():
  File "/Users/ms/scrapy-1/.venv/lib/python3.9/site-packages/scrapy/core/spidermw.py", line 118, in process_async
    async for r in iterable:
  File "/Users/ms/scrapy-1/.venv/lib/python3.9/site-packages/scrapy/spidermiddlewares/depth.py", line 35, in process_spider_output_async
    async for r in result or ():
  File "/Users/ms/scrapy-1/.venv/lib/python3.9/site-packages/scrapy/core/spidermw.py", line 118, in process_async
    async for r in iterable:
  File "/Users/ms/scrapy-1/.venv/lib/python3.9/site-packages/scrapy/spiders/crawl.py", line 124, in _parse_response
    for request_or_item in iterate_spider_output(cb_res):
  File "/Users/ms/scrapy-1/scrapy1/scrapy1/spiders/eurolux_spider.py", line 44, in parse_page
    description = bleach_html(response.css('.text-md-h6').get())
  File "/Users/ms/scrapy-1/scrapy1/scrapy1/spiders/eurolux_spider.py", line 15, in bleach_html
    cleaned_html = bleach.clean(html_string, tags=allowed_tags, strip=True)
  File "/Users/ms/scrapy-1/.venv/lib/python3.9/site-packages/bleach/__init__.py", line 82, in clean
    return cleaner.clean(text)
  File "/Users/ms/scrapy-1/.venv/lib/python3.9/site-packages/bleach/sanitizer.py", line 186, in clean
    raise TypeError(message)
TypeError: argument cannot be of 'NoneType' type, must be of text type
2023-11-13 18:46:26 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://eurolux.de/category/etikettierer-ausstattung> (referer: https://eurolux.de/)
2023-11-13 18:46:26 [scrapy.core.scraper] ERROR: Spider error processing <GET https://eurolux.de/category/etikettierer-ausstattung> (referer: https://eurolux.de/)
Traceback (most recent call last):
  File "/Users/ms/scrapy-1/.venv/lib/python3.9/site-packages/scrapy/utils/defer.py", line 295, in aiter_errback
    yield await it.__anext__()
  File "/Users/ms/scrapy-1/.venv/lib/python3.9/site-packages/scrapy/utils/python.py", line 374, in __anext__
    return await self.data.__anext__()
  File "/Users/ms/scrapy-1/.venv/lib/python3.9/site-packages/scrapy/utils/python.py", line 355, in _async_chain
    async for o in as_async_generator(it):
  File "/Users/ms/scrapy-1/.venv/lib/python3.9/site-packages/scrapy/utils/asyncgen.py", line 14, in as_async_generator
    async for r in it:
  File "/Users/ms/scrapy-1/.venv/lib/python3.9/site-packages/scrapy/utils/python.py", line 374, in __anext__
    return await self.data.__anext__()
  File "/Users/ms/scrapy-1/.venv/lib/python3.9/site-packages/scrapy/utils/python.py", line 355, in _async_chain
    async for o in as_async_generator(it):
  File "/Users/ms/scrapy-1/.venv/lib/python3.9/site-packages/scrapy/utils/asyncgen.py", line 14, in as_async_generator
    async for r in it:
  File "/Users/ms/scrapy-1/.venv/lib/python3.9/site-packages/scrapy/core/spidermw.py", line 118, in process_async
    async for r in iterable:
  File "/Users/ms/scrapy-1/.venv/lib/python3.9/site-packages/scrapy/spidermiddlewares/offsite.py", line 31, in process_spider_output_async
    async for r in result or ():
  File "/Users/ms/scrapy-1/.venv/lib/python3.9/site-packages/scrapy/core/spidermw.py", line 118, in process_async
    async for r in iterable:
  File "/Users/ms/scrapy-1/.venv/lib/python3.9/site-packages/scrapy/spidermiddlewares/referer.py", line 355, in process_spider_output_async
    async for r in result or ():
  File "/Users/ms/scrapy-1/.venv/lib/python3.9/site-packages/scrapy/core/spidermw.py", line 118, in process_async
    async for r in iterable:
  File "/Users/ms/scrapy-1/.venv/lib/python3.9/site-packages/scrapy/spidermiddlewares/urllength.py", line 30, in process_spider_output_async
    async for r in result or ():
  File "/Users/ms/scrapy-1/.venv/lib/python3.9/site-packages/scrapy/core/spidermw.py", line 118, in process_async
    async for r in iterable:
  File "/Users/ms/scrapy-1/.venv/lib/python3.9/site-packages/scrapy/spidermiddlewares/depth.py", line 35, in process_spider_output_async
    async for r in result or ():
  File "/Users/ms/scrapy-1/.venv/lib/python3.9/site-packages/scrapy/core/spidermw.py", line 118, in process_async
    async for r in iterable:
  File "/Users/ms/scrapy-1/.venv/lib/python3.9/site-packages/scrapy/spiders/crawl.py", line 124, in _parse_response
    for request_or_item in iterate_spider_output(cb_res):
  File "/Users/ms/scrapy-1/scrapy1/scrapy1/spiders/eurolux_spider.py", line 44, in parse_page
    description = bleach_html(response.css('.text-md-h6').get())
  File "/Users/ms/scrapy-1/scrapy1/scrapy1/spiders/eurolux_spider.py", line 15, in bleach_html
    cleaned_html = bleach.clean(html_string, tags=allowed_tags, strip=True)
  File "/Users/ms/scrapy-1/.venv/lib/python3.9/site-packages/bleach/__init__.py", line 82, in clean
    return cleaner.clean(text)
  File "/Users/ms/scrapy-1/.venv/lib/python3.9/site-packages/bleach/sanitizer.py", line 186, in clean
    raise TypeError(message)
TypeError: argument cannot be of 'NoneType' type, must be of text type
2023-11-13 18:46:27 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://eurolux.de/category/lebensmittel-technik-diverse> (referer: https://eurolux.de/)
2023-11-13 18:46:27 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://eurolux.de/category/kompl-abfuell-prozessanlagen> (referer: https://eurolux.de/)
2023-11-13 18:46:27 [scrapy.core.scraper] ERROR: Spider error processing <GET https://eurolux.de/category/lebensmittel-technik-diverse> (referer: https://eurolux.de/)
Traceback (most recent call last):
  File "/Users/ms/scrapy-1/.venv/lib/python3.9/site-packages/scrapy/utils/defer.py", line 295, in aiter_errback
    yield await it.__anext__()
  File "/Users/ms/scrapy-1/.venv/lib/python3.9/site-packages/scrapy/utils/python.py", line 374, in __anext__
    return await self.data.__anext__()
  File "/Users/ms/scrapy-1/.venv/lib/python3.9/site-packages/scrapy/utils/python.py", line 355, in _async_chain
    async for o in as_async_generator(it):
  File "/Users/ms/scrapy-1/.venv/lib/python3.9/site-packages/scrapy/utils/asyncgen.py", line 14, in as_async_generator
    async for r in it:
  File "/Users/ms/scrapy-1/.venv/lib/python3.9/site-packages/scrapy/utils/python.py", line 374, in __anext__
    return await self.data.__anext__()
  File "/Users/ms/scrapy-1/.venv/lib/python3.9/site-packages/scrapy/utils/python.py", line 355, in _async_chain
    async for o in as_async_generator(it):
  File "/Users/ms/scrapy-1/.venv/lib/python3.9/site-packages/scrapy/utils/asyncgen.py", line 14, in as_async_generator
    async for r in it:
  File "/Users/ms/scrapy-1/.venv/lib/python3.9/site-packages/scrapy/core/spidermw.py", line 118, in process_async
    async for r in iterable:
  File "/Users/ms/scrapy-1/.venv/lib/python3.9/site-packages/scrapy/spidermiddlewares/offsite.py", line 31, in process_spider_output_async
    async for r in result or ():
  File "/Users/ms/scrapy-1/.venv/lib/python3.9/site-packages/scrapy/core/spidermw.py", line 118, in process_async
    async for r in iterable:
  File "/Users/ms/scrapy-1/.venv/lib/python3.9/site-packages/scrapy/spidermiddlewares/referer.py", line 355, in process_spider_output_async
    async for r in result or ():
  File "/Users/ms/scrapy-1/.venv/lib/python3.9/site-packages/scrapy/core/spidermw.py", line 118, in process_async
    async for r in iterable:
  File "/Users/ms/scrapy-1/.venv/lib/python3.9/site-packages/scrapy/spidermiddlewares/urllength.py", line 30, in process_spider_output_async
    async for r in result or ():
  File "/Users/ms/scrapy-1/.venv/lib/python3.9/site-packages/scrapy/core/spidermw.py", line 118, in process_async
    async for r in iterable:
  File "/Users/ms/scrapy-1/.venv/lib/python3.9/site-packages/scrapy/spidermiddlewares/depth.py", line 35, in process_spider_output_async
    async for r in result or ():
  File "/Users/ms/scrapy-1/.venv/lib/python3.9/site-packages/scrapy/core/spidermw.py", line 118, in process_async
    async for r in iterable:
  File "/Users/ms/scrapy-1/.venv/lib/python3.9/site-packages/scrapy/spiders/crawl.py", line 124, in _parse_response
    for request_or_item in iterate_spider_output(cb_res):
  File "/Users/ms/scrapy-1/scrapy1/scrapy1/spiders/eurolux_spider.py", line 44, in parse_page
    description = bleach_html(response.css('.text-md-h6').get())
  File "/Users/ms/scrapy-1/scrapy1/scrapy1/spiders/eurolux_spider.py", line 15, in bleach_html
    cleaned_html = bleach.clean(html_string, tags=allowed_tags, strip=True)
  File "/Users/ms/scrapy-1/.venv/lib/python3.9/site-packages/bleach/__init__.py", line 82, in clean
    return cleaner.clean(text)
  File "/Users/ms/scrapy-1/.venv/lib/python3.9/site-packages/bleach/sanitizer.py", line 186, in clean
    raise TypeError(message)
TypeError: argument cannot be of 'NoneType' type, must be of text type
2023-11-13 18:46:27 [scrapy.core.scraper] ERROR: Spider error processing <GET https://eurolux.de/category/kompl-abfuell-prozessanlagen> (referer: https://eurolux.de/)
Traceback (most recent call last):
  File "/Users/ms/scrapy-1/.venv/lib/python3.9/site-packages/scrapy/utils/defer.py", line 295, in aiter_errback
    yield await it.__anext__()
  File "/Users/ms/scrapy-1/.venv/lib/python3.9/site-packages/scrapy/utils/python.py", line 374, in __anext__
    return await self.data.__anext__()
  File "/Users/ms/scrapy-1/.venv/lib/python3.9/site-packages/scrapy/utils/python.py", line 355, in _async_chain
    async for o in as_async_generator(it):
  File "/Users/ms/scrapy-1/.venv/lib/python3.9/site-packages/scrapy/utils/asyncgen.py", line 14, in as_async_generator
    async for r in it:
  File "/Users/ms/scrapy-1/.venv/lib/python3.9/site-packages/scrapy/utils/python.py", line 374, in __anext__
    return await self.data.__anext__()
  File "/Users/ms/scrapy-1/.venv/lib/python3.9/site-packages/scrapy/utils/python.py", line 355, in _async_chain
    async for o in as_async_generator(it):
  File "/Users/ms/scrapy-1/.venv/lib/python3.9/site-packages/scrapy/utils/asyncgen.py", line 14, in as_async_generator
    async for r in it:
  File "/Users/ms/scrapy-1/.venv/lib/python3.9/site-packages/scrapy/core/spidermw.py", line 118, in process_async
    async for r in iterable:
  File "/Users/ms/scrapy-1/.venv/lib/python3.9/site-packages/scrapy/spidermiddlewares/offsite.py", line 31, in process_spider_output_async
    async for r in result or ():
  File "/Users/ms/scrapy-1/.venv/lib/python3.9/site-packages/scrapy/core/spidermw.py", line 118, in process_async
    async for r in iterable:
  File "/Users/ms/scrapy-1/.venv/lib/python3.9/site-packages/scrapy/spidermiddlewares/referer.py", line 355, in process_spider_output_async
    async for r in result or ():
  File "/Users/ms/scrapy-1/.venv/lib/python3.9/site-packages/scrapy/core/spidermw.py", line 118, in process_async
    async for r in iterable:
  File "/Users/ms/scrapy-1/.venv/lib/python3.9/site-packages/scrapy/spidermiddlewares/urllength.py", line 30, in process_spider_output_async
    async for r in result or ():
  File "/Users/ms/scrapy-1/.venv/lib/python3.9/site-packages/scrapy/core/spidermw.py", line 118, in process_async
    async for r in iterable:
  File "/Users/ms/scrapy-1/.venv/lib/python3.9/site-packages/scrapy/spidermiddlewares/depth.py", line 35, in process_spider_output_async
    async for r in result or ():
  File "/Users/ms/scrapy-1/.venv/lib/python3.9/site-packages/scrapy/core/spidermw.py", line 118, in process_async
    async for r in iterable:
  File "/Users/ms/scrapy-1/.venv/lib/python3.9/site-packages/scrapy/spiders/crawl.py", line 124, in _parse_response
    for request_or_item in iterate_spider_output(cb_res):
  File "/Users/ms/scrapy-1/scrapy1/scrapy1/spiders/eurolux_spider.py", line 44, in parse_page
    description = bleach_html(response.css('.text-md-h6').get())
  File "/Users/ms/scrapy-1/scrapy1/scrapy1/spiders/eurolux_spider.py", line 15, in bleach_html
    cleaned_html = bleach.clean(html_string, tags=allowed_tags, strip=True)
  File "/Users/ms/scrapy-1/.venv/lib/python3.9/site-packages/bleach/__init__.py", line 82, in clean
    return cleaner.clean(text)
  File "/Users/ms/scrapy-1/.venv/lib/python3.9/site-packages/bleach/sanitizer.py", line 186, in clean
    raise TypeError(message)
TypeError: argument cannot be of 'NoneType' type, must be of text type
2023-11-13 18:46:28 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://eurolux.de/category/dampferzeuger> (referer: https://eurolux.de/)
2023-11-13 18:46:28 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://eurolux.de/category/lebensmittel-technik> (referer: https://eurolux.de/)
2023-11-13 18:46:28 [scrapy.core.scraper] ERROR: Spider error processing <GET https://eurolux.de/category/dampferzeuger> (referer: https://eurolux.de/)
Traceback (most recent call last):
  File "/Users/ms/scrapy-1/.venv/lib/python3.9/site-packages/scrapy/utils/defer.py", line 295, in aiter_errback
    yield await it.__anext__()
  File "/Users/ms/scrapy-1/.venv/lib/python3.9/site-packages/scrapy/utils/python.py", line 374, in __anext__
    return await self.data.__anext__()
  File "/Users/ms/scrapy-1/.venv/lib/python3.9/site-packages/scrapy/utils/python.py", line 355, in _async_chain
    async for o in as_async_generator(it):
  File "/Users/ms/scrapy-1/.venv/lib/python3.9/site-packages/scrapy/utils/asyncgen.py", line 14, in as_async_generator
    async for r in it:
  File "/Users/ms/scrapy-1/.venv/lib/python3.9/site-packages/scrapy/utils/python.py", line 374, in __anext__
    return await self.data.__anext__()
  File "/Users/ms/scrapy-1/.venv/lib/python3.9/site-packages/scrapy/utils/python.py", line 355, in _async_chain
    async for o in as_async_generator(it):
  File "/Users/ms/scrapy-1/.venv/lib/python3.9/site-packages/scrapy/utils/asyncgen.py", line 14, in as_async_generator
    async for r in it:
  File "/Users/ms/scrapy-1/.venv/lib/python3.9/site-packages/scrapy/core/spidermw.py", line 118, in process_async
    async for r in iterable:
  File "/Users/ms/scrapy-1/.venv/lib/python3.9/site-packages/scrapy/spidermiddlewares/offsite.py", line 31, in process_spider_output_async
    async for r in result or ():
  File "/Users/ms/scrapy-1/.venv/lib/python3.9/site-packages/scrapy/core/spidermw.py", line 118, in process_async
    async for r in iterable:
  File "/Users/ms/scrapy-1/.venv/lib/python3.9/site-packages/scrapy/spidermiddlewares/referer.py", line 355, in process_spider_output_async
    async for r in result or ():
  File "/Users/ms/scrapy-1/.venv/lib/python3.9/site-packages/scrapy/core/spidermw.py", line 118, in process_async
    async for r in iterable:
  File "/Users/ms/scrapy-1/.venv/lib/python3.9/site-packages/scrapy/spidermiddlewares/urllength.py", line 30, in process_spider_output_async
    async for r in result or ():
  File "/Users/ms/scrapy-1/.venv/lib/python3.9/site-packages/scrapy/core/spidermw.py", line 118, in process_async
    async for r in iterable:
  File "/Users/ms/scrapy-1/.venv/lib/python3.9/site-packages/scrapy/spidermiddlewares/depth.py", line 35, in process_spider_output_async
    async for r in result or ():
  File "/Users/ms/scrapy-1/.venv/lib/python3.9/site-packages/scrapy/core/spidermw.py", line 118, in process_async
    async for r in iterable:
  File "/Users/ms/scrapy-1/.venv/lib/python3.9/site-packages/scrapy/spiders/crawl.py", line 124, in _parse_response
    for request_or_item in iterate_spider_output(cb_res):
  File "/Users/ms/scrapy-1/scrapy1/scrapy1/spiders/eurolux_spider.py", line 44, in parse_page
    description = bleach_html(response.css('.text-md-h6').get())
  File "/Users/ms/scrapy-1/scrapy1/scrapy1/spiders/eurolux_spider.py", line 15, in bleach_html
    cleaned_html = bleach.clean(html_string, tags=allowed_tags, strip=True)
  File "/Users/ms/scrapy-1/.venv/lib/python3.9/site-packages/bleach/__init__.py", line 82, in clean
    return cleaner.clean(text)
  File "/Users/ms/scrapy-1/.venv/lib/python3.9/site-packages/bleach/sanitizer.py", line 186, in clean
    raise TypeError(message)
TypeError: argument cannot be of 'NoneType' type, must be of text type
2023-11-13 18:46:28 [scrapy.core.scraper] ERROR: Spider error processing <GET https://eurolux.de/category/lebensmittel-technik> (referer: https://eurolux.de/)
Traceback (most recent call last):
  File "/Users/ms/scrapy-1/.venv/lib/python3.9/site-packages/scrapy/utils/defer.py", line 295, in aiter_errback
    yield await it.__anext__()
  File "/Users/ms/scrapy-1/.venv/lib/python3.9/site-packages/scrapy/utils/python.py", line 374, in __anext__
    return await self.data.__anext__()
  File "/Users/ms/scrapy-1/.venv/lib/python3.9/site-packages/scrapy/utils/python.py", line 355, in _async_chain
    async for o in as_async_generator(it):
  File "/Users/ms/scrapy-1/.venv/lib/python3.9/site-packages/scrapy/utils/asyncgen.py", line 14, in as_async_generator
    async for r in it:
  File "/Users/ms/scrapy-1/.venv/lib/python3.9/site-packages/scrapy/utils/python.py", line 374, in __anext__
    return await self.data.__anext__()
  File "/Users/ms/scrapy-1/.venv/lib/python3.9/site-packages/scrapy/utils/python.py", line 355, in _async_chain
    async for o in as_async_generator(it):
  File "/Users/ms/scrapy-1/.venv/lib/python3.9/site-packages/scrapy/utils/asyncgen.py", line 14, in as_async_generator
    async for r in it:
  File "/Users/ms/scrapy-1/.venv/lib/python3.9/site-packages/scrapy/core/spidermw.py", line 118, in process_async
    async for r in iterable:
  File "/Users/ms/scrapy-1/.venv/lib/python3.9/site-packages/scrapy/spidermiddlewares/offsite.py", line 31, in process_spider_output_async
    async for r in result or ():
  File "/Users/ms/scrapy-1/.venv/lib/python3.9/site-packages/scrapy/core/spidermw.py", line 118, in process_async
    async for r in iterable:
  File "/Users/ms/scrapy-1/.venv/lib/python3.9/site-packages/scrapy/spidermiddlewares/referer.py", line 355, in process_spider_output_async
    async for r in result or ():
  File "/Users/ms/scrapy-1/.venv/lib/python3.9/site-packages/scrapy/core/spidermw.py", line 118, in process_async
    async for r in iterable:
  File "/Users/ms/scrapy-1/.venv/lib/python3.9/site-packages/scrapy/spidermiddlewares/urllength.py", line 30, in process_spider_output_async
    async for r in result or ():
  File "/Users/ms/scrapy-1/.venv/lib/python3.9/site-packages/scrapy/core/spidermw.py", line 118, in process_async
    async for r in iterable:
  File "/Users/ms/scrapy-1/.venv/lib/python3.9/site-packages/scrapy/spidermiddlewares/depth.py", line 35, in process_spider_output_async
    async for r in result or ():
  File "/Users/ms/scrapy-1/.venv/lib/python3.9/site-packages/scrapy/core/spidermw.py", line 118, in process_async
    async for r in iterable:
  File "/Users/ms/scrapy-1/.venv/lib/python3.9/site-packages/scrapy/spiders/crawl.py", line 124, in _parse_response
    for request_or_item in iterate_spider_output(cb_res):
  File "/Users/ms/scrapy-1/scrapy1/scrapy1/spiders/eurolux_spider.py", line 44, in parse_page
    description = bleach_html(response.css('.text-md-h6').get())
  File "/Users/ms/scrapy-1/scrapy1/scrapy1/spiders/eurolux_spider.py", line 15, in bleach_html
    cleaned_html = bleach.clean(html_string, tags=allowed_tags, strip=True)
  File "/Users/ms/scrapy-1/.venv/lib/python3.9/site-packages/bleach/__init__.py", line 82, in clean
    return cleaner.clean(text)
  File "/Users/ms/scrapy-1/.venv/lib/python3.9/site-packages/bleach/sanitizer.py", line 186, in clean
    raise TypeError(message)
TypeError: argument cannot be of 'NoneType' type, must be of text type
2023-11-13 18:46:28 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://eurolux.de/category/getranke-und-technik-diverse> (referer: https://eurolux.de/)
2023-11-13 18:46:28 [scrapy.core.scraper] ERROR: Spider error processing <GET https://eurolux.de/category/getranke-und-technik-diverse> (referer: https://eurolux.de/)
Traceback (most recent call last):
  File "/Users/ms/scrapy-1/.venv/lib/python3.9/site-packages/scrapy/utils/defer.py", line 295, in aiter_errback
    yield await it.__anext__()
  File "/Users/ms/scrapy-1/.venv/lib/python3.9/site-packages/scrapy/utils/python.py", line 374, in __anext__
    return await self.data.__anext__()
  File "/Users/ms/scrapy-1/.venv/lib/python3.9/site-packages/scrapy/utils/python.py", line 355, in _async_chain
    async for o in as_async_generator(it):
  File "/Users/ms/scrapy-1/.venv/lib/python3.9/site-packages/scrapy/utils/asyncgen.py", line 14, in as_async_generator
    async for r in it:
  File "/Users/ms/scrapy-1/.venv/lib/python3.9/site-packages/scrapy/utils/python.py", line 374, in __anext__
    return await self.data.__anext__()
  File "/Users/ms/scrapy-1/.venv/lib/python3.9/site-packages/scrapy/utils/python.py", line 355, in _async_chain
    async for o in as_async_generator(it):
  File "/Users/ms/scrapy-1/.venv/lib/python3.9/site-packages/scrapy/utils/asyncgen.py", line 14, in as_async_generator
    async for r in it:
  File "/Users/ms/scrapy-1/.venv/lib/python3.9/site-packages/scrapy/core/spidermw.py", line 118, in process_async
    async for r in iterable:
  File "/Users/ms/scrapy-1/.venv/lib/python3.9/site-packages/scrapy/spidermiddlewares/offsite.py", line 31, in process_spider_output_async
    async for r in result or ():
  File "/Users/ms/scrapy-1/.venv/lib/python3.9/site-packages/scrapy/core/spidermw.py", line 118, in process_async
    async for r in iterable:
  File "/Users/ms/scrapy-1/.venv/lib/python3.9/site-packages/scrapy/spidermiddlewares/referer.py", line 355, in process_spider_output_async
    async for r in result or ():
  File "/Users/ms/scrapy-1/.venv/lib/python3.9/site-packages/scrapy/core/spidermw.py", line 118, in process_async
    async for r in iterable:
  File "/Users/ms/scrapy-1/.venv/lib/python3.9/site-packages/scrapy/spidermiddlewares/urllength.py", line 30, in process_spider_output_async
    async for r in result or ():
  File "/Users/ms/scrapy-1/.venv/lib/python3.9/site-packages/scrapy/core/spidermw.py", line 118, in process_async
    async for r in iterable:
  File "/Users/ms/scrapy-1/.venv/lib/python3.9/site-packages/scrapy/spidermiddlewares/depth.py", line 35, in process_spider_output_async
    async for r in result or ():
  File "/Users/ms/scrapy-1/.venv/lib/python3.9/site-packages/scrapy/core/spidermw.py", line 118, in process_async
    async for r in iterable:
  File "/Users/ms/scrapy-1/.venv/lib/python3.9/site-packages/scrapy/spiders/crawl.py", line 124, in _parse_response
    for request_or_item in iterate_spider_output(cb_res):
  File "/Users/ms/scrapy-1/scrapy1/scrapy1/spiders/eurolux_spider.py", line 44, in parse_page
    description = bleach_html(response.css('.text-md-h6').get())
  File "/Users/ms/scrapy-1/scrapy1/scrapy1/spiders/eurolux_spider.py", line 15, in bleach_html
    cleaned_html = bleach.clean(html_string, tags=allowed_tags, strip=True)
  File "/Users/ms/scrapy-1/.venv/lib/python3.9/site-packages/bleach/__init__.py", line 82, in clean
    return cleaner.clean(text)
  File "/Users/ms/scrapy-1/.venv/lib/python3.9/site-packages/bleach/sanitizer.py", line 186, in clean
    raise TypeError(message)
TypeError: argument cannot be of 'NoneType' type, must be of text type
2023-11-13 18:46:28 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://eurolux.de/category/fueller-verschliesser-rinser> (referer: https://eurolux.de/)
2023-11-13 18:46:29 [scrapy.core.scraper] ERROR: Spider error processing <GET https://eurolux.de/category/fueller-verschliesser-rinser> (referer: https://eurolux.de/)
Traceback (most recent call last):
  File "/Users/ms/scrapy-1/.venv/lib/python3.9/site-packages/scrapy/utils/defer.py", line 295, in aiter_errback
    yield await it.__anext__()
  File "/Users/ms/scrapy-1/.venv/lib/python3.9/site-packages/scrapy/utils/python.py", line 374, in __anext__
    return await self.data.__anext__()
  File "/Users/ms/scrapy-1/.venv/lib/python3.9/site-packages/scrapy/utils/python.py", line 355, in _async_chain
    async for o in as_async_generator(it):
  File "/Users/ms/scrapy-1/.venv/lib/python3.9/site-packages/scrapy/utils/asyncgen.py", line 14, in as_async_generator
    async for r in it:
  File "/Users/ms/scrapy-1/.venv/lib/python3.9/site-packages/scrapy/utils/python.py", line 374, in __anext__
    return await self.data.__anext__()
  File "/Users/ms/scrapy-1/.venv/lib/python3.9/site-packages/scrapy/utils/python.py", line 355, in _async_chain
    async for o in as_async_generator(it):
  File "/Users/ms/scrapy-1/.venv/lib/python3.9/site-packages/scrapy/utils/asyncgen.py", line 14, in as_async_generator
    async for r in it:
  File "/Users/ms/scrapy-1/.venv/lib/python3.9/site-packages/scrapy/core/spidermw.py", line 118, in process_async
    async for r in iterable:
  File "/Users/ms/scrapy-1/.venv/lib/python3.9/site-packages/scrapy/spidermiddlewares/offsite.py", line 31, in process_spider_output_async
    async for r in result or ():
  File "/Users/ms/scrapy-1/.venv/lib/python3.9/site-packages/scrapy/core/spidermw.py", line 118, in process_async
    async for r in iterable:
  File "/Users/ms/scrapy-1/.venv/lib/python3.9/site-packages/scrapy/spidermiddlewares/referer.py", line 355, in process_spider_output_async
    async for r in result or ():
  File "/Users/ms/scrapy-1/.venv/lib/python3.9/site-packages/scrapy/core/spidermw.py", line 118, in process_async
    async for r in iterable:
  File "/Users/ms/scrapy-1/.venv/lib/python3.9/site-packages/scrapy/spidermiddlewares/urllength.py", line 30, in process_spider_output_async
    async for r in result or ():
  File "/Users/ms/scrapy-1/.venv/lib/python3.9/site-packages/scrapy/core/spidermw.py", line 118, in process_async
    async for r in iterable:
  File "/Users/ms/scrapy-1/.venv/lib/python3.9/site-packages/scrapy/spidermiddlewares/depth.py", line 35, in process_spider_output_async
    async for r in result or ():
  File "/Users/ms/scrapy-1/.venv/lib/python3.9/site-packages/scrapy/core/spidermw.py", line 118, in process_async
    async for r in iterable:
  File "/Users/ms/scrapy-1/.venv/lib/python3.9/site-packages/scrapy/spiders/crawl.py", line 124, in _parse_response
    for request_or_item in iterate_spider_output(cb_res):
  File "/Users/ms/scrapy-1/scrapy1/scrapy1/spiders/eurolux_spider.py", line 44, in parse_page
    description = bleach_html(response.css('.text-md-h6').get())
  File "/Users/ms/scrapy-1/scrapy1/scrapy1/spiders/eurolux_spider.py", line 15, in bleach_html
    cleaned_html = bleach.clean(html_string, tags=allowed_tags, strip=True)
  File "/Users/ms/scrapy-1/.venv/lib/python3.9/site-packages/bleach/__init__.py", line 82, in clean
    return cleaner.clean(text)
  File "/Users/ms/scrapy-1/.venv/lib/python3.9/site-packages/bleach/sanitizer.py", line 186, in clean
    raise TypeError(message)
TypeError: argument cannot be of 'NoneType' type, must be of text type
2023-11-13 18:46:29 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://eurolux.de/category/verpacken-palettieren> (referer: https://eurolux.de/)
2023-11-13 18:46:29 [scrapy.core.scraper] ERROR: Spider error processing <GET https://eurolux.de/category/verpacken-palettieren> (referer: https://eurolux.de/)
Traceback (most recent call last):
  File "/Users/ms/scrapy-1/.venv/lib/python3.9/site-packages/scrapy/utils/defer.py", line 295, in aiter_errback
    yield await it.__anext__()
  File "/Users/ms/scrapy-1/.venv/lib/python3.9/site-packages/scrapy/utils/python.py", line 374, in __anext__
    return await self.data.__anext__()
  File "/Users/ms/scrapy-1/.venv/lib/python3.9/site-packages/scrapy/utils/python.py", line 355, in _async_chain
    async for o in as_async_generator(it):
  File "/Users/ms/scrapy-1/.venv/lib/python3.9/site-packages/scrapy/utils/asyncgen.py", line 14, in as_async_generator
    async for r in it:
  File "/Users/ms/scrapy-1/.venv/lib/python3.9/site-packages/scrapy/utils/python.py", line 374, in __anext__
    return await self.data.__anext__()
  File "/Users/ms/scrapy-1/.venv/lib/python3.9/site-packages/scrapy/utils/python.py", line 355, in _async_chain
    async for o in as_async_generator(it):
  File "/Users/ms/scrapy-1/.venv/lib/python3.9/site-packages/scrapy/utils/asyncgen.py", line 14, in as_async_generator
    async for r in it:
  File "/Users/ms/scrapy-1/.venv/lib/python3.9/site-packages/scrapy/core/spidermw.py", line 118, in process_async
    async for r in iterable:
  File "/Users/ms/scrapy-1/.venv/lib/python3.9/site-packages/scrapy/spidermiddlewares/offsite.py", line 31, in process_spider_output_async
    async for r in result or ():
  File "/Users/ms/scrapy-1/.venv/lib/python3.9/site-packages/scrapy/core/spidermw.py", line 118, in process_async
    async for r in iterable:
  File "/Users/ms/scrapy-1/.venv/lib/python3.9/site-packages/scrapy/spidermiddlewares/referer.py", line 355, in process_spider_output_async
    async for r in result or ():
  File "/Users/ms/scrapy-1/.venv/lib/python3.9/site-packages/scrapy/core/spidermw.py", line 118, in process_async
    async for r in iterable:
  File "/Users/ms/scrapy-1/.venv/lib/python3.9/site-packages/scrapy/spidermiddlewares/urllength.py", line 30, in process_spider_output_async
    async for r in result or ():
  File "/Users/ms/scrapy-1/.venv/lib/python3.9/site-packages/scrapy/core/spidermw.py", line 118, in process_async
    async for r in iterable:
  File "/Users/ms/scrapy-1/.venv/lib/python3.9/site-packages/scrapy/spidermiddlewares/depth.py", line 35, in process_spider_output_async
    async for r in result or ():
  File "/Users/ms/scrapy-1/.venv/lib/python3.9/site-packages/scrapy/core/spidermw.py", line 118, in process_async
    async for r in iterable:
  File "/Users/ms/scrapy-1/.venv/lib/python3.9/site-packages/scrapy/spiders/crawl.py", line 124, in _parse_response
    for request_or_item in iterate_spider_output(cb_res):
  File "/Users/ms/scrapy-1/scrapy1/scrapy1/spiders/eurolux_spider.py", line 44, in parse_page
    description = bleach_html(response.css('.text-md-h6').get())
  File "/Users/ms/scrapy-1/scrapy1/scrapy1/spiders/eurolux_spider.py", line 15, in bleach_html
    cleaned_html = bleach.clean(html_string, tags=allowed_tags, strip=True)
  File "/Users/ms/scrapy-1/.venv/lib/python3.9/site-packages/bleach/__init__.py", line 82, in clean
    return cleaner.clean(text)
  File "/Users/ms/scrapy-1/.venv/lib/python3.9/site-packages/bleach/sanitizer.py", line 186, in clean
    raise TypeError(message)
TypeError: argument cannot be of 'NoneType' type, must be of text type
2023-11-13 18:46:29 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://eurolux.de/category/etikettierer-ausstattung-> (referer: https://eurolux.de/)
2023-11-13 18:46:30 [scrapy.core.scraper] ERROR: Spider error processing <GET https://eurolux.de/category/etikettierer-ausstattung-> (referer: https://eurolux.de/)
Traceback (most recent call last):
  File "/Users/ms/scrapy-1/.venv/lib/python3.9/site-packages/scrapy/utils/defer.py", line 295, in aiter_errback
    yield await it.__anext__()
  File "/Users/ms/scrapy-1/.venv/lib/python3.9/site-packages/scrapy/utils/python.py", line 374, in __anext__
    return await self.data.__anext__()
  File "/Users/ms/scrapy-1/.venv/lib/python3.9/site-packages/scrapy/utils/python.py", line 355, in _async_chain
    async for o in as_async_generator(it):
  File "/Users/ms/scrapy-1/.venv/lib/python3.9/site-packages/scrapy/utils/asyncgen.py", line 14, in as_async_generator
    async for r in it:
  File "/Users/ms/scrapy-1/.venv/lib/python3.9/site-packages/scrapy/utils/python.py", line 374, in __anext__
    return await self.data.__anext__()
  File "/Users/ms/scrapy-1/.venv/lib/python3.9/site-packages/scrapy/utils/python.py", line 355, in _async_chain
    async for o in as_async_generator(it):
  File "/Users/ms/scrapy-1/.venv/lib/python3.9/site-packages/scrapy/utils/asyncgen.py", line 14, in as_async_generator
    async for r in it:
  File "/Users/ms/scrapy-1/.venv/lib/python3.9/site-packages/scrapy/core/spidermw.py", line 118, in process_async
    async for r in iterable:
  File "/Users/ms/scrapy-1/.venv/lib/python3.9/site-packages/scrapy/spidermiddlewares/offsite.py", line 31, in process_spider_output_async
    async for r in result or ():
  File "/Users/ms/scrapy-1/.venv/lib/python3.9/site-packages/scrapy/core/spidermw.py", line 118, in process_async
    async for r in iterable:
  File "/Users/ms/scrapy-1/.venv/lib/python3.9/site-packages/scrapy/spidermiddlewares/referer.py", line 355, in process_spider_output_async
    async for r in result or ():
  File "/Users/ms/scrapy-1/.venv/lib/python3.9/site-packages/scrapy/core/spidermw.py", line 118, in process_async
    async for r in iterable:
  File "/Users/ms/scrapy-1/.venv/lib/python3.9/site-packages/scrapy/spidermiddlewares/urllength.py", line 30, in process_spider_output_async
    async for r in result or ():
  File "/Users/ms/scrapy-1/.venv/lib/python3.9/site-packages/scrapy/core/spidermw.py", line 118, in process_async
    async for r in iterable:
  File "/Users/ms/scrapy-1/.venv/lib/python3.9/site-packages/scrapy/spidermiddlewares/depth.py", line 35, in process_spider_output_async
    async for r in result or ():
  File "/Users/ms/scrapy-1/.venv/lib/python3.9/site-packages/scrapy/core/spidermw.py", line 118, in process_async
    async for r in iterable:
  File "/Users/ms/scrapy-1/.venv/lib/python3.9/site-packages/scrapy/spiders/crawl.py", line 124, in _parse_response
    for request_or_item in iterate_spider_output(cb_res):
  File "/Users/ms/scrapy-1/scrapy1/scrapy1/spiders/eurolux_spider.py", line 44, in parse_page
    description = bleach_html(response.css('.text-md-h6').get())
  File "/Users/ms/scrapy-1/scrapy1/scrapy1/spiders/eurolux_spider.py", line 15, in bleach_html
    cleaned_html = bleach.clean(html_string, tags=allowed_tags, strip=True)
  File "/Users/ms/scrapy-1/.venv/lib/python3.9/site-packages/bleach/__init__.py", line 82, in clean
    return cleaner.clean(text)
  File "/Users/ms/scrapy-1/.venv/lib/python3.9/site-packages/bleach/sanitizer.py", line 186, in clean
    raise TypeError(message)
TypeError: argument cannot be of 'NoneType' type, must be of text type
2023-11-13 18:46:30 [scrapy.core.engine] INFO: Closing spider (finished)
2023-11-13 18:46:30 [scrapy.extensions.feedexport] INFO: Stored json feed (0 items) in: output.json
2023-11-13 18:46:30 [scrapy.statscollectors] INFO: Dumping Scrapy stats:
{'downloader/request_bytes': 14247,
 'downloader/request_count': 54,
 'downloader/request_method_count/GET': 54,
 'downloader/response_bytes': 58583110,
 'downloader/response_count': 54,
 'downloader/response_status_count/200': 54,
 'elapsed_time_seconds': 36.823856,
 'feedexport/success_count/FileFeedStorage': 1,
 'finish_reason': 'finished',
 'finish_time': datetime.datetime(2023, 11, 13, 17, 46, 30, 112822, tzinfo=datetime.timezone.utc),
 'log_count/DEBUG': 57,
 'log_count/ERROR': 52,
 'log_count/INFO': 11,
 'log_count/WARNING': 1,
 'memusage/max': 59637760,
 'memusage/startup': 59637760,
 'request_depth_max': 1,
 'response_received_count': 54,
 'robotstxt/request_count': 1,
 'robotstxt/response_count': 1,
 'robotstxt/response_status_count/200': 1,
 'scheduler/dequeued': 53,
 'scheduler/dequeued/memory': 53,
 'scheduler/enqueued': 53,
 'scheduler/enqueued/memory': 53,
 'spider_exceptions/TypeError': 52,
 'start_time': datetime.datetime(2023, 11, 13, 17, 45, 53, 288966, tzinfo=datetime.timezone.utc)}
2023-11-13 18:46:30 [scrapy.core.engine] INFO: Spider closed (finished)
2023-11-13 18:47:32 [scrapy.utils.log] INFO: Scrapy 2.11.0 started (bot: scrapy1)
2023-11-13 18:47:32 [scrapy.utils.log] INFO: Versions: lxml 4.9.3.0, libxml2 2.9.13, cssselect 1.2.0, parsel 1.8.1, w3lib 2.1.2, Twisted 22.10.0, Python 3.9.6 (default, May  7 2023, 23:32:44) - [Clang 14.0.3 (clang-1403.0.22.14.1)], pyOpenSSL 23.3.0 (OpenSSL 3.1.4 24 Oct 2023), cryptography 41.0.5, Platform macOS-14.0-arm64-arm-64bit
2023-11-13 18:47:32 [scrapy.addons] INFO: Enabled addons:
[]
2023-11-13 18:47:32 [asyncio] DEBUG: Using selector: KqueueSelector
2023-11-13 18:47:32 [scrapy.utils.log] DEBUG: Using reactor: twisted.internet.asyncioreactor.AsyncioSelectorReactor
2023-11-13 18:47:32 [scrapy.utils.log] DEBUG: Using asyncio event loop: asyncio.unix_events._UnixSelectorEventLoop
2023-11-13 18:47:32 [scrapy.extensions.telnet] INFO: Telnet Password: 0e003314286e6454
2023-11-13 18:47:32 [scrapy.middleware] INFO: Enabled extensions:
['scrapy.extensions.corestats.CoreStats',
 'scrapy.extensions.telnet.TelnetConsole',
 'scrapy.extensions.memusage.MemoryUsage',
 'scrapy.extensions.feedexport.FeedExporter',
 'scrapy.extensions.logstats.LogStats']
2023-11-13 18:47:32 [scrapy.crawler] INFO: Overridden settings:
{'BOT_NAME': 'scrapy1',
 'FEED_EXPORT_ENCODING': 'utf-8',
 'LOG_FILE': 'scrapy.log',
 'NEWSPIDER_MODULE': 'scrapy1.spiders',
 'REQUEST_FINGERPRINTER_IMPLEMENTATION': '2.7',
 'ROBOTSTXT_OBEY': True,
 'SPIDER_MODULES': ['scrapy1.spiders'],
 'TWISTED_REACTOR': 'twisted.internet.asyncioreactor.AsyncioSelectorReactor'}
2023-11-13 18:47:32 [py.warnings] WARNING: /Users/ms/scrapy-1/.venv/lib/python3.9/site-packages/urllib3/__init__.py:34: NotOpenSSLWarning: urllib3 v2.0 only supports OpenSSL 1.1.1+, currently the 'ssl' module is compiled with 'LibreSSL 2.8.3'. See: https://github.com/urllib3/urllib3/issues/3020
  warnings.warn(

2023-11-13 18:47:32 [scrapy.middleware] INFO: Enabled downloader middlewares:
['scrapy.downloadermiddlewares.robotstxt.RobotsTxtMiddleware',
 'scrapy.downloadermiddlewares.httpauth.HttpAuthMiddleware',
 'scrapy.downloadermiddlewares.downloadtimeout.DownloadTimeoutMiddleware',
 'scrapy.downloadermiddlewares.defaultheaders.DefaultHeadersMiddleware',
 'scrapy.downloadermiddlewares.useragent.UserAgentMiddleware',
 'scrapy.downloadermiddlewares.retry.RetryMiddleware',
 'scrapy.downloadermiddlewares.redirect.MetaRefreshMiddleware',
 'scrapy.downloadermiddlewares.httpcompression.HttpCompressionMiddleware',
 'scrapy.downloadermiddlewares.redirect.RedirectMiddleware',
 'scrapy.downloadermiddlewares.cookies.CookiesMiddleware',
 'scrapy.downloadermiddlewares.httpproxy.HttpProxyMiddleware',
 'scrapy.downloadermiddlewares.stats.DownloaderStats']
2023-11-13 18:47:32 [scrapy.middleware] INFO: Enabled spider middlewares:
['scrapy.spidermiddlewares.httperror.HttpErrorMiddleware',
 'scrapy.spidermiddlewares.offsite.OffsiteMiddleware',
 'scrapy.spidermiddlewares.referer.RefererMiddleware',
 'scrapy.spidermiddlewares.urllength.UrlLengthMiddleware',
 'scrapy.spidermiddlewares.depth.DepthMiddleware']
2023-11-13 18:47:32 [scrapy.middleware] INFO: Enabled item pipelines:
[]
2023-11-13 18:47:32 [scrapy.core.engine] INFO: Spider opened
2023-11-13 18:47:32 [scrapy.extensions.logstats] INFO: Crawled 0 pages (at 0 pages/min), scraped 0 items (at 0 items/min)
2023-11-13 18:47:32 [scrapy.extensions.telnet] INFO: Telnet console listening on 127.0.0.1:6023
2023-11-13 18:47:33 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://eurolux.de/robots.txt> (referer: None)
2023-11-13 18:47:34 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://eurolux.de/> (referer: None)
2023-11-13 18:47:39 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://eurolux.de/category/milchtank> (referer: https://eurolux.de/)
2023-11-13 18:47:39 [scrapy.dupefilters] DEBUG: Filtered duplicate request: <GET https://eurolux.de/category/lagertanks> - no more duplicates will be shown (see DUPEFILTER_DEBUG to show all duplicates)
2023-11-13 18:47:39 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://eurolux.de/category/maischetank> (referer: https://eurolux.de/)
2023-11-13 18:47:39 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://eurolux.de/category/weintank> (referer: https://eurolux.de/)
2023-11-13 18:47:40 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://eurolux.de/category/drucktank-sektdrucktank> (referer: https://eurolux.de/)
2023-11-13 18:47:41 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://eurolux.de/category/biertank-zkg-tank> (referer: https://eurolux.de/)
2023-11-13 18:47:42 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://eurolux.de/category/lagertanks> (referer: https://eurolux.de/)
2023-11-13 18:47:42 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://eurolux.de/category/immervolltank> (referer: https://eurolux.de/)
2023-11-13 18:47:42 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://eurolux.de/category/fruchtsafttank-kze-tank> (referer: https://eurolux.de/)
2023-11-13 18:47:42 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://eurolux.de/category/cip-tank-de> (referer: https://eurolux.de/)
2023-11-13 18:47:42 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://eurolux.de/category/warmespeicher> (referer: https://eurolux.de/)
2023-11-13 18:47:42 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://eurolux.de/category/loschwassertank-wasserzisterne> (referer: https://eurolux.de/)
2023-11-13 18:47:44 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://eurolux.de/category/transporttank-container> (referer: https://eurolux.de/)
2023-11-13 18:47:44 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://eurolux.de/category/gfk-tank-kunststofftank> (referer: https://eurolux.de/)
2023-11-13 18:47:45 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://eurolux.de/category/komplette-abfuellanlage> (referer: https://eurolux.de/)
2023-11-13 18:47:45 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://eurolux.de/category/zubehor> (referer: https://eurolux.de/)
2023-11-13 18:47:46 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://eurolux.de/category/ruhrwerke> (referer: https://eurolux.de/)
2023-11-13 18:47:46 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://eurolux.de/product/19-00063-3L-000-liters-storage-tanks-outside-marbled-for-wine-water-fruit-juice-schnapps-> (referer: https://eurolux.de/category/weintank)
2023-11-13 18:47:46 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://eurolux.de/product/23-0401euba-163000-liter-lagertankmilchtank-mit-seitlichem-ruhrwerksmixer-isoliert-diffusionsdicht-verschweit> (referer: https://eurolux.de/category/milchtank)
2023-11-13 18:47:46 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://eurolux.de/product/16-00183bl-8000-liter-drucktank> (referer: https://eurolux.de/category/drucktank-sektdrucktank)
2023-11-13 18:47:46 [scrapy.core.scraper] DEBUG: Scraped from <200 https://eurolux.de/product/19-00063-3L-000-liters-storage-tanks-outside-marbled-for-wine-water-fruit-juice-schnapps->
{'description': 'Lagertank außen marmoriert\n'
                '\n'
                'für Wein, Wasser, Fruchtsaft, Schnaps \n'
                '\n'
                'Inhalt: 3.000 Liter\n'
                '\n'
                'NEU!\n'
                '\n'
                '\n'
                '\n'
                '\xa0\xa0\xa0\xa0\xa0\xa0\xa0\xa0\xa0\xa0\xa0 \xa0\xa0\xa0\xa0 \n'
                '\n'
                'Abmessungen und Gewicht:\n'
                '\n'
                'Durchmesser:\xa0\xa0\xa0\xa0\xa0\xa0\xa0 1110 mm \n'
                '\n'
                'Ges.Höhe:\xa0\xa0\xa0\xa0\xa0\xa0\xa0\xa0\xa0\xa0 \xa0\xa0'
                '3650 mm\n'
                '\n'
                'Zyl. Höhe:\xa0\xa0\xa0\xa0\xa0\xa0\xa0\xa0\xa0\xa0 \xa0\xa0'
                '3000 mm\n'
                '\n'
                '\xa0\n'
                '\n'
                'Material:\xa0\xa0\xa0\xa0\xa0 \xa0\xa0\xa0\xa0\xa0\xa0\xa0\xa0\xa0\xa0\xa0\xa0\xa0\xa0\xa0 \n'
                '\n'
                'V2A - AISI 304, \xa0V4A – AISI 316 \n'
                '\n'
                '\xa0\n'
                '\n'
                'Oberfläche:\xa0\xa0\xa0\xa0\xa0\xa0\xa0\xa0\xa0\xa0\xa0\xa0\xa0\xa0\xa0 \n'
                '\n'
                'Oberboden: V2A= 304, innen IIID außen marmoriert\n'
                '\n'
                'Zylinder: V2A=304, innen IIID, außen marmoriert \n'
                '\n'
                'Unterboden: V4A=316, IIIC=2B marmoriert \n'
                '\n'
                '\xa0\n'
                '\n'
                'Oberboden:\xa0\xa0\xa0 \n'
                '\n'
                'Konischer Boden\xa0 \n'
                '\n'
                '1 x Be- und Entlüftungsanschluss DN50\n'
                '\n'
                '2 x Kranösen\n'
                '\n'
                '\xa0\n'
                '\n'
                'Zylindertank:\n'
                '\n'
                '2 x '
                'Leiterhaken\xa0\xa0\xa0\xa0\xa0\xa0\xa0\xa0\xa0\xa0\xa0\xa0\xa0 \n'
                '\n'
                '1 x Mannloch vorne oval 430 x 320 mm \xa0schwenkbar mit Bügel '
                'und Halterung\n'
                ' 1 x Probierhahn DN 15 \xa0(gegen Aufpreis)\n'
                '\n'
                '1 x Tauchschaftshülse für Temperaturanzeige (gegen Aufpreis)\n'
                '\n'
                '1 x Thermometer digital (gegen Aufpreis) \n'
                '\n'
                '1 x Füllstandanzeige mit Leiste und Skala\n'
                '\n'
                '1 x Klarablauf mit Scheibenventil DN 50 und Blindkappe DN 50 '
                '(gegen Aufpreis)\n'
                '\n'
                '\xa0\n'
                '\n'
                'Unterboden:\xa0\xa0 \n'
                '\n'
                'Konischer Boden\xa0\xa0\xa0 \n'
                '\n'
                '1 x nach vorne gezogener Auslauf mit Scheibenventil DN 50 und '
                'Blindkappe DN 50 (gegen Aufpreis)\n'
                '\n'
                '3 x Kalottenfüße höhenverstellbar',
 'title': '3.000 Liter Lagertank außen marmoriert  für Wein, Wasser, '
          'Fruchtsaft, Schnaps'}
2023-11-13 18:47:47 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://eurolux.de/product/milk-tank-12000-litres-in-aisi-3041with-agitator-> (referer: https://eurolux.de/category/milchtank)
2023-11-13 18:47:47 [scrapy.core.scraper] DEBUG: Scraped from <200 https://eurolux.de/product/milk-tank-12000-litres-in-aisi-3041with-agitator->
{'description': 'Milchtank 12.000 Liter aus V2A mit Rührwerk \n'
                '\n'
                'Mixer seitlich\n'
                '\n'
                'mit Kühl-Heizmantel 15,4 m²\n'
                '\n'
                'mit Isolierung 80 mm\n'
                '\n'
                '\xa0\n'
                '\n'
                'Zul.Betriebsüberdruck: 1 '
                'bar \xa0\xa0\xa0\xa0\xa0\xa0\xa0\xa0\xa0\xa0\xa0\xa0\xa0\xa0\xa0\xa0\xa0\xa0\xa0\xa0\xa0\xa0\xa0\xa0\xa0\xa0\xa0\xa0\xa0\n'
                '\n'
                'Zul.Betriebstemperatur: '
                '130°C\xa0\xa0\xa0\xa0\xa0\xa0\xa0\xa0\xa0\xa0\xa0\xa0\xa0\xa0\xa0\xa0\xa0\xa0\xa0\xa0\xa0\xa0\xa0\xa0\xa0\xa0\xa0\xa0\xa0\xa0 \n'
                '\n'
                'Inhalt: 12.000 Liter\n'
                '\n'
                '\n'
                '\n'
                'die Abmessungen:\n'
                '\n'
                '\xa0\n'
                '\n'
                'Ges.Höhe: 3530 mm\xa0\xa0\xa0 Zylinder Höhe: 2500 '
                'mm\xa0\xa0\xa0\xa0 Durchmesser: 2610 '
                'mm\xa0\xa0\xa0\xa0\xa0\xa0\xa0\xa0\xa0\xa0\xa0 \xa0\xa0\xa0\xa0\xa0\xa0\xa0\xa0 '
                'Gewicht: 13220kg\n'
                '\n'
                '\xa0\xa0\xa0\xa0\xa0\xa0\xa0\xa0\xa0\xa0\xa0 \n'
                '\n'
                '\xa0\xa0\xa0\xa0\xa0\xa0\xa0\xa0\xa0\xa0\xa0\xa0\xa0\xa0\xa0\xa0\xa0\xa0\xa0\xa0\xa0\xa0\xa0\xa0\xa0\xa0\xa0\xa0\xa0\xa0\xa0\xa0\xa0\xa0\xa0\xa0\xa0\xa0\xa0\xa0\xa0\xa0\xa0\xa0\xa0\xa0\xa0\xa0\xa0\xa0\xa0\xa0\xa0\xa0\xa0\xa0\xa0\xa0 \n'
                '\n'
                'Material:\xa0\xa0\xa0\xa0\xa0\xa0\xa0\xa0\xa0\xa0\xa0\xa0 \xa0\xa0\xa0\xa0\xa0\xa0\xa0\n'
                '\n'
                'V2A - AISI 304, 1.4307\n'
                '\n'
                '\xa0\n'
                '\n'
                '\xa0\n'
                '\n'
                'Oberfläche:\xa0\xa0\xa0 \xa0\xa0\xa0\xa0\xa0\xa0\xa0\n'
                '\n'
                'außen marmoriert, innen 2B=IIIC\n'
                '\n'
                '\xa0\n'
                '\n'
                '\xa0\n'
                '\n'
                'Oberboden:\xa0\xa0 \xa0 \xa0\xa0\xa0\xa0\xa0\n'
                '\n'
                '- mit Mannloch mit Deckel DN 400 mm mit Klammern\xa0\xa0 \n'
                '\n'
                '- mit CIP Reinigung zentral\n'
                '\n'
                '- mit 2 Ösen\n'
                '\n'
                '- mit Be-und Entlüftung\n'
                '\n'
                '\xa0\n'
                '\n'
                'Zylinder:\xa0\xa0\xa0\xa0\xa0\xa0\xa0\xa0 \xa0\xa0\xa0\xa0 \n'
                '\n'
                '\xa0- mit Mannloch oval vorne 440 x 310 mm\n'
                '\n'
                '\xa0- mit Probierhahn\n'
                '\n'
                '\xa0- mit Isolierung \n'
                '\n'
                '\xa0- mit Rührwerk / Mixer seitlich( LENZE, Type: MHERAXX '
                '090-12 V1C, V/Y:230/400, Hz: 50, r/min: 1445,kW: 1,1)\n'
                '\n'
                '\xa0- mit Temperaturanzeige\n'
                '\n'
                '- mit Gewindeanscheißstutzen DN 40\n'
                '\n'
                '- mit 4 x Gewinde auf der Rückseite \n'
                '\n'
                '- mit Isolierung 80 mm Mineral Wool\n'
                '\n'
                '- mit Kühl- und Heizmantel 15,4 m² \n'
                '\n'
                '\xa0\xa0\xa0\xa0\xa0\xa0\xa0\xa0\xa0\xa0\xa0\xa0\xa0\xa0\xa0\xa0\xa0\xa0\xa0\xa0\xa0\xa0\xa0\xa0\xa0\xa0\xa0\xa0\xa0\xa0 \xa0\xa0\xa0\xa0\xa0\n'
                '\n'
                'Unterboden: \xa0 \xa0\xa0\xa0\n'
                '\n'
                '- nach vorne gezogenem Restauslauf mit Scheibenventil DN 40\n'
                '\n'
                '- 4 stabile Füsse\n'
                '\n'
                '\xa0\n'
                '\n'
                'Preisgleitklausel:\n'
                '\n'
                'Falls sich gravierende Veränderungen in der '
                'Materialbeschaffungs-Situation nach oben oder nach unten '
                'ergeben, behalten wir uns Angebotskorrekturen vor.',
 'title': 'Milchtank 12.000 Liter aus V2A mit Rührwerk'}
2023-11-13 18:47:47 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://eurolux.de/category/getraenke-und-technik> (referer: https://eurolux.de/)
2023-11-13 18:47:47 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://eurolux.de/product/500-litres-storage-tank-pressure-tank-with-cooling-jacket-with-conical-bottom-in-v2a-max-working-pressure-2-bar-new> (referer: https://eurolux.de/category/biertank-zkg-tank)
2023-11-13 18:47:47 [scrapy.crawler] INFO: Received SIGINT, shutting down gracefully. Send again to force 
2023-11-13 18:47:47 [scrapy.core.engine] INFO: Closing spider (shutdown)
2023-11-13 18:47:47 [scrapy.core.scraper] DEBUG: Scraped from <200 https://eurolux.de/product/500-litres-storage-tank-pressure-tank-with-cooling-jacket-with-conical-bottom-in-v2a-max-working-pressure-2-bar-new>
{'description': 'AS UNI 003-449',
 'title': '500 Liter Lagertank /  Drucktank mit Kühlmantel  mit Konusboden aus '
          'V2A NEU'}
2023-11-13 18:47:48 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://eurolux.de/product/23-0083-500-liter-biertank-lagertank-mit-kuhlmantel> (referer: https://eurolux.de/category/biertank-zkg-tank)
2023-11-13 18:47:49 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://eurolux.de/product/beer-tank-storage-tank-pressure-tank-500-litres> (referer: https://eurolux.de/category/biertank-zkg-tank)
2023-11-13 18:47:49 [scrapy.core.scraper] DEBUG: Scraped from <200 https://eurolux.de/product/beer-tank-storage-tank-pressure-tank-500-litres>
{'description': 'UNI 003-515\n'
                '\n'
                'Biertank/ Lagertanks/\xa0Drucktank 500 Liter\n'
                '\n'
                ' mit Kühlmantel rund stehend aus V2A, \n'
                '\n'
                ' Betriebsdruck: +2,0 bar',
 'title': '500 Liter Tank aus V2A'}
2023-11-13 18:47:49 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://eurolux.de/product/500-liter-zkg-tanks-lagertanks-biertanks-drucktanks-in-v2a> (referer: https://eurolux.de/category/biertank-zkg-tank)
2023-11-13 18:47:49 [scrapy.core.scraper] DEBUG: Scraped from <200 https://eurolux.de/product/500-liter-zkg-tanks-lagertanks-biertanks-drucktanks-in-v2a>
{'description': 'Eurolux \n'
                '\n'
                'ZKG Tanks / Lagertanks / Biertanks / Drucktanks in V2A\n'
                '\n'
                'mit Kühlmantelundmit Isolierung\n'
                '\n'
                'Prüfdruck: 2,86 bar, Betriebsdruck: 2 bar\n'
                '\n'
                'Inhalt: 500 Liter\n'
                '\n'
                '\n'
                '\n'
                'Material: V2A (AISI 304) 1.4301\n'
                '\n'
                '\xa0\n'
                '\n'
                'Oberboden:\n'
                '\n'
                '\n'
                '\n'
                'mit 2 Ösen\n'
                '\n'
                'mit Entluftungssystem\n'
                '\n'
                'mit CIP-Reinigung\n'
                '\n'
                'mit nach unten gezogenen Füllleitung DN 32 mit '
                'Gärspundarmatur (mit Überdruckventil, mit \xa0\n'
                '\n'
                '\n'
                '\xa0 \xa0 \xa0 \xa0 \xa0 Manometer )\n'
                '\n'
                '\xa0\n'
                '\n'
                'Tankzylinder:\n'
                '\n'
                '\n'
                '\n'
                'mit Leiterhaken oben\n'
                '\n'
                'mit Mannloch oval 430 x 330 mm\n'
                '\n'
                'mit Kühlmantel und mit Isolierung\n'
                '\n'
                'mit Probierhahn DN 25 (gegen Aufpreis: Spirale in V2A)\n'
                '\n'
                'mit Tauchschafthülse (gegen Aufpreis: Temperaturanzeige)\n'
                '\n'
                'auf der Rückseite vom Tank 2 x Anschlüsse für Kühlung (Ein- '
                'und Ausgang 1“ und 1¼“)\n'
                '\n'
                '\n'
                '\xa0\n'
                '\n'
                'Unterboden:\n'
                '\n'
                '\n'
                '\n'
                'mit nach vorne gezogenem Restauslauf mit Scheibenventil DN '
                '50\n'
                '\n'
                'mit nach vorne gezogenem Klarablauf mit Scheibenventil DN 50\n'
                '\n'
                'mit Konusboden 60°\n'
                '\n'
                'mit Kühlmantel und mit Isolierung im Konusboden\n'
                '\n'
                'auf der Rückseite vom Konusboden 2 x Anschlüsse für Kühlung '
                '(Ein- und Ausgang 1“ und 1¼“)\n'
                '\n'
                '\n'
                '4 Kalottenfüsse, höhenverstellbar\n'
                '\n'
                ' \n'
                '\n'
                '\n'
                '\n'
                'Preisgleitklausel:\n'
                'Falls sich gravierende Veränderungen in der '
                'Materialbeschaffungs-Situation nach oben oder nach unten '
                'ergeben, behalten wir uns Angebotskorrekturen vor.',
 'title': '500 Liter ZKG Tanks / Lagertanks / Biertanks / Drucktanks in V2A'}
2023-11-13 18:47:50 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://eurolux.de/product/23-0251euba-164000-liter-heiwassertank-warmespeicher-lagertank-1-bar-isoliert-stehend-aus-v2a> (referer: https://eurolux.de/category/warmespeicher)
2023-11-13 18:47:50 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://eurolux.de/product/000-litre-gfk-tank-water-tank> (referer: https://eurolux.de/category/loschwassertank-wasserzisterne)
2023-11-13 18:47:50 [scrapy.core.scraper] DEBUG: Scraped from <200 https://eurolux.de/product/000-litre-gfk-tank-water-tank>
{'description': 'Lagertank / GFK Tank / Kunststofftank / Zweistöckiger Tank '
                'oder auch als Einkammertank nutzbar mit 81.000 Liter\n'
                '\n'
                'Wassertank/ Zisterne/ Puffertank/ Flachbodentank/ '
                'Mehrkammertank \n'
                '\n'
                '\xa0\n'
                '\n'
                '\xa0Inhalt: 81.000 Liter \n'
                '\n'
                '(oben: 54.000 Liter, unten: 27.000 Liter)\n'
                '\n'
                '\n'
                '\n'
                '\n'
                'Zeichnung vorhanden\n'
                '\n'
                '\xa0\xa0\n'
                '\n'
                'Tank-Beschreibung\n'
                '\n'
                '\xa0\n'
                '\n'
                'Behälter mit gewölbtem Boden oben, Mantelzylinder und '
                'Flachboden oben 54.000Ltr, unten 27.000 Ltr mit '
                'Standzarge/Fußring.\n'
                '\n'
                '\xa0\n'
                '\n'
                '\xa0\n'
                '\n'
                'Tankoberboden:\n'
                '\n'
                '\n'
                '\n'
                'Gewölbter Oberboden mit zentralen Flansch, DN 50 für '
                'Reinigung\n'
                '\n'
                'Mit Belüftungsstutzen 240 mit Flansch DN 50\n'
                '\n'
                '\n'
                '\xa0\n'
                '\n'
                'Tankzylinder:\n'
                '\n'
                '\n'
                '\n'
                'Mit Entlüftung DN 50 für unteren Tank Pos.2 siehe Skizze\n'
                '\n'
                'Mit Flanschanschluß DN 50 mit 57° Einlauf\n'
                '\n'
                '2 x mit Mannloch oval310 x 440 mit Klemmbügel mit '
                'Feststellrad aus V4A\n'
                '\n'
                '2 x mit 3/8’’ Probierhahn\n'
                '\n'
                '2 x mit Flanschanschluß DN 50 für Rührwerk mit 69° Einlauf\n'
                '\n'
                'Mit nach vorne gezogenem Restauslaufrohr DN 65 mit '
                'Flanschanschluß\n'
                '\n'
                '\n'
                '\xa0\n'
                '\n'
                '\xa0\n'
                '\n'
                'Tankboden:\xa0\xa0\xa0\xa0 \n'
                '\n'
                '\n'
                '\n'
                '\n'
                '\n'
                'Mit Flachboden mit 2% Bodenschräge/Gefälle\n'
                '\n'
                '\n'
                '\n'
                '\n'
                'Mit Restauslauf DN 65 mit Flanschanschluß\n'
                '\n'
                '\n'
                '\n'
                '\n'
                'Mit Auslaufsicke',
 'title': '81.000 Liter GFK Tank / Wassertank'}
2023-11-13 18:47:51 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://eurolux.de/product/000-liter-storage-tanks-steel-tanks-water-tanks-water-cistern-> (referer: https://eurolux.de/category/loschwassertank-wasserzisterne)
2023-11-13 18:47:51 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://eurolux.de/product/23-0268euba-7800-liter-lagertank> (referer: https://eurolux.de/category/cip-tank-de)
2023-11-13 18:47:51 [scrapy.core.scraper] DEBUG: Scraped from <200 https://eurolux.de/product/000-liter-storage-tanks-steel-tanks-water-tanks-water-cistern->
{'description': 'Lagertanks/ Stahltanks/ Löschwassertanks/ Wasserzisternen\n'
                '\n'
                'mit roter lebensmittelechter '
                'Munkaturbeschichtung\xa0\xa0\xa0\xa0\xa0\xa0\xa0\xa0\xa0\xa0\xa0\xa0\xa0\xa0\xa0\xa0\xa0\xa0\xa0\xa0\xa0\xa0\xa0\xa0\xa0\xa0\xa0\xa0 \n'
                '\n'
                'Inhalt: 120.000 Liter\n'
                '\n'
                '\n'
                '\n'
                'UNI-BADWIN\n'
                '\n'
                '\n'
                '\n'
                'Abmessungen und Gewicht:\n'
                '\n'
                'Ges. '
                'Höhe:\xa0\xa0\xa0\xa0\xa0\xa0\xa0\xa0\xa0\xa0\xa0\xa0\xa0\xa0\xa0\xa0\xa0\xa0 \xa0'
                '17.200 mm\n'
                '\n'
                'Zyl. '
                'Höhe:\xa0\xa0\xa0\xa0\xa0\xa0\xa0\xa0\xa0\xa0\xa0\xa0\xa0\xa0\xa0\xa0\xa0\xa0\xa0\xa0 '
                '15.230 mm\xa0\xa0\xa0\xa0\xa0\xa0 \n'
                '\n'
                'Durchmesser:\xa0\xa0\xa0\xa0\xa0\xa0\xa0\xa0\xa0\xa0\xa0\xa0\xa0\xa0\xa0\xa0 '
                '3.100 mm\n'
                '\n'
                'Gewicht: \n'
                '\n'
                '\xa0\n'
                '\n'
                'Oberboden:\n'
                '\n'
                'Mit gewölbtem Boden\n'
                '\n'
                'Mit 4 Kranösen\n'
                '\n'
                'Mit 2 Anschlussmuffen 1“\n'
                '\n'
                'Mit 1 Anschlussmuffe 2“\n'
                '\n'
                'Mit zentralem Flansch DN 150\n'
                '\n'
                'Mit Mannloch DN 200\n'
                '\n'
                'Mit 1 Haltelasche für Laufpodest \n'
                '\n'
                '\xa0\n'
                '\n'
                '\xa0\n'
                '\n'
                'Zylinder:\n'
                '\n'
                'Mit Mannloch 430 x 340 mm mit Schwingdeckel mit Bügel\n'
                '\n'
                'Mit Temperaturanzeige Nippel 1“\n'
                '\n'
                'Mit Probierhahn Nippel 1“\n'
                '\n'
                'Mit Klarablauf DN 65\n'
                '\n'
                '\xa0\n'
                '\n'
                'Unterboden:\n'
                '\n'
                'Mit gewölbtem Boden\n'
                '\n'
                'Mit Auslaufrohr DN \n'
                '\n'
                'Mit 8 Füßen \n'
                '\n'
                '\xa0\n'
                '\n'
                'Bemerkung: Gesamte Ausstattung siehe Fotos',
 'title': '120.000 Liter Löschwassertank/Lagertank/Stahltanks/Wasserzisternen'}
2023-11-13 18:47:51 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://eurolux.de/product/gfk-storage-tank-34000-liter-capacity-round-vertical> (referer: https://eurolux.de/category/gfk-tank-kunststofftank)
2023-11-13 18:47:51 [scrapy.core.scraper] DEBUG: Scraped from <200 https://eurolux.de/product/gfk-storage-tank-34000-liter-capacity-round-vertical>
{'description': 'KK UNI-CH\n'
                '\n'
                '\n'
                '\n'
                'Abmessungen:\n'
                '\n'
                'Ges. '
                'Höhe:\xa0\xa0\xa0\xa0\xa0\xa0\xa0\xa0\xa0\xa0\xa0\xa0\xa0\xa0\xa0\xa0\xa0\xa0 '
                '7.350\xa0 mm\n'
                '\n'
                'Zylinder '
                'Höhe:\xa0\xa0\xa0\xa0\xa0\xa0\xa0\xa0\xa0\xa0\xa0\xa0\xa0 '
                '6.600\xa0 mm\n'
                '\n'
                'Durchmesser:\xa0\xa0\xa0\xa0\xa0\xa0\xa0\xa0\xa0\xa0\xa0\xa0\xa0\xa0 '
                '2.500\xa0 mm\n'
                '\n'
                '\xa0\n'
                '\n'
                'Material:\n'
                '\n'
                'Werkstoff: \xa0\xa0\xa0\xa0\xa0\xa0\xa0\xa0\xa0\xa0\xa0\xa0\xa0\xa0\xa0\xa0\xa0\xa0\xa0 '
                'GFK\n'
                '\n'
                '\xa0\n'
                '\n'
                'Oberboden:\n'
                '\n'
                '- mit Klöpperboden\n'
                '\n'
                '- mit Gewindestutzen DN 100\n'
                '\n'
                '- mit Mannloch Ø 400 rund\n'
                '\n'
                '\xa0\n'
                '\n'
                'Zylinder:\n'
                '\n'
                '- mit Mannloch Ø 430 x 330 oval\n'
                '\n'
                '- mit Klarablauf DN 65\n'
                '\n'
                '- mit Restablauf DN 65\n'
                '\n'
                '- mit Fußring mit Sockel mit 3 % Schräge',
 'title': '34.000 Liter GFK Lagertank rund stehend'}
2023-11-13 18:47:51 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://eurolux.de/product/reduction-excentric-dn-6550-new> (referer: https://eurolux.de/category/zubehor)
2023-11-13 18:47:51 [scrapy.core.scraper] DEBUG: Scraped from <200 https://eurolux.de/product/reduction-excentric-dn-6550-new>
{'description': '', 'title': 'Reduzierung / Übergang Exzentrisch DN 65/50 NEU'}
2023-11-13 18:47:51 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://eurolux.de/product/gfk-storage-tank-30000-liter-capacity-round-with-flat-bottom> (referer: https://eurolux.de/category/gfk-tank-kunststofftank)
2023-11-13 18:47:52 [scrapy.core.scraper] DEBUG: Scraped from <200 https://eurolux.de/product/gfk-storage-tank-30000-liter-capacity-round-with-flat-bottom>
{'description': 'KK UNI-CH\n'
                '\n'
                '\xa0\n'
                '\n'
                'Abmessungen:\n'
                '\n'
                'Ges. '
                'Höhe:\xa0\xa0\xa0\xa0\xa0\xa0\xa0\xa0\xa0\xa0\xa0\xa0\xa0\xa0\xa0\xa0\xa0\xa0 '
                '7.000\xa0 mm\n'
                '\n'
                'Zyl. '
                'Höhe:\xa0\xa0\xa0\xa0\xa0\xa0\xa0\xa0\xa0\xa0\xa0\xa0\xa0\xa0\xa0\xa0\xa0\xa0\xa0\xa0 '
                '6.350\xa0 mm\n'
                '\n'
                'Durchmesser\xa0\xa0\xa0\xa0\xa0\xa0\xa0\xa0\xa0\xa0\xa0\xa0\xa0\xa0\xa0 '
                '2.430\xa0 mm\n'
                '\n'
                '\xa0\n'
                '\n'
                'Material:\n'
                '\n'
                'Werkstoff: GFK\n'
                '\n'
                '\xa0\n'
                '\n'
                'Oberboden:\n'
                '\n'
                '- mit Klöpperboden\n'
                '\n'
                '- Mannloch DN 300 rund\n'
                '\n'
                '\xa0\n'
                '\n'
                'Zylinder:\n'
                '\n'
                '- mit Restablauf DN 65 \n'
                '\n'
                '- mit Gewindestutzen DN 65\n'
                '\n'
                '- mit Klarablauf\n'
                '\n'
                '- mit Mannloch Ø 330x430\n'
                '\n'
                '\xa0\n'
                '\n'
                'Unterboden:\n'
                '\n'
                '- mit Flachboden mit Fußring 3 % Schräge\n'
                '\n'
                '- mit Restablauf DN 50',
 'title': '30.000 Liter GFK Lagertank rund mit Flachboden'}
2023-11-13 18:47:52 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://eurolux.de/product/16-00077L-agitator-stelzer> (referer: https://eurolux.de/category/ruhrwerke)
2023-11-13 18:47:52 [scrapy.core.scraper] DEBUG: Scraped from <200 https://eurolux.de/product/16-00077L-agitator-stelzer>
{'description': 'Motor Typ DRK 34 D\n'
                '\n'
                'Nr. 30712\n'
                '\n'
                'Betriebsart: S, Nr. 1\n'
                '\n'
                'IP44\xa0\xa0 3.0 kW\n'
                '\n'
                '50 Hz\xa0\xa0 380/660 V\n'
                '\n'
                '1440 min',
 'title': 'Rührwerk Stelzer'}
2023-11-13 18:47:52 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://eurolux.de/product/17-00168L-agitator-stelzer> (referer: https://eurolux.de/category/ruhrwerke)
2023-11-13 18:47:52 [scrapy.core.scraper] DEBUG: Scraped from <200 https://eurolux.de/product/17-00168L-agitator-stelzer>
{'description': 'Rührwerk STELZER \n'
                '\n'
                '\n'
                'Motordaten:\n'
                '\n'
                'Typ: DRX 1206 D\n'
                '\n'
                '0,55 kW\n'
                '\n'
                '905 / min.\n'
                '\n'
                '50 Hz\n'
                '\n'
                '220/380 V\n'
                '\n'
                '2,8 /1,6 A\n'
                '\n'
                '\xa0\n'
                '\n'
                '\xa0\n'
                '\n'
                'die Abmessungen:\n'
                '\n'
                'Höhe: \xa0 730 mm\n'
                '\n'
                'Breite: \xa0280 mm\n'
                '\n'
                'Länge: 300 mm\n'
                '\n'
                'Länge des Flügels: 100 mm\n'
                '\n'
                'Gewicht: 70 kg',
 'title': 'Rührwerk  STELZER'}
2023-11-13 18:47:53 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://eurolux.de/product/17-00165bl-agitator-guth-for-threaded-connection-size-37> (referer: https://eurolux.de/category/ruhrwerke)
2023-11-13 18:47:53 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://eurolux.de/product/23-0278-750-liter-lagertank> (referer: https://eurolux.de/category/ruhrwerke)
2023-11-13 18:47:53 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://eurolux.de/product/10-1885-mixer> (referer: https://eurolux.de/category/ruhrwerke)
2023-11-13 18:47:53 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://eurolux.de/product/eurocut-neck-sleeve-remover> (referer: https://eurolux.de/category/getraenke-und-technik)
2023-11-13 18:47:53 [scrapy.core.scraper] DEBUG: Scraped from <200 https://eurolux.de/product/10-1885-mixer>
{'description': 'Rührwerk Typ 80B\n\nNEU', 'title': 'Rührwerk Typ 80B'}
2023-11-13 18:47:53 [scrapy.core.scraper] DEBUG: Scraped from <200 https://eurolux.de/product/eurocut-neck-sleeve-remover>
{'description': 'Eurocut Halshülsenentferner - VORFÜHRMASCHINE\n'
                ' frequenzgesteuert – 5000 Flaschen/h',
 'title': 'Eurocut Halshülsenentferner '}
2023-11-13 18:47:53 [scrapy.extensions.feedexport] INFO: Stored json feed (14 items) in: output.json
2023-11-13 18:47:53 [scrapy.statscollectors] INFO: Dumping Scrapy stats:
{'downloader/request_bytes': 11777,
 'downloader/request_count': 40,
 'downloader/request_method_count/GET': 40,
 'downloader/response_bytes': 43644423,
 'downloader/response_count': 40,
 'downloader/response_status_count/200': 40,
 'dupefilter/filtered': 1199,
 'elapsed_time_seconds': 20.595046,
 'feedexport/success_count/FileFeedStorage': 1,
 'finish_reason': 'shutdown',
 'finish_time': datetime.datetime(2023, 11, 13, 17, 47, 53, 345291, tzinfo=datetime.timezone.utc),
 'item_scraped_count': 14,
 'log_count/DEBUG': 58,
 'log_count/INFO': 12,
 'log_count/WARNING': 1,
 'memusage/max': 60588032,
 'memusage/startup': 60588032,
 'request_depth_max': 3,
 'response_received_count': 40,
 'robotstxt/request_count': 1,
 'robotstxt/response_count': 1,
 'robotstxt/response_status_count/200': 1,
 'scheduler/dequeued': 39,
 'scheduler/dequeued/memory': 39,
 'scheduler/enqueued': 329,
 'scheduler/enqueued/memory': 329,
 'start_time': datetime.datetime(2023, 11, 13, 17, 47, 32, 750245, tzinfo=datetime.timezone.utc)}
2023-11-13 18:47:53 [scrapy.core.engine] INFO: Spider closed (shutdown)
